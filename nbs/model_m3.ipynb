{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import ConfigObject\n",
    "from utils import reserve_pop\n",
    "from utils import id_generator\n",
    "from utils import writer\n",
    "from utils import LibriSpeechGenerator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from parts import VSConvBlock\n",
    "from parts import DownSamplingBlock\n",
    "from parts import UpSamplingBlock\n",
    "from parts import OutBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonConfig = {\n",
    "    \"test_platform\": False,\n",
    "    \"ds_prop\": 0.25,\n",
    "    \"sr\": 16000,\n",
    "    \"n_samples\": 65536,\n",
    "    \n",
    "    \"n_channels\": 1,\n",
    "    \"n_classes\": 1,\n",
    "    \"depth\": 5,\n",
    "    \"fsize\": 24,\n",
    "    \"moffset\": 8,\n",
    "    \n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 25,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 8,\n",
    "    \"verbose\": 100,\n",
    "\n",
    "    \"checkpoint_path\": \"../models/model_checkpoint.pt\",\n",
    "    \"model_path\": \"../models/last_model.pt\",\n",
    "\n",
    "    \"save_last_batch\": True,\n",
    "    \"writer_path\": \"../logs/\",\n",
    "    \"history_path\": \"../logs/history.json\"\n",
    "}\n",
    "\n",
    "config = ConfigObject(**jsonConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "_params = {\n",
    "    'batch_size': config.batch_size,\n",
    "    'shuffle': config.shuffle,\n",
    "    'num_workers': config.num_workers\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load(\"../data/processed/noisy/train/x_train.pt\")\n",
    "y_train = torch.load(\"../data/processed/noisy/train/y_train.pt\")\n",
    "X_val = torch.load(\"../data/processed/noisy/val/x_val.pt\")\n",
    "y_val = torch.load(\"../data/processed/noisy/val/y_val.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generators\n",
    "lsg = LibriSpeechGenerator(config, X_train, y_train)\n",
    "lsg_val = LibriSpeechGenerator(config, X_val, y_val)\n",
    "\n",
    "ls_generator = data.DataLoader(lsg, **_params)\n",
    "ls_val_generator = data.DataLoader(lsg_val, **_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEWUNet(nn.Module):\n",
    "    def __init__(self, config, fd=15, fu=5):\n",
    "        \"\"\"Speech Enhancenment using Wave-U-Net\"\"\"\n",
    "        super(SEWUNet, self).__init__()\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.n_channels = config.n_channels\n",
    "        self.n_classes = config.n_classes\n",
    "        self.depth = config.depth\n",
    "        self.fsize = config.fsize\n",
    "        self.moffset = config.moffset\n",
    "        self.fd = fd\n",
    "        self.fu = fu\n",
    "\n",
    "        # Generate the list of in, out channels for the encoder\n",
    "        self.enc_filters = [self.n_channels]\n",
    "        self.enc_filters += [self.fsize * i + self.moffset\n",
    "                             for i in range(1, self.depth + 1)]\n",
    "        self.n_encoder = zip(self.enc_filters, self.enc_filters[1:])\n",
    "\n",
    "        # Bottleneck block sizes\n",
    "        mid_in = self.fsize * self.depth + self.moffset\n",
    "        mid_out = self.fsize * (self.depth + 1) + self.moffset\n",
    "\n",
    "        # Generate the list of in, out channels for the decoder\n",
    "        self.out_dec = reserve_pop(self.enc_filters)\n",
    "        self.in_dec = [mid_out + self.enc_filters[-1]]\n",
    "        self.in_dec += [self.out_dec[i] + self.out_dec[i + 1]\n",
    "                        for i in range(self.depth - 1)]\n",
    "        self.n_decoder = zip(self.in_dec, self.out_dec)\n",
    "\n",
    "        # Architecture and parameters\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "\n",
    "        # Build the encoder part of the U-net architecture\n",
    "        for i, (in_ch, out_ch) in enumerate(self.n_encoder):\n",
    "            self.encoder.append(DownSamplingBlock(\n",
    "                in_ch=in_ch,\n",
    "                out_ch=out_ch,\n",
    "                kernel_size=self.fd,\n",
    "                padding=self.fd // 2,\n",
    "                activation=nn.LeakyReLU(0.1))\n",
    "            )\n",
    "\n",
    "        # Bottleneck block for the U-net\n",
    "        self.mid_block = VSConvBlock(\n",
    "            in_ch=mid_in,\n",
    "            out_ch=mid_out,\n",
    "            kernel_size=self.fd,\n",
    "            padding=self.fd // 2,\n",
    "            activation=nn.LeakyReLU(0.1))\n",
    "\n",
    "        # Build the decoder part of the U-net architecture\n",
    "        for in_ch, out_ch in self.n_decoder:\n",
    "            self.decoder.append(UpSamplingBlock(\n",
    "                in_ch=in_ch,\n",
    "                out_ch=out_ch,\n",
    "                kernel_size=self.fu,\n",
    "                padding=self.fu // 2,\n",
    "                activation=nn.LeakyReLU(0.1),\n",
    "                mode=\"deconv\")\n",
    "            )\n",
    "\n",
    "        # Output block\n",
    "        out_ch = self.out_dec[-1] + 1\n",
    "        self.out_block = OutBlock(\n",
    "            in_ch=out_ch,\n",
    "            out_ch=self.n_classes,\n",
    "            activation=nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\"\"\"\n",
    "        enc = []\n",
    "        net_in = copy.copy(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            x, xi = self.encoder[i](x)\n",
    "            enc.append(xi)\n",
    "\n",
    "        x = self.mid_block(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            x = self.decoder[i](x, enc.pop())\n",
    "\n",
    "        x = self.out_block(x, net_in)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SEWUNet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "history = {'loss': [], 'SNR': [], 'val_loss': [], 'val_SNR': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomMetric():\n",
    "    \"\"\"Calculate the SNR of X and Y\"\"\"\n",
    "    def SNR(X, Y):\n",
    "        n = X.shape[2]\n",
    "        return torch.mean(10 * torch.log10(\n",
    "            (torch.norm(Y, dim=2)**2 / n) /\n",
    "            (torch.norm(X - Y, dim=2)**2 / n)\n",
    "        ))\n",
    "    return SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR (Validation): 10.05069351196289\n"
     ]
    }
   ],
   "source": [
    "# Build optimizer\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-6,\n",
    "    betas=(0.9, 0.999))\n",
    "\n",
    "# lr_scheduler = torch.optim.lr_scheduler(optimizer)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "# Loss and metric\n",
    "m_loss = nn.L1Loss()\n",
    "m_snr = CustomMetric()\n",
    "\n",
    "# Print validation metric before trainer\n",
    "print(\"SNR (Validation): {}\".format(m_snr(lsg_val.X, lsg_val.y).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1259572"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of trainable parameters in the model\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display trainning metrics\n",
    "def _display_metrics(epoch, it, steps, loss, metric):\n",
    "    print(\"Epoch [{:02d}/{:02d}]\".format(\n",
    "        epoch + 1, config.epochs), end=\", \")\n",
    "\n",
    "    print(\"Step [{:03d}/{:03d}]\".format(\n",
    "        it + 1, steps), end=\", \")\n",
    "\n",
    "    print(\"Loss: {}, SNR: {}\".format(\n",
    "        loss, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [01/25], Step [100/1803], Loss: 0.05473051965236664, SNR: -3.2239551544189453\n",
      "Epoch [01/25], Step [200/1803], Loss: 0.020575430244207382, SNR: 2.7811977863311768\n",
      "Epoch [01/25], Step [300/1803], Loss: 0.02033960074186325, SNR: 4.5944013595581055\n",
      "Epoch [01/25], Step [400/1803], Loss: 0.014637280255556107, SNR: 7.072195053100586\n",
      "Epoch [01/25], Step [500/1803], Loss: 0.017390117049217224, SNR: 6.698851108551025\n",
      "Epoch [01/25], Step [600/1803], Loss: 0.014986532740294933, SNR: 7.638518333435059\n",
      "Epoch [01/25], Step [700/1803], Loss: 0.012788310647010803, SNR: 8.781002044677734\n",
      "Epoch [01/25], Step [800/1803], Loss: 0.014047808945178986, SNR: 8.477258682250977\n",
      "Epoch [01/25], Step [900/1803], Loss: 0.017903342843055725, SNR: 7.726228713989258\n",
      "Epoch [01/25], Step [1000/1803], Loss: 0.022160548716783524, SNR: 8.40881061553955\n",
      "Epoch [01/25], Step [1100/1803], Loss: 0.012669771909713745, SNR: 9.56650161743164\n",
      "Epoch [01/25], Step [1200/1803], Loss: 0.012064819224178791, SNR: 10.092784881591797\n",
      "Epoch [01/25], Step [1300/1803], Loss: 0.013764082454144955, SNR: 8.91454029083252\n",
      "Epoch [01/25], Step [1400/1803], Loss: 0.011581424623727798, SNR: 10.521549224853516\n",
      "Epoch [01/25], Step [1500/1803], Loss: 0.013271575793623924, SNR: 8.50806999206543\n",
      "Epoch [01/25], Step [1600/1803], Loss: 0.011889130808413029, SNR: 10.359825134277344\n",
      "Epoch [01/25], Step [1700/1803], Loss: 0.010425330139696598, SNR: 11.108381271362305\n",
      "Epoch [01/25], Step [1800/1803], Loss: 0.009276974946260452, SNR: 11.748239517211914\n",
      ".:. Training metrics = Loss: 0.01997561670504964, SNR: 6.814212632239611\n",
      ".:. Validation metrics = Loss: 0.0114912891280644, SNR: 10.406515778009616\n",
      "Epoch [02/25], Step [100/1803], Loss: 0.014801406301558018, SNR: 9.532004356384277\n",
      "Epoch [02/25], Step [200/1803], Loss: 0.011903775855898857, SNR: 9.875457763671875\n",
      "Epoch [02/25], Step [300/1803], Loss: 0.009958039969205856, SNR: 10.258450508117676\n",
      "Epoch [02/25], Step [400/1803], Loss: 0.010633097030222416, SNR: 11.000850677490234\n",
      "Epoch [02/25], Step [500/1803], Loss: 0.013063868507742882, SNR: 10.811656951904297\n",
      "Epoch [02/25], Step [600/1803], Loss: 0.011693840846419334, SNR: 10.141229629516602\n",
      "Epoch [02/25], Step [700/1803], Loss: 0.011523080989718437, SNR: 10.425186157226562\n",
      "Epoch [02/25], Step [800/1803], Loss: 0.012169916182756424, SNR: 10.616241455078125\n",
      "Epoch [02/25], Step [900/1803], Loss: 0.013445824384689331, SNR: 10.341114044189453\n",
      "Epoch [02/25], Step [1000/1803], Loss: 0.01348605751991272, SNR: 10.096540451049805\n",
      "Epoch [02/25], Step [1100/1803], Loss: 0.010803413577377796, SNR: 11.385173797607422\n",
      "Epoch [02/25], Step [1200/1803], Loss: 0.011039434000849724, SNR: 11.604729652404785\n",
      "Epoch [02/25], Step [1300/1803], Loss: 0.01194972824305296, SNR: 10.460193634033203\n",
      "Epoch [02/25], Step [1400/1803], Loss: 0.012855492532253265, SNR: 10.350472450256348\n",
      "Epoch [02/25], Step [1500/1803], Loss: 0.014513596892356873, SNR: 10.093910217285156\n",
      "Epoch [02/25], Step [1600/1803], Loss: 0.011767849326133728, SNR: 11.087543487548828\n",
      "Epoch [02/25], Step [1700/1803], Loss: 0.013874825090169907, SNR: 11.08570671081543\n",
      "Epoch [02/25], Step [1800/1803], Loss: 0.010429643094539642, SNR: 10.811487197875977\n",
      ".:. Training metrics = Loss: 0.01170897359161703, SNR: 10.770403727772804\n",
      ".:. Validation metrics = Loss: 0.009801563506325743, SNR: 11.84279996836132\n",
      "Epoch [03/25], Step [100/1803], Loss: 0.01062750443816185, SNR: 12.233661651611328\n",
      "Epoch [03/25], Step [200/1803], Loss: 0.01326625794172287, SNR: 11.247163772583008\n",
      "Epoch [03/25], Step [300/1803], Loss: 0.009594250470399857, SNR: 12.758127212524414\n",
      "Epoch [03/25], Step [400/1803], Loss: 0.011999065056443214, SNR: 12.067089080810547\n",
      "Epoch [03/25], Step [500/1803], Loss: 0.010235059075057507, SNR: 12.051798820495605\n",
      "Epoch [03/25], Step [600/1803], Loss: 0.014055291190743446, SNR: 11.748069763183594\n",
      "Epoch [03/25], Step [700/1803], Loss: 0.009228907525539398, SNR: 11.859251022338867\n",
      "Epoch [03/25], Step [800/1803], Loss: 0.013217609375715256, SNR: 11.436559677124023\n",
      "Epoch [03/25], Step [900/1803], Loss: 0.0121085150167346, SNR: 11.795150756835938\n",
      "Epoch [03/25], Step [1000/1803], Loss: 0.009970862418413162, SNR: 12.128443717956543\n",
      "Epoch [03/25], Step [1100/1803], Loss: 0.007987997494637966, SNR: 12.652826309204102\n",
      "Epoch [03/25], Step [1200/1803], Loss: 0.008557848632335663, SNR: 12.738168716430664\n",
      "Epoch [03/25], Step [1300/1803], Loss: 0.012898549437522888, SNR: 10.406993865966797\n",
      "Epoch [03/25], Step [1400/1803], Loss: 0.00840681791305542, SNR: 10.76492977142334\n",
      "Epoch [03/25], Step [1500/1803], Loss: 0.013652151450514793, SNR: 10.762571334838867\n",
      "Epoch [03/25], Step [1600/1803], Loss: 0.009939916431903839, SNR: 12.413240432739258\n",
      "Epoch [03/25], Step [1700/1803], Loss: 0.009036073461174965, SNR: 12.557567596435547\n",
      "Epoch [03/25], Step [1800/1803], Loss: 0.008848045952618122, SNR: 11.819707870483398\n",
      ".:. Training metrics = Loss: 0.010389610356107902, SNR: 11.834664670251817\n",
      ".:. Validation metrics = Loss: 0.009373219992400903, SNR: 12.467406088509467\n",
      "Epoch [04/25], Step [100/1803], Loss: 0.008787481114268303, SNR: 12.539751052856445\n",
      "Epoch [04/25], Step [200/1803], Loss: 0.010586933232843876, SNR: 11.702960968017578\n",
      "Epoch [04/25], Step [300/1803], Loss: 0.009568237699568272, SNR: 13.059283256530762\n",
      "Epoch [04/25], Step [400/1803], Loss: 0.009209929034113884, SNR: 13.008491516113281\n",
      "Epoch [04/25], Step [500/1803], Loss: 0.009421356953680515, SNR: 13.630799293518066\n",
      "Epoch [04/25], Step [600/1803], Loss: 0.007846293970942497, SNR: 13.042181015014648\n",
      "Epoch [04/25], Step [700/1803], Loss: 0.010547436773777008, SNR: 13.275123596191406\n",
      "Epoch [04/25], Step [800/1803], Loss: 0.00794051494449377, SNR: 12.425518035888672\n",
      "Epoch [04/25], Step [900/1803], Loss: 0.008597366511821747, SNR: 12.421998977661133\n",
      "Epoch [04/25], Step [1000/1803], Loss: 0.008605103939771652, SNR: 12.822044372558594\n",
      "Epoch [04/25], Step [1100/1803], Loss: 0.009562494233250618, SNR: 12.744735717773438\n",
      "Epoch [04/25], Step [1200/1803], Loss: 0.008440111763775349, SNR: 13.054119110107422\n",
      "Epoch [04/25], Step [1300/1803], Loss: 0.009006207808852196, SNR: 12.025452613830566\n",
      "Epoch [04/25], Step [1400/1803], Loss: 0.008460842072963715, SNR: 12.770156860351562\n",
      "Epoch [04/25], Step [1500/1803], Loss: 0.01042177528142929, SNR: 12.394743919372559\n",
      "Epoch [04/25], Step [1600/1803], Loss: 0.009668605402112007, SNR: 11.831944465637207\n",
      "Epoch [04/25], Step [1700/1803], Loss: 0.008780493400990963, SNR: 11.75679874420166\n",
      "Epoch [04/25], Step [1800/1803], Loss: 0.008574478328227997, SNR: 13.296407699584961\n",
      ".:. Training metrics = Loss: 0.009767111850629038, SNR: 12.365753276341747\n",
      ".:. Validation metrics = Loss: 0.008664124356117223, SNR: 12.981033177641894\n",
      "Epoch [05/25], Step [100/1803], Loss: 0.009326446801424026, SNR: 12.291430473327637\n",
      "Epoch [05/25], Step [200/1803], Loss: 0.009105442091822624, SNR: 12.43787956237793\n",
      "Epoch [05/25], Step [300/1803], Loss: 0.011013544164597988, SNR: 12.363473892211914\n",
      "Epoch [05/25], Step [400/1803], Loss: 0.00946083664894104, SNR: 12.502021789550781\n",
      "Epoch [05/25], Step [500/1803], Loss: 0.008965540677309036, SNR: 12.917623519897461\n",
      "Epoch [05/25], Step [600/1803], Loss: 0.011561006307601929, SNR: 12.519233703613281\n",
      "Epoch [05/25], Step [700/1803], Loss: 0.009401321411132812, SNR: 12.862207412719727\n",
      "Epoch [05/25], Step [800/1803], Loss: 0.012333940714597702, SNR: 11.573722839355469\n",
      "Epoch [05/25], Step [900/1803], Loss: 0.007618109695613384, SNR: 12.978848457336426\n",
      "Epoch [05/25], Step [1000/1803], Loss: 0.009173506870865822, SNR: 13.088918685913086\n",
      "Epoch [05/25], Step [1100/1803], Loss: 0.00747961038723588, SNR: 13.498127937316895\n",
      "Epoch [05/25], Step [1200/1803], Loss: 0.007213963661342859, SNR: 13.07012939453125\n",
      "Epoch [05/25], Step [1300/1803], Loss: 0.00848410278558731, SNR: 12.891725540161133\n",
      "Epoch [05/25], Step [1400/1803], Loss: 0.008208351209759712, SNR: 13.357099533081055\n",
      "Epoch [05/25], Step [1500/1803], Loss: 0.00774028617888689, SNR: 13.558733940124512\n",
      "Epoch [05/25], Step [1600/1803], Loss: 0.009330453351140022, SNR: 12.775287628173828\n",
      "Epoch [05/25], Step [1700/1803], Loss: 0.009373282082378864, SNR: 12.187509536743164\n",
      "Epoch [05/25], Step [1800/1803], Loss: 0.009260032325983047, SNR: 12.677772521972656\n",
      ".:. Training metrics = Loss: 0.009361823740949383, SNR: 12.735629626238758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:. Validation metrics = Loss: 0.008399375910552736, SNR: 13.201644641701678\n",
      "Epoch [06/25], Step [100/1803], Loss: 0.01073942705988884, SNR: 13.269275665283203\n",
      "Epoch [06/25], Step [200/1803], Loss: 0.010253725573420525, SNR: 12.212249755859375\n",
      "Epoch [06/25], Step [300/1803], Loss: 0.013425052165985107, SNR: 12.214350700378418\n",
      "Epoch [06/25], Step [400/1803], Loss: 0.008944828063249588, SNR: 12.218657493591309\n",
      "Epoch [06/25], Step [500/1803], Loss: 0.008597420528531075, SNR: 11.993618965148926\n",
      "Epoch [06/25], Step [600/1803], Loss: 0.0074988375417888165, SNR: 13.716730117797852\n",
      "Epoch [06/25], Step [700/1803], Loss: 0.00891093723475933, SNR: 12.989017486572266\n",
      "Epoch [06/25], Step [800/1803], Loss: 0.0073180608451366425, SNR: 13.029745101928711\n",
      "Epoch [06/25], Step [900/1803], Loss: 0.009781349450349808, SNR: 12.303825378417969\n",
      "Epoch [06/25], Step [1000/1803], Loss: 0.009152738377451897, SNR: 13.710086822509766\n",
      "Epoch [06/25], Step [1100/1803], Loss: 0.009232832118868828, SNR: 13.338787078857422\n",
      "Epoch [06/25], Step [1200/1803], Loss: 0.0088329017162323, SNR: 13.132623672485352\n",
      "Epoch [06/25], Step [1300/1803], Loss: 0.008821981959044933, SNR: 11.261171340942383\n",
      "Epoch [06/25], Step [1400/1803], Loss: 0.010276870802044868, SNR: 12.1560640335083\n",
      "Epoch [06/25], Step [1500/1803], Loss: 0.00794959906488657, SNR: 13.811784744262695\n",
      "Epoch [06/25], Step [1600/1803], Loss: 0.009036801755428314, SNR: 13.678525924682617\n",
      "Epoch [06/25], Step [1700/1803], Loss: 0.010247016325592995, SNR: 12.196873664855957\n",
      "Epoch [06/25], Step [1800/1803], Loss: 0.008934532292187214, SNR: 12.206975936889648\n",
      ".:. Training metrics = Loss: 0.009041782454897056, SNR: 13.019814820340704\n",
      ".:. Validation metrics = Loss: 0.008172614343022976, SNR: 13.394371638566657\n",
      "Epoch [07/25], Step [100/1803], Loss: 0.006975746247917414, SNR: 13.419947624206543\n",
      "Epoch [07/25], Step [200/1803], Loss: 0.008562812581658363, SNR: 12.84487533569336\n",
      "Epoch [07/25], Step [300/1803], Loss: 0.007444777525961399, SNR: 13.343010902404785\n",
      "Epoch [07/25], Step [400/1803], Loss: 0.008327478542923927, SNR: 14.082595825195312\n",
      "Epoch [07/25], Step [500/1803], Loss: 0.008572814986109734, SNR: 12.800803184509277\n",
      "Epoch [07/25], Step [600/1803], Loss: 0.009268853813409805, SNR: 12.78078556060791\n",
      "Epoch [07/25], Step [700/1803], Loss: 0.00843534804880619, SNR: 12.45600700378418\n",
      "Epoch [07/25], Step [800/1803], Loss: 0.00895686261355877, SNR: 13.691703796386719\n",
      "Epoch [07/25], Step [900/1803], Loss: 0.007825972512364388, SNR: 14.251876831054688\n",
      "Epoch [07/25], Step [1000/1803], Loss: 0.008466389030218124, SNR: 13.050529479980469\n",
      "Epoch [07/25], Step [1100/1803], Loss: 0.011913740076124668, SNR: 13.486112594604492\n",
      "Epoch [07/25], Step [1200/1803], Loss: 0.009886644780635834, SNR: 13.082021713256836\n",
      "Epoch [07/25], Step [1300/1803], Loss: 0.006471413653343916, SNR: 13.652021408081055\n",
      "Epoch [07/25], Step [1400/1803], Loss: 0.010577700100839138, SNR: 13.332447052001953\n",
      "Epoch [07/25], Step [1500/1803], Loss: 0.011078618466854095, SNR: 13.256424903869629\n",
      "Epoch [07/25], Step [1600/1803], Loss: 0.00891544483602047, SNR: 14.066996574401855\n",
      "Epoch [07/25], Step [1700/1803], Loss: 0.007670697756111622, SNR: 13.176645278930664\n",
      "Epoch [07/25], Step [1800/1803], Loss: 0.007962331175804138, SNR: 12.610471725463867\n",
      ".:. Training metrics = Loss: 0.00877222357094138, SNR: 13.24417985808796\n",
      ".:. Validation metrics = Loss: 0.007874151652137444, SNR: 13.685343168803984\n",
      "Epoch [08/25], Step [100/1803], Loss: 0.008447534404695034, SNR: 12.799951553344727\n",
      "Epoch [08/25], Step [200/1803], Loss: 0.0065614692866802216, SNR: 14.465133666992188\n",
      "Epoch [08/25], Step [300/1803], Loss: 0.00830001849681139, SNR: 12.955930709838867\n",
      "Epoch [08/25], Step [400/1803], Loss: 0.006792882457375526, SNR: 14.719154357910156\n",
      "Epoch [08/25], Step [500/1803], Loss: 0.008035965263843536, SNR: 14.031951904296875\n",
      "Epoch [08/25], Step [600/1803], Loss: 0.007842102088034153, SNR: 13.682326316833496\n",
      "Epoch [08/25], Step [700/1803], Loss: 0.007187236566096544, SNR: 13.968964576721191\n",
      "Epoch [08/25], Step [800/1803], Loss: 0.0077209072187542915, SNR: 12.633129119873047\n",
      "Epoch [08/25], Step [900/1803], Loss: 0.007512838579714298, SNR: 14.366331100463867\n",
      "Epoch [08/25], Step [1000/1803], Loss: 0.008524464443325996, SNR: 12.675418853759766\n",
      "Epoch [08/25], Step [1100/1803], Loss: 0.010026616975665092, SNR: 14.04542350769043\n",
      "Epoch [08/25], Step [1200/1803], Loss: 0.007156019099056721, SNR: 13.631747245788574\n",
      "Epoch [08/25], Step [1300/1803], Loss: 0.008088165894150734, SNR: 13.986140251159668\n",
      "Epoch [08/25], Step [1400/1803], Loss: 0.008187265135347843, SNR: 13.64120864868164\n",
      "Epoch [08/25], Step [1500/1803], Loss: 0.007735427934676409, SNR: 14.130290985107422\n",
      "Epoch [08/25], Step [1600/1803], Loss: 0.010625263676047325, SNR: 13.993288040161133\n",
      "Epoch [08/25], Step [1700/1803], Loss: 0.007005251944065094, SNR: 13.491525650024414\n",
      "Epoch [08/25], Step [1800/1803], Loss: 0.007575504016131163, SNR: 14.115400314331055\n",
      ".:. Training metrics = Loss: 0.008517454885740258, SNR: 13.454984488362077\n",
      ".:. Validation metrics = Loss: 0.007783549852177591, SNR: 13.901809212392804\n",
      "Epoch [09/25], Step [100/1803], Loss: 0.00921914353966713, SNR: 14.375624656677246\n",
      "Epoch [09/25], Step [200/1803], Loss: 0.008199183270335197, SNR: 13.52273178100586\n",
      "Epoch [09/25], Step [300/1803], Loss: 0.008476213552057743, SNR: 13.645142555236816\n",
      "Epoch [09/25], Step [400/1803], Loss: 0.007264967076480389, SNR: 14.470841407775879\n",
      "Epoch [09/25], Step [500/1803], Loss: 0.00791896041482687, SNR: 12.709979057312012\n",
      "Epoch [09/25], Step [600/1803], Loss: 0.007986007258296013, SNR: 13.951274871826172\n",
      "Epoch [09/25], Step [700/1803], Loss: 0.009130564518272877, SNR: 12.442310333251953\n",
      "Epoch [09/25], Step [800/1803], Loss: 0.011237191036343575, SNR: 12.913066864013672\n",
      "Epoch [09/25], Step [900/1803], Loss: 0.010654582642018795, SNR: 14.175609588623047\n",
      "Epoch [09/25], Step [1000/1803], Loss: 0.007799393497407436, SNR: 14.012532234191895\n",
      "Epoch [09/25], Step [1100/1803], Loss: 0.007860591635107994, SNR: 13.724916458129883\n",
      "Epoch [09/25], Step [1200/1803], Loss: 0.006387321278452873, SNR: 14.961112976074219\n",
      "Epoch [09/25], Step [1300/1803], Loss: 0.006157356780022383, SNR: 14.529816627502441\n",
      "Epoch [09/25], Step [1400/1803], Loss: 0.008066168054938316, SNR: 13.387847900390625\n",
      "Epoch [09/25], Step [1500/1803], Loss: 0.011818461120128632, SNR: 14.017269134521484\n",
      "Epoch [09/25], Step [1600/1803], Loss: 0.008140021935105324, SNR: 13.989227294921875\n",
      "Epoch [09/25], Step [1700/1803], Loss: 0.007800344843417406, SNR: 13.734795570373535\n",
      "Epoch [09/25], Step [1800/1803], Loss: 0.008028375916182995, SNR: 12.952128410339355\n",
      ".:. Training metrics = Loss: 0.008326633664871692, SNR: 13.629371794786568\n",
      ".:. Validation metrics = Loss: 0.007629630835694836, SNR: 13.950826988936543\n",
      "Epoch [10/25], Step [100/1803], Loss: 0.008538628928363323, SNR: 13.63070297241211\n",
      "Epoch [10/25], Step [200/1803], Loss: 0.008596932515501976, SNR: 13.838895797729492\n",
      "Epoch [10/25], Step [300/1803], Loss: 0.006709772162139416, SNR: 14.459468841552734\n",
      "Epoch [10/25], Step [400/1803], Loss: 0.007077732123434544, SNR: 13.405922889709473\n",
      "Epoch [10/25], Step [500/1803], Loss: 0.00676268246024847, SNR: 14.366966247558594\n",
      "Epoch [10/25], Step [600/1803], Loss: 0.006594534497708082, SNR: 14.506424903869629\n",
      "Epoch [10/25], Step [700/1803], Loss: 0.010681821033358574, SNR: 13.115880966186523\n",
      "Epoch [10/25], Step [800/1803], Loss: 0.007690716534852982, SNR: 13.186064720153809\n",
      "Epoch [10/25], Step [900/1803], Loss: 0.01080353930592537, SNR: 14.184417724609375\n",
      "Epoch [10/25], Step [1000/1803], Loss: 0.008723439648747444, SNR: 12.286698341369629\n",
      "Epoch [10/25], Step [1100/1803], Loss: 0.006846321746706963, SNR: 13.408599853515625\n",
      "Epoch [10/25], Step [1200/1803], Loss: 0.008135488256812096, SNR: 14.467652320861816\n",
      "Epoch [10/25], Step [1300/1803], Loss: 0.01326759159564972, SNR: 13.335004806518555\n",
      "Epoch [10/25], Step [1400/1803], Loss: 0.007861606776714325, SNR: 13.587728500366211\n",
      "Epoch [10/25], Step [1500/1803], Loss: 0.006513390690088272, SNR: 15.249988555908203\n",
      "Epoch [10/25], Step [1600/1803], Loss: 0.009427841752767563, SNR: 13.15180778503418\n",
      "Epoch [10/25], Step [1700/1803], Loss: 0.00993047934025526, SNR: 13.952831268310547\n",
      "Epoch [10/25], Step [1800/1803], Loss: 0.008489677682518959, SNR: 13.716012001037598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:. Training metrics = Loss: 0.00817558599695121, SNR: 13.779388164109019\n",
      ".:. Validation metrics = Loss: 0.00744580823686235, SNR: 14.20136443574225\n",
      "Epoch [11/25], Step [100/1803], Loss: 0.006422805599868298, SNR: 14.820114135742188\n",
      "Epoch [11/25], Step [200/1803], Loss: 0.006161750294268131, SNR: 15.135879516601562\n",
      "Epoch [11/25], Step [300/1803], Loss: 0.007400254253298044, SNR: 14.534192085266113\n",
      "Epoch [11/25], Step [400/1803], Loss: 0.007824202999472618, SNR: 14.104194641113281\n",
      "Epoch [11/25], Step [500/1803], Loss: 0.006948021240532398, SNR: 14.702183723449707\n",
      "Epoch [11/25], Step [600/1803], Loss: 0.007612846791744232, SNR: 13.800819396972656\n",
      "Epoch [11/25], Step [700/1803], Loss: 0.00809633918106556, SNR: 14.26915168762207\n",
      "Epoch [11/25], Step [800/1803], Loss: 0.007734213024377823, SNR: 13.728994369506836\n",
      "Epoch [11/25], Step [900/1803], Loss: 0.00897651445120573, SNR: 13.115857124328613\n",
      "Epoch [11/25], Step [1000/1803], Loss: 0.007390432991087437, SNR: 13.870912551879883\n",
      "Epoch [11/25], Step [1100/1803], Loss: 0.008468261919915676, SNR: 13.794733047485352\n",
      "Epoch [11/25], Step [1200/1803], Loss: 0.007608463056385517, SNR: 14.169296264648438\n",
      "Epoch [11/25], Step [1300/1803], Loss: 0.010308638215065002, SNR: 13.984429359436035\n",
      "Epoch [11/25], Step [1400/1803], Loss: 0.00885460153222084, SNR: 13.273538589477539\n",
      "Epoch [11/25], Step [1500/1803], Loss: 0.009540064260363579, SNR: 14.084270477294922\n",
      "Epoch [11/25], Step [1600/1803], Loss: 0.006767170503735542, SNR: 14.633721351623535\n",
      "Epoch [11/25], Step [1700/1803], Loss: 0.006232679821550846, SNR: 15.700725555419922\n",
      "Epoch [11/25], Step [1800/1803], Loss: 0.0059101516380906105, SNR: 15.242767333984375\n",
      ".:. Training metrics = Loss: 0.008060594268188776, SNR: 13.894409136433366\n",
      ".:. Validation metrics = Loss: 0.007474988401162738, SNR: 14.176298682508692\n",
      "Epoch [12/25], Step [100/1803], Loss: 0.007810013834387064, SNR: 13.829343795776367\n",
      "Epoch [12/25], Step [200/1803], Loss: 0.007818736135959625, SNR: 14.529352188110352\n",
      "Epoch [12/25], Step [300/1803], Loss: 0.008972610346972942, SNR: 13.797725677490234\n",
      "Epoch [12/25], Step [400/1803], Loss: 0.0074540600180625916, SNR: 14.462295532226562\n",
      "Epoch [12/25], Step [500/1803], Loss: 0.006375587545335293, SNR: 14.650421142578125\n",
      "Epoch [12/25], Step [600/1803], Loss: 0.006159116514027119, SNR: 13.835174560546875\n",
      "Epoch [12/25], Step [700/1803], Loss: 0.009229661896824837, SNR: 12.879927635192871\n",
      "Epoch [12/25], Step [800/1803], Loss: 0.007280957419425249, SNR: 14.360685348510742\n",
      "Epoch [12/25], Step [900/1803], Loss: 0.007791951764374971, SNR: 14.454399108886719\n",
      "Epoch [12/25], Step [1000/1803], Loss: 0.009219813160598278, SNR: 15.172536849975586\n",
      "Epoch [12/25], Step [1100/1803], Loss: 0.00567691121250391, SNR: 15.592354774475098\n",
      "Epoch [12/25], Step [1200/1803], Loss: 0.007384863216429949, SNR: 15.284801483154297\n",
      "Epoch [12/25], Step [1300/1803], Loss: 0.007782898843288422, SNR: 14.634321212768555\n",
      "Epoch [12/25], Step [1400/1803], Loss: 0.00856168195605278, SNR: 13.162464141845703\n",
      "Epoch [12/25], Step [1500/1803], Loss: 0.007925314828753471, SNR: 13.531553268432617\n",
      "Epoch [12/25], Step [1600/1803], Loss: 0.008203900419175625, SNR: 14.372601509094238\n",
      "Epoch [12/25], Step [1700/1803], Loss: 0.005922752432525158, SNR: 13.934643745422363\n",
      "Epoch [12/25], Step [1800/1803], Loss: 0.007084932178258896, SNR: 15.023740768432617\n",
      ".:. Training metrics = Loss: 0.00797074177951236, SNR: 13.985534032913389\n",
      ".:. Validation metrics = Loss: 0.007308127918433131, SNR: 14.311407458747516\n",
      "Epoch [13/25], Step [100/1803], Loss: 0.008116239681839943, SNR: 13.761372566223145\n",
      "Epoch [13/25], Step [200/1803], Loss: 0.011153818108141422, SNR: 13.01697063446045\n",
      "Epoch [13/25], Step [300/1803], Loss: 0.007880676537752151, SNR: 14.169443130493164\n",
      "Epoch [13/25], Step [400/1803], Loss: 0.0082144346088171, SNR: 13.71346664428711\n",
      "Epoch [13/25], Step [500/1803], Loss: 0.005822146311402321, SNR: 15.989556312561035\n",
      "Epoch [13/25], Step [600/1803], Loss: 0.007230200804769993, SNR: 14.244301795959473\n",
      "Epoch [13/25], Step [700/1803], Loss: 0.007059588097035885, SNR: 13.94198226928711\n",
      "Epoch [13/25], Step [800/1803], Loss: 0.006967409048229456, SNR: 15.055042266845703\n",
      "Epoch [13/25], Step [900/1803], Loss: 0.007879450917243958, SNR: 13.25599479675293\n",
      "Epoch [13/25], Step [1000/1803], Loss: 0.008259354159235954, SNR: 13.978019714355469\n",
      "Epoch [13/25], Step [1100/1803], Loss: 0.008345166221261024, SNR: 13.909112930297852\n",
      "Epoch [13/25], Step [1200/1803], Loss: 0.006100821774452925, SNR: 14.66629409790039\n",
      "Epoch [13/25], Step [1300/1803], Loss: 0.007546038832515478, SNR: 14.746883392333984\n",
      "Epoch [13/25], Step [1400/1803], Loss: 0.0073595205321908, SNR: 14.082025527954102\n",
      "Epoch [13/25], Step [1500/1803], Loss: 0.007195479702204466, SNR: 14.343425750732422\n",
      "Epoch [13/25], Step [1600/1803], Loss: 0.008005162701010704, SNR: 15.0120849609375\n",
      "Epoch [13/25], Step [1700/1803], Loss: 0.008244198746979237, SNR: 13.660648345947266\n",
      "Epoch [13/25], Step [1800/1803], Loss: 0.007448827847838402, SNR: 13.63544750213623\n",
      ".:. Training metrics = Loss: 0.007885437199692256, SNR: 14.080027778112523\n",
      ".:. Validation metrics = Loss: 0.007563083300589175, SNR: 14.176595212416307\n",
      "Epoch [14/25], Step [100/1803], Loss: 0.01029298733919859, SNR: 12.3601655960083\n",
      "Epoch [14/25], Step [200/1803], Loss: 0.006869758479297161, SNR: 15.524800300598145\n",
      "Epoch [14/25], Step [300/1803], Loss: 0.0096360445022583, SNR: 13.874616622924805\n",
      "Epoch [14/25], Step [400/1803], Loss: 0.00875992514193058, SNR: 13.900096893310547\n",
      "Epoch [14/25], Step [500/1803], Loss: 0.0060578444972634315, SNR: 14.5741605758667\n",
      "Epoch [14/25], Step [600/1803], Loss: 0.011017784476280212, SNR: 13.202859878540039\n",
      "Epoch [14/25], Step [700/1803], Loss: 0.008001172915101051, SNR: 14.151063919067383\n",
      "Epoch [14/25], Step [800/1803], Loss: 0.007870585657656193, SNR: 13.178396224975586\n",
      "Epoch [14/25], Step [900/1803], Loss: 0.007150363177061081, SNR: 13.568364143371582\n",
      "Epoch [14/25], Step [1000/1803], Loss: 0.006906877271831036, SNR: 14.334529876708984\n",
      "Epoch [14/25], Step [1100/1803], Loss: 0.007332270499318838, SNR: 14.887765884399414\n",
      "Epoch [14/25], Step [1200/1803], Loss: 0.006872318685054779, SNR: 13.955814361572266\n",
      "Epoch [14/25], Step [1300/1803], Loss: 0.007955568842589855, SNR: 14.434891700744629\n",
      "Epoch [14/25], Step [1400/1803], Loss: 0.007922278717160225, SNR: 14.623601913452148\n",
      "Epoch [14/25], Step [1500/1803], Loss: 0.007750543765723705, SNR: 13.776721000671387\n",
      "Epoch [14/25], Step [1600/1803], Loss: 0.006655767560005188, SNR: 14.924416542053223\n",
      "Epoch [14/25], Step [1700/1803], Loss: 0.007604670245200396, SNR: 13.440973281860352\n",
      "Epoch [14/25], Step [1800/1803], Loss: 0.008463498204946518, SNR: 14.48553466796875\n",
      ".:. Training metrics = Loss: 0.00781509492448082, SNR: 14.158481918933376\n",
      ".:. Validation metrics = Loss: 0.00722536583992913, SNR: 14.526734088281259\n",
      "Epoch [15/25], Step [100/1803], Loss: 0.007597912102937698, SNR: 13.817161560058594\n",
      "Epoch [15/25], Step [200/1803], Loss: 0.006942902226001024, SNR: 14.076468467712402\n",
      "Epoch [15/25], Step [300/1803], Loss: 0.007894403301179409, SNR: 13.569929122924805\n",
      "Epoch [15/25], Step [400/1803], Loss: 0.011035177856683731, SNR: 13.27923583984375\n",
      "Epoch [15/25], Step [500/1803], Loss: 0.005959963891655207, SNR: 14.737709999084473\n",
      "Epoch [15/25], Step [600/1803], Loss: 0.00924578495323658, SNR: 13.84577751159668\n",
      "Epoch [15/25], Step [700/1803], Loss: 0.008477481082081795, SNR: 13.765052795410156\n",
      "Epoch [15/25], Step [800/1803], Loss: 0.00679329689592123, SNR: 14.606513023376465\n",
      "Epoch [15/25], Step [900/1803], Loss: 0.007378218695521355, SNR: 14.369333267211914\n",
      "Epoch [15/25], Step [1000/1803], Loss: 0.005964179057627916, SNR: 14.457231521606445\n",
      "Epoch [15/25], Step [1100/1803], Loss: 0.00859341211616993, SNR: 13.592607498168945\n",
      "Epoch [15/25], Step [1200/1803], Loss: 0.01000053808093071, SNR: 13.945333480834961\n",
      "Epoch [15/25], Step [1300/1803], Loss: 0.007875533774495125, SNR: 13.424776077270508\n",
      "Epoch [15/25], Step [1400/1803], Loss: 0.0064689889550209045, SNR: 14.359153747558594\n",
      "Epoch [15/25], Step [1500/1803], Loss: 0.008480393327772617, SNR: 14.643350601196289\n",
      "Epoch [15/25], Step [1600/1803], Loss: 0.006701398640871048, SNR: 14.568350791931152\n",
      "Epoch [15/25], Step [1700/1803], Loss: 0.007981720380485058, SNR: 14.174734115600586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Step [1800/1803], Loss: 0.0065190428867936134, SNR: 15.130154609680176\n",
      ".:. Training metrics = Loss: 0.00773868347220106, SNR: 14.238498730799863\n",
      ".:. Validation metrics = Loss: 0.007214457331152859, SNR: 14.524607051021048\n",
      "Epoch [16/25], Step [100/1803], Loss: 0.008080366998910904, SNR: 14.356382369995117\n",
      "Epoch [16/25], Step [200/1803], Loss: 0.0120442109182477, SNR: 13.139310836791992\n",
      "Epoch [16/25], Step [300/1803], Loss: 0.008735572919249535, SNR: 14.220425605773926\n",
      "Epoch [16/25], Step [400/1803], Loss: 0.008111171424388885, SNR: 14.78336238861084\n",
      "Epoch [16/25], Step [500/1803], Loss: 0.006228624377399683, SNR: 14.7085599899292\n",
      "Epoch [16/25], Step [600/1803], Loss: 0.007265930995345116, SNR: 14.406047821044922\n",
      "Epoch [16/25], Step [700/1803], Loss: 0.007566412910819054, SNR: 14.074190139770508\n",
      "Epoch [16/25], Step [800/1803], Loss: 0.009379255585372448, SNR: 13.36577320098877\n",
      "Epoch [16/25], Step [900/1803], Loss: 0.007527222856879234, SNR: 14.516386032104492\n",
      "Epoch [16/25], Step [1000/1803], Loss: 0.008764442056417465, SNR: 13.525946617126465\n",
      "Epoch [16/25], Step [1100/1803], Loss: 0.0072257984429597855, SNR: 14.365974426269531\n",
      "Epoch [16/25], Step [1200/1803], Loss: 0.007836421951651573, SNR: 14.587835311889648\n",
      "Epoch [16/25], Step [1300/1803], Loss: 0.007547379471361637, SNR: 13.52108097076416\n",
      "Epoch [16/25], Step [1400/1803], Loss: 0.009269083850085735, SNR: 14.0975341796875\n",
      "Epoch [16/25], Step [1500/1803], Loss: 0.00666737649589777, SNR: 15.349678039550781\n",
      "Epoch [16/25], Step [1600/1803], Loss: 0.008130311965942383, SNR: 14.06640625\n",
      "Epoch [16/25], Step [1700/1803], Loss: 0.006553977727890015, SNR: 14.322741508483887\n",
      "Epoch [16/25], Step [1800/1803], Loss: 0.007079225964844227, SNR: 13.753287315368652\n",
      ".:. Training metrics = Loss: 0.007687988392410626, SNR: 14.30089943838614\n",
      ".:. Validation metrics = Loss: 0.007579753747447848, SNR: 14.174031952265487\n",
      "Epoch [17/25], Step [100/1803], Loss: 0.007715478073805571, SNR: 14.862204551696777\n",
      "Epoch [17/25], Step [200/1803], Loss: 0.007901594042778015, SNR: 13.807088851928711\n",
      "Epoch [17/25], Step [300/1803], Loss: 0.007718884386122227, SNR: 14.669218063354492\n",
      "Epoch [17/25], Step [400/1803], Loss: 0.007846387103199959, SNR: 14.436969757080078\n",
      "Epoch [17/25], Step [500/1803], Loss: 0.006434419192373753, SNR: 15.385473251342773\n",
      "Epoch [17/25], Step [600/1803], Loss: 0.006032556761056185, SNR: 14.055334091186523\n",
      "Epoch [17/25], Step [700/1803], Loss: 0.007146398536860943, SNR: 14.129475593566895\n",
      "Epoch [17/25], Step [800/1803], Loss: 0.0075188023038208485, SNR: 14.615650177001953\n",
      "Epoch [17/25], Step [900/1803], Loss: 0.008016852661967278, SNR: 14.304094314575195\n",
      "Epoch [17/25], Step [1000/1803], Loss: 0.008074721321463585, SNR: 13.755125999450684\n",
      "Epoch [17/25], Step [1100/1803], Loss: 0.006912363227456808, SNR: 14.41618824005127\n",
      "Epoch [17/25], Step [1200/1803], Loss: 0.007546187378466129, SNR: 14.339574813842773\n",
      "Epoch [17/25], Step [1300/1803], Loss: 0.008452977985143661, SNR: 14.058298110961914\n",
      "Epoch [17/25], Step [1400/1803], Loss: 0.0071641914546489716, SNR: 15.253332138061523\n",
      "Epoch [17/25], Step [1500/1803], Loss: 0.007180051878094673, SNR: 15.048440933227539\n",
      "Epoch [17/25], Step [1600/1803], Loss: 0.0063300104811787605, SNR: 14.778268814086914\n",
      "Epoch [17/25], Step [1700/1803], Loss: 0.006420104764401913, SNR: 14.90954875946045\n",
      "Epoch [17/25], Step [1800/1803], Loss: 0.007536076474934816, SNR: 14.811851501464844\n",
      ".:. Training metrics = Loss: 0.007610445043503615, SNR: 14.382068461810317\n",
      ".:. Validation metrics = Loss: 0.007158394468195994, SNR: 14.56926386156463\n",
      "Epoch [18/25], Step [100/1803], Loss: 0.007627330254763365, SNR: 14.155872344970703\n",
      "Epoch [18/25], Step [200/1803], Loss: 0.007182351313531399, SNR: 15.09184455871582\n",
      "Epoch [18/25], Step [300/1803], Loss: 0.007052954286336899, SNR: 14.155092239379883\n",
      "Epoch [18/25], Step [400/1803], Loss: 0.0066755907610058784, SNR: 13.953571319580078\n",
      "Epoch [18/25], Step [500/1803], Loss: 0.0074959686025977135, SNR: 14.330793380737305\n",
      "Epoch [18/25], Step [600/1803], Loss: 0.006234666798263788, SNR: 15.614641189575195\n",
      "Epoch [18/25], Step [700/1803], Loss: 0.0073151239193975925, SNR: 15.543415069580078\n",
      "Epoch [18/25], Step [800/1803], Loss: 0.008088993839919567, SNR: 14.687989234924316\n",
      "Epoch [18/25], Step [900/1803], Loss: 0.012066522613167763, SNR: 13.978336334228516\n",
      "Epoch [18/25], Step [1000/1803], Loss: 0.006102954503148794, SNR: 15.847217559814453\n",
      "Epoch [18/25], Step [1100/1803], Loss: 0.006685441825538874, SNR: 14.012956619262695\n",
      "Epoch [18/25], Step [1200/1803], Loss: 0.00937738735228777, SNR: 13.068544387817383\n",
      "Epoch [18/25], Step [1300/1803], Loss: 0.007608028128743172, SNR: 15.582855224609375\n",
      "Epoch [18/25], Step [1400/1803], Loss: 0.008770963177084923, SNR: 14.317347526550293\n",
      "Epoch [18/25], Step [1500/1803], Loss: 0.0071623362600803375, SNR: 13.826589584350586\n",
      "Epoch [18/25], Step [1600/1803], Loss: 0.0074480678886175156, SNR: 14.456863403320312\n",
      "Epoch [18/25], Step [1700/1803], Loss: 0.007741248235106468, SNR: 14.270732879638672\n",
      "Epoch [18/25], Step [1800/1803], Loss: 0.009107429534196854, SNR: 14.83016586303711\n",
      ".:. Training metrics = Loss: 0.00757089413988224, SNR: 14.43507333530823\n",
      ".:. Validation metrics = Loss: 0.007177700731101308, SNR: 14.563810176995657\n",
      "Epoch [19/25], Step [100/1803], Loss: 0.00853312760591507, SNR: 13.300159454345703\n",
      "Epoch [19/25], Step [200/1803], Loss: 0.006126017309725285, SNR: 15.966449737548828\n",
      "Epoch [19/25], Step [300/1803], Loss: 0.0069509465247392654, SNR: 14.066659927368164\n",
      "Epoch [19/25], Step [400/1803], Loss: 0.007543960586190224, SNR: 15.045974731445312\n",
      "Epoch [19/25], Step [500/1803], Loss: 0.006805681623518467, SNR: 14.98133659362793\n",
      "Epoch [19/25], Step [600/1803], Loss: 0.007520293816924095, SNR: 14.386934280395508\n",
      "Epoch [19/25], Step [700/1803], Loss: 0.009986523538827896, SNR: 12.693178176879883\n",
      "Epoch [19/25], Step [800/1803], Loss: 0.006989034824073315, SNR: 16.69609832763672\n",
      "Epoch [19/25], Step [900/1803], Loss: 0.005457744933664799, SNR: 14.530710220336914\n",
      "Epoch [19/25], Step [1000/1803], Loss: 0.0071230800822377205, SNR: 14.594742774963379\n",
      "Epoch [19/25], Step [1100/1803], Loss: 0.007243019063025713, SNR: 14.370670318603516\n",
      "Epoch [19/25], Step [1200/1803], Loss: 0.01004086621105671, SNR: 13.894582748413086\n",
      "Epoch [19/25], Step [1300/1803], Loss: 0.00820995308458805, SNR: 14.765239715576172\n",
      "Epoch [19/25], Step [1400/1803], Loss: 0.008266976103186607, SNR: 14.535223960876465\n",
      "Epoch [19/25], Step [1500/1803], Loss: 0.007377624046057463, SNR: 15.062505722045898\n",
      "Epoch [19/25], Step [1600/1803], Loss: 0.007632712367922068, SNR: 13.475513458251953\n",
      "Epoch [19/25], Step [1700/1803], Loss: 0.00728444242849946, SNR: 14.622868537902832\n",
      "Epoch [19/25], Step [1800/1803], Loss: 0.0077362703159451485, SNR: 13.593644142150879\n",
      ".:. Training metrics = Loss: 0.007499040887106594, SNR: 14.516413984196523\n",
      ".:. Validation metrics = Loss: 0.007030839266251064, SNR: 14.613537499842206\n",
      "Epoch [20/25], Step [100/1803], Loss: 0.00566044682636857, SNR: 15.564059257507324\n",
      "Epoch [20/25], Step [200/1803], Loss: 0.008206980302929878, SNR: 14.259016990661621\n",
      "Epoch [20/25], Step [300/1803], Loss: 0.006824640557169914, SNR: 14.848701477050781\n",
      "Epoch [20/25], Step [400/1803], Loss: 0.008815916255116463, SNR: 14.225887298583984\n",
      "Epoch [20/25], Step [500/1803], Loss: 0.008699001744389534, SNR: 13.83727741241455\n",
      "Epoch [20/25], Step [600/1803], Loss: 0.006248948164284229, SNR: 14.907276153564453\n",
      "Epoch [20/25], Step [700/1803], Loss: 0.00796069297939539, SNR: 14.666457176208496\n",
      "Epoch [20/25], Step [800/1803], Loss: 0.006790844723582268, SNR: 14.904803276062012\n",
      "Epoch [20/25], Step [900/1803], Loss: 0.006436205003410578, SNR: 14.575896263122559\n",
      "Epoch [20/25], Step [1000/1803], Loss: 0.006720977369695902, SNR: 13.829668045043945\n",
      "Epoch [20/25], Step [1100/1803], Loss: 0.0069189053028821945, SNR: 15.53907585144043\n",
      "Epoch [20/25], Step [1200/1803], Loss: 0.008531717583537102, SNR: 14.497133255004883\n",
      "Epoch [20/25], Step [1300/1803], Loss: 0.005890130531042814, SNR: 14.642354011535645\n",
      "Epoch [20/25], Step [1400/1803], Loss: 0.006797988899052143, SNR: 15.988866806030273\n",
      "Epoch [20/25], Step [1500/1803], Loss: 0.006487170234322548, SNR: 15.777730941772461\n",
      "Epoch [20/25], Step [1600/1803], Loss: 0.008212496526539326, SNR: 15.397712707519531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Step [1700/1803], Loss: 0.007598171476274729, SNR: 14.989885330200195\n",
      "Epoch [20/25], Step [1800/1803], Loss: 0.005977139808237553, SNR: 15.675301551818848\n",
      ".:. Training metrics = Loss: 0.007467014555027132, SNR: 14.5580084534284\n",
      ".:. Validation metrics = Loss: 0.007231002917113726, SNR: 14.571144718179246\n",
      "Epoch [21/25], Step [100/1803], Loss: 0.007160509005188942, SNR: 15.102139472961426\n",
      "Epoch [21/25], Step [200/1803], Loss: 0.00712980143725872, SNR: 14.954452514648438\n",
      "Epoch [21/25], Step [300/1803], Loss: 0.007243111729621887, SNR: 15.603673934936523\n",
      "Epoch [21/25], Step [400/1803], Loss: 0.007740925531834364, SNR: 14.223321914672852\n",
      "Epoch [21/25], Step [500/1803], Loss: 0.006158323958516121, SNR: 15.375284194946289\n",
      "Epoch [21/25], Step [600/1803], Loss: 0.008327595889568329, SNR: 13.847644805908203\n",
      "Epoch [21/25], Step [700/1803], Loss: 0.007257456891238689, SNR: 14.824256896972656\n",
      "Epoch [21/25], Step [800/1803], Loss: 0.007152812089771032, SNR: 14.762767791748047\n",
      "Epoch [21/25], Step [900/1803], Loss: 0.0067163072526454926, SNR: 14.448431015014648\n",
      "Epoch [21/25], Step [1000/1803], Loss: 0.006892318371683359, SNR: 15.07270622253418\n",
      "Epoch [21/25], Step [1100/1803], Loss: 0.006963993422687054, SNR: 14.433082580566406\n",
      "Epoch [21/25], Step [1200/1803], Loss: 0.010199207812547684, SNR: 13.520648956298828\n",
      "Epoch [21/25], Step [1300/1803], Loss: 0.005806606262922287, SNR: 15.47342300415039\n",
      "Epoch [21/25], Step [1400/1803], Loss: 0.006413761526346207, SNR: 15.657694816589355\n",
      "Epoch [21/25], Step [1500/1803], Loss: 0.006470572203397751, SNR: 14.680209159851074\n",
      "Epoch [21/25], Step [1600/1803], Loss: 0.006808724720031023, SNR: 15.190805435180664\n",
      "Epoch [21/25], Step [1700/1803], Loss: 0.007444491144269705, SNR: 14.999920845031738\n",
      "Epoch [21/25], Step [1800/1803], Loss: 0.007014990784227848, SNR: 14.714675903320312\n",
      ".:. Training metrics = Loss: 0.0074056442598345795, SNR: 14.63381395958685\n",
      ".:. Validation metrics = Loss: 0.007360050056442023, SNR: 14.402121434417296\n",
      "Epoch [22/25], Step [100/1803], Loss: 0.007844936102628708, SNR: 13.06842041015625\n",
      "Epoch [22/25], Step [200/1803], Loss: 0.006895907688885927, SNR: 15.480962753295898\n",
      "Epoch [22/25], Step [300/1803], Loss: 0.007275203708559275, SNR: 13.999336242675781\n",
      "Epoch [22/25], Step [400/1803], Loss: 0.006280616857111454, SNR: 14.869245529174805\n",
      "Epoch [22/25], Step [500/1803], Loss: 0.007087875623255968, SNR: 15.45905876159668\n",
      "Epoch [22/25], Step [600/1803], Loss: 0.007967529818415642, SNR: 14.13076400756836\n",
      "Epoch [22/25], Step [700/1803], Loss: 0.007958739995956421, SNR: 15.545339584350586\n",
      "Epoch [22/25], Step [800/1803], Loss: 0.006129413843154907, SNR: 14.953207015991211\n",
      "Epoch [22/25], Step [900/1803], Loss: 0.007875176146626472, SNR: 14.614190101623535\n",
      "Epoch [22/25], Step [1000/1803], Loss: 0.007563833147287369, SNR: 13.924105644226074\n",
      "Epoch [22/25], Step [1100/1803], Loss: 0.007785237394273281, SNR: 14.417909622192383\n",
      "Epoch [22/25], Step [1200/1803], Loss: 0.007419622503221035, SNR: 14.376579284667969\n",
      "Epoch [22/25], Step [1300/1803], Loss: 0.007338603492826223, SNR: 14.482152938842773\n",
      "Epoch [22/25], Step [1400/1803], Loss: 0.007612334564328194, SNR: 14.456655502319336\n",
      "Epoch [22/25], Step [1500/1803], Loss: 0.006934550125151873, SNR: 14.564908981323242\n",
      "Epoch [22/25], Step [1600/1803], Loss: 0.006170277018100023, SNR: 15.230508804321289\n",
      "Epoch [22/25], Step [1700/1803], Loss: 0.0071046967059373856, SNR: 14.498257637023926\n",
      "Epoch [22/25], Step [1800/1803], Loss: 0.00699314521625638, SNR: 16.160778045654297\n",
      ".:. Training metrics = Loss: 0.0073694909016193124, SNR: 14.675085360441953\n",
      ".:. Validation metrics = Loss: 0.0068455359461788495, SNR: 14.943952195703021\n",
      "Epoch [23/25], Step [100/1803], Loss: 0.006835526321083307, SNR: 14.536874771118164\n",
      "Epoch [23/25], Step [200/1803], Loss: 0.007501011248677969, SNR: 14.427902221679688\n",
      "Epoch [23/25], Step [300/1803], Loss: 0.007361620664596558, SNR: 14.233189582824707\n",
      "Epoch [23/25], Step [400/1803], Loss: 0.006894258316606283, SNR: 14.617355346679688\n",
      "Epoch [23/25], Step [500/1803], Loss: 0.007344831712543964, SNR: 15.595525741577148\n",
      "Epoch [23/25], Step [600/1803], Loss: 0.006100339815020561, SNR: 16.271080017089844\n",
      "Epoch [23/25], Step [700/1803], Loss: 0.007166034542024136, SNR: 14.497712135314941\n",
      "Epoch [23/25], Step [800/1803], Loss: 0.006530856713652611, SNR: 14.322145462036133\n",
      "Epoch [23/25], Step [900/1803], Loss: 0.00762163195759058, SNR: 14.486726760864258\n",
      "Epoch [23/25], Step [1000/1803], Loss: 0.009173307567834854, SNR: 14.617837905883789\n",
      "Epoch [23/25], Step [1100/1803], Loss: 0.00839168205857277, SNR: 14.461275100708008\n",
      "Epoch [23/25], Step [1200/1803], Loss: 0.007913921028375626, SNR: 13.973188400268555\n",
      "Epoch [23/25], Step [1300/1803], Loss: 0.00650420505553484, SNR: 15.092536926269531\n",
      "Epoch [23/25], Step [1400/1803], Loss: 0.006624375469982624, SNR: 15.067849159240723\n",
      "Epoch [23/25], Step [1500/1803], Loss: 0.006954064592719078, SNR: 14.763203620910645\n",
      "Epoch [23/25], Step [1600/1803], Loss: 0.006181005388498306, SNR: 14.680368423461914\n",
      "Epoch [23/25], Step [1700/1803], Loss: 0.005983013194054365, SNR: 14.749332427978516\n",
      "Epoch [23/25], Step [1800/1803], Loss: 0.006933161523193121, SNR: 15.304986953735352\n",
      ".:. Training metrics = Loss: 0.007332330894856346, SNR: 14.722239028614261\n",
      ".:. Validation metrics = Loss: 0.006928993494187562, SNR: 14.835540473350802\n",
      "Epoch [24/25], Step [100/1803], Loss: 0.007645213510841131, SNR: 14.838820457458496\n",
      "Epoch [24/25], Step [200/1803], Loss: 0.006020602770149708, SNR: 14.540331840515137\n",
      "Epoch [24/25], Step [300/1803], Loss: 0.00657975347712636, SNR: 14.839941024780273\n",
      "Epoch [24/25], Step [400/1803], Loss: 0.0073081133887171745, SNR: 14.77197551727295\n",
      "Epoch [24/25], Step [500/1803], Loss: 0.007451727520674467, SNR: 14.702568054199219\n",
      "Epoch [24/25], Step [600/1803], Loss: 0.009178784675896168, SNR: 13.379512786865234\n",
      "Epoch [24/25], Step [700/1803], Loss: 0.006971115246415138, SNR: 14.162857055664062\n",
      "Epoch [24/25], Step [800/1803], Loss: 0.005401758477091789, SNR: 15.226953506469727\n",
      "Epoch [24/25], Step [900/1803], Loss: 0.005902756005525589, SNR: 14.781241416931152\n",
      "Epoch [24/25], Step [1000/1803], Loss: 0.009510651230812073, SNR: 13.53988265991211\n",
      "Epoch [24/25], Step [1100/1803], Loss: 0.0069315023720264435, SNR: 14.894275665283203\n",
      "Epoch [24/25], Step [1200/1803], Loss: 0.006238424219191074, SNR: 15.565706253051758\n",
      "Epoch [24/25], Step [1300/1803], Loss: 0.01081124134361744, SNR: 14.10096263885498\n",
      "Epoch [24/25], Step [1400/1803], Loss: 0.007892594672739506, SNR: 14.571699142456055\n",
      "Epoch [24/25], Step [1500/1803], Loss: 0.006867293268442154, SNR: 14.89503288269043\n",
      "Epoch [24/25], Step [1600/1803], Loss: 0.006522956304252148, SNR: 15.324012756347656\n",
      "Epoch [24/25], Step [1700/1803], Loss: 0.007172156125307083, SNR: 16.10535430908203\n",
      "Epoch [24/25], Step [1800/1803], Loss: 0.009374503046274185, SNR: 13.579992294311523\n",
      ".:. Training metrics = Loss: 0.007284641330908971, SNR: 14.77600485878648\n",
      ".:. Validation metrics = Loss: 0.006880975059900877, SNR: 14.973290208596081\n",
      "Epoch [25/25], Step [100/1803], Loss: 0.007610050495713949, SNR: 14.228280067443848\n",
      "Epoch [25/25], Step [200/1803], Loss: 0.007756710983812809, SNR: 15.56563949584961\n",
      "Epoch [25/25], Step [300/1803], Loss: 0.006808901205658913, SNR: 15.151891708374023\n",
      "Epoch [25/25], Step [400/1803], Loss: 0.007411606144160032, SNR: 15.929333686828613\n",
      "Epoch [25/25], Step [500/1803], Loss: 0.0059294262900948524, SNR: 15.23105239868164\n",
      "Epoch [25/25], Step [600/1803], Loss: 0.006614050827920437, SNR: 15.020681381225586\n",
      "Epoch [25/25], Step [700/1803], Loss: 0.005386425647884607, SNR: 15.166448593139648\n",
      "Epoch [25/25], Step [800/1803], Loss: 0.005572381895035505, SNR: 16.03582763671875\n",
      "Epoch [25/25], Step [900/1803], Loss: 0.006531008519232273, SNR: 15.032027244567871\n",
      "Epoch [25/25], Step [1000/1803], Loss: 0.007438458036631346, SNR: 14.228872299194336\n",
      "Epoch [25/25], Step [1100/1803], Loss: 0.01107371598482132, SNR: 13.644854545593262\n",
      "Epoch [25/25], Step [1200/1803], Loss: 0.0065723625011742115, SNR: 14.501242637634277\n",
      "Epoch [25/25], Step [1300/1803], Loss: 0.007481080014258623, SNR: 15.056461334228516\n",
      "Epoch [25/25], Step [1400/1803], Loss: 0.007885931991040707, SNR: 14.002346992492676\n",
      "Epoch [25/25], Step [1500/1803], Loss: 0.00649671396240592, SNR: 15.305936813354492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Step [1600/1803], Loss: 0.00745839299634099, SNR: 15.335469245910645\n",
      "Epoch [25/25], Step [1700/1803], Loss: 0.006951865274459124, SNR: 14.492782592773438\n",
      "Epoch [25/25], Step [1800/1803], Loss: 0.006012919824570417, SNR: 15.784590721130371\n",
      ".:. Training metrics = Loss: 0.007238717805114965, SNR: 14.829161329661938\n",
      ".:. Validation metrics = Loss: 0.006867052396427849, SNR: 14.953265213077266\n"
     ]
    }
   ],
   "source": [
    "# Train the model over epochs\n",
    "steps = len(ls_generator)\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    # training and val metrics for all data\n",
    "    loss, metric = 0.0, 0.0\n",
    "    val_loss, val_metric = 0.0, 0.0\n",
    "\n",
    "    # ======================== Training ============================= #\n",
    "    for i, (local_batch, local_labels) in enumerate(ls_generator):\n",
    "        # Transfer to Device\n",
    "        local_batch = local_batch.to(device)\n",
    "        local_labels = local_labels.to(device)\n",
    "\n",
    "        # Set gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass, backward pass, optimize\n",
    "        outputs = model(local_batch)\n",
    "        loss_batch = m_loss(outputs, local_labels)\n",
    "        batch_metric = m_snr(outputs, local_labels)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute metrics to all batch\n",
    "        loss += loss_batch.item() * len(local_batch)\n",
    "        metric += batch_metric.item() * len(local_batch)\n",
    "\n",
    "        # Print the loss every \"verbose\" batches\n",
    "        if (i + 1) % config.verbose == 0:\n",
    "            _display_metrics(epoch, i, steps,\n",
    "                loss_batch.item(), batch_metric.item())\n",
    "\n",
    "    # Compute the statistics of the last epoch and save to history\n",
    "    history['loss'].append(loss / len(lsg))\n",
    "    history['SNR'].append(metric / len(lsg))\n",
    "\n",
    "    # Checkpoint the model\n",
    "    torch.save(model.state_dict(), config.checkpoint_path)\n",
    "    \n",
    "    # Print Validation statistics\n",
    "    print(\".:. Training metrics =\", end=\" \")\n",
    "    print(\"Loss: {}, SNR: {}\".format(loss / len(lsg), metric / len(lsg)))\n",
    "    \n",
    "    # ======================= Validation ============================ #\n",
    "    with torch.no_grad():\n",
    "        for local_batch, local_labels in ls_val_generator:\n",
    "            # Transfer to device\n",
    "            local_batch = local_batch.to(device)\n",
    "            local_labels = local_labels.to(device)\n",
    "\n",
    "            # Predict, get loss and metric\n",
    "            outputs = model(local_batch)\n",
    "            val_loss += m_loss(outputs, local_labels).item() \\\n",
    "                * len(local_batch)\n",
    "\n",
    "            val_metric += m_snr(outputs, local_labels).item() \\\n",
    "                * len(local_batch)\n",
    "\n",
    "        val_loss /= len(lsg_val)\n",
    "        val_metric /= len(lsg_val)\n",
    "                \n",
    "    # Print Validation statistics\n",
    "    print(\".:. Validation metrics =\", end=\" \")\n",
    "    print(\"Loss: {}, SNR: {}\".format(val_loss, val_metric))\n",
    "\n",
    "    # Compute the metrics and loss of last batch and save to history\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_SNR'].append(val_metric)\n",
    "    lr_scheduler.step(val_loss)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "history['elapsed_time'] = elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the last model\n",
    "torch.save(model.state_dict(), config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot network history\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['val_loss'], label='val')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Traning history')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot network history\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(history['SNR'], label='train')\n",
    "plt.plot(history['val_SNR'], label='val')\n",
    "plt.ylabel('SNR')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Traning history')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history to a JSON file\n",
    "with open(config.history_path, 'w') as fp:\n",
    "    json.dump(history, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.load(\"../data/processed/noisy/test/x_test.pt\")\n",
    "y_test = torch.load(\"../data/processed/noisy/test/y_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsg_test = LibriSpeechGenerator(config, X_test, y_test)\n",
    "ls_test_generator = data.DataLoader(lsg_test, **_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3874, 1, 65536])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR (Test): 10.058753967285156\n"
     ]
    }
   ],
   "source": [
    "# Print validation metric before trainer\n",
    "print(\"SNR (Test): {}\".format(m_snr(lsg_test.X, lsg_test.y).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_metric = 0.0, 0.0\n",
    "with torch.no_grad():\n",
    "    for local_batch, local_labels in ls_test_generator:\n",
    "        # Transfer to device\n",
    "        local_batch = local_batch.to(device)\n",
    "        local_labels = local_labels.to(device)\n",
    "\n",
    "        # Predict, get loss and metric\n",
    "        outputs = model(local_batch)\n",
    "        test_loss += m_loss(outputs, local_labels).item() \\\n",
    "            * len(local_batch)\n",
    "\n",
    "        test_metric += m_snr(outputs, local_labels).item() \\\n",
    "            * len(local_batch)\n",
    "        \n",
    "        writer(local_batch, local_labels,\n",
    "               outputs, config.sr, config.writer_path)\n",
    "\n",
    "    test_loss /= len(lsg_test)\n",
    "    test_metric /= len(lsg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_history = {\n",
    "    'SNR_ini': m_snr(lsg_test.X, lsg_test.y).item(),\n",
    "    'SNR': test_metric,\n",
    "    'loss': test_loss\n",
    "}\n",
    "\n",
    "with open(os.path.join(config.writer_path, 'test_history.json') , 'w') as fp:\n",
    "    json.dump(test_history, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sewunet",
   "language": "python",
   "name": "sewunet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
