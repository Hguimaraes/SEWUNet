{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import ConfigObject\n",
    "from utils import reserve_pop\n",
    "from utils import id_generator\n",
    "from utils import writer\n",
    "from utils import LibriSpeechGenerator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from parts import VSConvBlock\n",
    "from parts import DownSamplingBlock\n",
    "from parts import UpSamplingBlock\n",
    "from parts import OutBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonConfig = {\n",
    "    \"test_platform\": False,\n",
    "    \"ds_prop\": 0.25,\n",
    "    \"sr\": 16000,\n",
    "    \"n_samples\": 65536,\n",
    "    \n",
    "    \"n_channels\": 1,\n",
    "    \"n_classes\": 1,\n",
    "    \"depth\": 5,\n",
    "    \"fsize\": 24,\n",
    "    \"moffset\": 8,\n",
    "    \n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 25,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 8,\n",
    "    \"verbose\": 100,\n",
    "\n",
    "    \"checkpoint_path\": \"../models/model_checkpoint.pt\",\n",
    "    \"model_path\": \"../models/last_model.pt\",\n",
    "\n",
    "    \"save_last_batch\": True,\n",
    "    \"writer_path\": \"../logs/\",\n",
    "    \"history_path\": \"../logs/history.json\"\n",
    "}\n",
    "\n",
    "config = ConfigObject(**jsonConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "_params = {\n",
    "    'batch_size': config.batch_size,\n",
    "    'shuffle': config.shuffle,\n",
    "    'num_workers': config.num_workers\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load(\"../data/processed/noisy/train/x_train.pt\")\n",
    "y_train = torch.load(\"../data/processed/noisy/train/y_train.pt\")\n",
    "X_val = torch.load(\"../data/processed/noisy/val/x_val.pt\")\n",
    "y_val = torch.load(\"../data/processed/noisy/val/y_val.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generators\n",
    "lsg = LibriSpeechGenerator(config, X_train, y_train)\n",
    "lsg_val = LibriSpeechGenerator(config, X_val, y_val)\n",
    "\n",
    "ls_generator = data.DataLoader(lsg, **_params)\n",
    "ls_val_generator = data.DataLoader(lsg_val, **_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEWUNet(nn.Module):\n",
    "    def __init__(self, config, fd=15, fu=5):\n",
    "        \"\"\"Speech Enhancenment using Wave-U-Net\"\"\"\n",
    "        super(SEWUNet, self).__init__()\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.n_channels = config.n_channels\n",
    "        self.n_classes = config.n_classes\n",
    "        self.depth = config.depth\n",
    "        self.fsize = config.fsize\n",
    "        self.moffset = config.moffset\n",
    "        self.fd = fd\n",
    "        self.fu = fu\n",
    "\n",
    "        # Generate the list of in, out channels for the encoder\n",
    "        self.enc_filters = [self.n_channels]\n",
    "        self.enc_filters += [self.fsize * i + self.moffset\n",
    "                             for i in range(1, self.depth + 1)]\n",
    "        self.n_encoder = zip(self.enc_filters, self.enc_filters[1:])\n",
    "\n",
    "        # Bottleneck block sizes\n",
    "        mid_in = self.fsize * self.depth + self.moffset\n",
    "        mid_out = self.fsize * (self.depth + 1) + self.moffset\n",
    "\n",
    "        # Generate the list of in, out channels for the decoder\n",
    "        self.out_dec = reserve_pop(self.enc_filters)\n",
    "        self.in_dec = [mid_out + self.enc_filters[-1]]\n",
    "        self.in_dec += [self.out_dec[i] + self.out_dec[i + 1]\n",
    "                        for i in range(self.depth - 1)]\n",
    "        self.n_decoder = zip(self.in_dec, self.out_dec)\n",
    "\n",
    "        # Architecture and parameters\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "\n",
    "        # Build the encoder part of the U-net architecture\n",
    "        for i, (in_ch, out_ch) in enumerate(self.n_encoder):\n",
    "            self.encoder.append(DownSamplingBlock(\n",
    "                in_ch=in_ch,\n",
    "                out_ch=out_ch,\n",
    "                kernel_size=self.fd,\n",
    "                padding=self.fd // 2,\n",
    "                activation=nn.LeakyReLU(0.1))\n",
    "            )\n",
    "\n",
    "        # Bottleneck block for the U-net\n",
    "        self.mid_block = VSConvBlock(\n",
    "            in_ch=mid_in,\n",
    "            out_ch=mid_out,\n",
    "            kernel_size=self.fd,\n",
    "            padding=self.fd // 2,\n",
    "            activation=nn.LeakyReLU(0.1))\n",
    "\n",
    "        # Build the decoder part of the U-net architecture\n",
    "        for in_ch, out_ch in self.n_decoder:\n",
    "            self.decoder.append(UpSamplingBlock(\n",
    "                in_ch=in_ch,\n",
    "                out_ch=out_ch,\n",
    "                kernel_size=self.fu,\n",
    "                padding=self.fu // 2,\n",
    "                activation=nn.LeakyReLU(0.1))\n",
    "            )\n",
    "\n",
    "        # Output block\n",
    "        out_ch = self.out_dec[-1] + 1\n",
    "        self.out_block = OutBlock(\n",
    "            in_ch=out_ch,\n",
    "            out_ch=self.n_classes,\n",
    "            activation=nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\"\"\"\n",
    "        enc = []\n",
    "        net_in = copy.copy(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            x, xi = self.encoder[i](x)\n",
    "            enc.append(xi)\n",
    "\n",
    "        x = self.mid_block(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            x = self.decoder[i](x, enc.pop())\n",
    "\n",
    "        x = self.out_block(x, net_in)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SEWUNet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "history = {'loss': [], 'SNR': [], 'val_loss': [], 'val_SNR': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomMetric():\n",
    "    \"\"\"Calculate the SNR of X and Y\"\"\"\n",
    "    def SNR(X, Y):\n",
    "        n = X.shape[2]\n",
    "        return torch.mean(10 * torch.log10(\n",
    "            (torch.norm(Y, dim=2)**2 / n) /\n",
    "            (torch.norm(X - Y, dim=2)**2 / n)\n",
    "        ))\n",
    "    return SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR (Validation): 10.05069351196289\n"
     ]
    }
   ],
   "source": [
    "# Build optimizer\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-6,\n",
    "    betas=(0.9, 0.999))\n",
    "\n",
    "# lr_scheduler = torch.optim.lr_scheduler(optimizer)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "# Loss and metric\n",
    "m_loss = nn.L1Loss()\n",
    "m_snr = CustomMetric()\n",
    "\n",
    "# Print validation metric before trainer\n",
    "print(\"SNR (Validation): {}\".format(m_snr(lsg_val.X, lsg_val.y).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1139372"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of trainable parameters in the model\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display trainning metrics\n",
    "def _display_metrics(epoch, it, steps, loss, metric):\n",
    "    print(\"Epoch [{:02d}/{:02d}]\".format(\n",
    "        epoch + 1, config.epochs), end=\", \")\n",
    "\n",
    "    print(\"Step [{:03d}/{:03d}]\".format(\n",
    "        it + 1, steps), end=\", \")\n",
    "\n",
    "    print(\"Loss: {}, SNR: {}\".format(\n",
    "        loss, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [01/25], Step [100/1803], Loss: 0.04428306594491005, SNR: -2.4753310680389404\n",
      "Epoch [01/25], Step [200/1803], Loss: 0.034397199749946594, SNR: 1.3119312524795532\n",
      "Epoch [01/25], Step [300/1803], Loss: 0.025615144520998, SNR: 3.9518463611602783\n",
      "Epoch [01/25], Step [400/1803], Loss: 0.020957859233021736, SNR: 4.828291416168213\n",
      "Epoch [01/25], Step [500/1803], Loss: 0.019809134304523468, SNR: 5.383466720581055\n",
      "Epoch [01/25], Step [600/1803], Loss: 0.018589459359645844, SNR: 5.510369300842285\n",
      "Epoch [01/25], Step [700/1803], Loss: 0.018613435328006744, SNR: 6.368080139160156\n",
      "Epoch [01/25], Step [800/1803], Loss: 0.015867672860622406, SNR: 6.935920715332031\n",
      "Epoch [01/25], Step [900/1803], Loss: 0.015716083347797394, SNR: 6.467394828796387\n",
      "Epoch [01/25], Step [1000/1803], Loss: 0.01548947673290968, SNR: 7.03093957901001\n",
      "Epoch [01/25], Step [1100/1803], Loss: 0.013291444629430771, SNR: 9.063199043273926\n",
      "Epoch [01/25], Step [1200/1803], Loss: 0.02539989724755287, SNR: 7.106131553649902\n",
      "Epoch [01/25], Step [1300/1803], Loss: 0.015494509600102901, SNR: 9.401174545288086\n",
      "Epoch [01/25], Step [1400/1803], Loss: 0.013801977038383484, SNR: 8.151789665222168\n",
      "Epoch [01/25], Step [1500/1803], Loss: 0.013401098549365997, SNR: 8.384085655212402\n",
      "Epoch [01/25], Step [1600/1803], Loss: 0.011430235579609871, SNR: 9.895992279052734\n",
      "Epoch [01/25], Step [1700/1803], Loss: 0.01118486188352108, SNR: 8.767632484436035\n",
      "Epoch [01/25], Step [1800/1803], Loss: 0.01032443717122078, SNR: 9.54713249206543\n",
      ".:. Training metrics = Loss: 0.021049723926744444, SNR: 5.879201173712077\n",
      ".:. Validation metrics = Loss: 0.012292125851016406, SNR: 9.624725198783562\n",
      "Epoch [02/25], Step [100/1803], Loss: 0.012155996635556221, SNR: 10.447235107421875\n",
      "Epoch [02/25], Step [200/1803], Loss: 0.018503643572330475, SNR: 8.761223793029785\n",
      "Epoch [02/25], Step [300/1803], Loss: 0.011713987216353416, SNR: 10.582249641418457\n",
      "Epoch [02/25], Step [400/1803], Loss: 0.012117335572838783, SNR: 10.636838912963867\n",
      "Epoch [02/25], Step [500/1803], Loss: 0.013961678370833397, SNR: 11.255178451538086\n",
      "Epoch [02/25], Step [600/1803], Loss: 0.011446445249021053, SNR: 10.864933967590332\n",
      "Epoch [02/25], Step [700/1803], Loss: 0.009736735373735428, SNR: 10.054285049438477\n",
      "Epoch [02/25], Step [800/1803], Loss: 0.011700356379151344, SNR: 10.038208961486816\n",
      "Epoch [02/25], Step [900/1803], Loss: 0.009942194446921349, SNR: 10.673725128173828\n",
      "Epoch [02/25], Step [1000/1803], Loss: 0.013394924812018871, SNR: 10.137167930603027\n",
      "Epoch [02/25], Step [1100/1803], Loss: 0.01155684981495142, SNR: 10.172188758850098\n",
      "Epoch [02/25], Step [1200/1803], Loss: 0.014475305564701557, SNR: 10.86338996887207\n",
      "Epoch [02/25], Step [1300/1803], Loss: 0.008681203238666058, SNR: 11.399320602416992\n",
      "Epoch [02/25], Step [1400/1803], Loss: 0.008641939610242844, SNR: 11.666299819946289\n",
      "Epoch [02/25], Step [1500/1803], Loss: 0.015402136370539665, SNR: 10.843887329101562\n",
      "Epoch [02/25], Step [1600/1803], Loss: 0.010239580646157265, SNR: 11.540239334106445\n",
      "Epoch [02/25], Step [1700/1803], Loss: 0.010100603103637695, SNR: 11.795494079589844\n",
      "Epoch [02/25], Step [1800/1803], Loss: 0.012174295261502266, SNR: 11.090084075927734\n",
      ".:. Training metrics = Loss: 0.011974234826436017, SNR: 10.481571929589311\n",
      ".:. Validation metrics = Loss: 0.010076350159056365, SNR: 11.583172541136339\n",
      "Epoch [03/25], Step [100/1803], Loss: 0.009335152804851532, SNR: 11.856046676635742\n",
      "Epoch [03/25], Step [200/1803], Loss: 0.010046104900538921, SNR: 11.826295852661133\n",
      "Epoch [03/25], Step [300/1803], Loss: 0.01046048291027546, SNR: 12.23015308380127\n",
      "Epoch [03/25], Step [400/1803], Loss: 0.009721429087221622, SNR: 11.515933990478516\n",
      "Epoch [03/25], Step [500/1803], Loss: 0.010736473836004734, SNR: 11.15838623046875\n",
      "Epoch [03/25], Step [600/1803], Loss: 0.012601136229932308, SNR: 11.107928276062012\n",
      "Epoch [03/25], Step [700/1803], Loss: 0.012232156470417976, SNR: 10.848479270935059\n",
      "Epoch [03/25], Step [800/1803], Loss: 0.009792070835828781, SNR: 12.195119857788086\n",
      "Epoch [03/25], Step [900/1803], Loss: 0.00911057647317648, SNR: 12.382490158081055\n",
      "Epoch [03/25], Step [1000/1803], Loss: 0.012343263253569603, SNR: 11.69698715209961\n",
      "Epoch [03/25], Step [1100/1803], Loss: 0.009257961995899677, SNR: 11.949018478393555\n",
      "Epoch [03/25], Step [1200/1803], Loss: 0.009760051034390926, SNR: 12.32728385925293\n",
      "Epoch [03/25], Step [1300/1803], Loss: 0.009431774728000164, SNR: 13.196369171142578\n",
      "Epoch [03/25], Step [1400/1803], Loss: 0.009371936321258545, SNR: 12.86606502532959\n",
      "Epoch [03/25], Step [1500/1803], Loss: 0.011945183388888836, SNR: 12.082799911499023\n",
      "Epoch [03/25], Step [1600/1803], Loss: 0.011081637814640999, SNR: 11.856388092041016\n",
      "Epoch [03/25], Step [1700/1803], Loss: 0.006921907886862755, SNR: 13.699621200561523\n",
      "Epoch [03/25], Step [1800/1803], Loss: 0.007996332831680775, SNR: 12.413280487060547\n",
      ".:. Training metrics = Loss: 0.01045277854923406, SNR: 11.76348870362491\n",
      ".:. Validation metrics = Loss: 0.009027088377738055, SNR: 12.576239767480672\n",
      "Epoch [04/25], Step [100/1803], Loss: 0.008953621610999107, SNR: 12.258858680725098\n",
      "Epoch [04/25], Step [200/1803], Loss: 0.007685989141464233, SNR: 12.07457447052002\n",
      "Epoch [04/25], Step [300/1803], Loss: 0.0069290464743971825, SNR: 12.187440872192383\n",
      "Epoch [04/25], Step [400/1803], Loss: 0.007771839387714863, SNR: 13.07415771484375\n",
      "Epoch [04/25], Step [500/1803], Loss: 0.011593219824135303, SNR: 11.94421100616455\n",
      "Epoch [04/25], Step [600/1803], Loss: 0.009699994698166847, SNR: 11.411273002624512\n",
      "Epoch [04/25], Step [700/1803], Loss: 0.009726179763674736, SNR: 12.484298706054688\n",
      "Epoch [04/25], Step [800/1803], Loss: 0.012269804254174232, SNR: 11.506402015686035\n",
      "Epoch [04/25], Step [900/1803], Loss: 0.007234628312289715, SNR: 13.767650604248047\n",
      "Epoch [04/25], Step [1000/1803], Loss: 0.009240960702300072, SNR: 12.441903114318848\n",
      "Epoch [04/25], Step [1100/1803], Loss: 0.008779546245932579, SNR: 12.62993049621582\n",
      "Epoch [04/25], Step [1200/1803], Loss: 0.008504990488290787, SNR: 12.786727905273438\n",
      "Epoch [04/25], Step [1300/1803], Loss: 0.013382875360548496, SNR: 12.11358642578125\n",
      "Epoch [04/25], Step [1400/1803], Loss: 0.010369820520281792, SNR: 13.38884162902832\n",
      "Epoch [04/25], Step [1500/1803], Loss: 0.007835117168724537, SNR: 12.61066722869873\n",
      "Epoch [04/25], Step [1600/1803], Loss: 0.008025053888559341, SNR: 12.774435997009277\n",
      "Epoch [04/25], Step [1700/1803], Loss: 0.00813782587647438, SNR: 13.016027450561523\n",
      "Epoch [04/25], Step [1800/1803], Loss: 0.010490356013178825, SNR: 13.219381332397461\n",
      ".:. Training metrics = Loss: 0.00970682005568713, SNR: 12.409295206100701\n",
      ".:. Validation metrics = Loss: 0.00857253932004661, SNR: 12.991294683523513\n",
      "Epoch [05/25], Step [100/1803], Loss: 0.009212570264935493, SNR: 12.622272491455078\n",
      "Epoch [05/25], Step [200/1803], Loss: 0.011066166684031487, SNR: 12.42758560180664\n",
      "Epoch [05/25], Step [300/1803], Loss: 0.00948936864733696, SNR: 12.893224716186523\n",
      "Epoch [05/25], Step [400/1803], Loss: 0.006544385105371475, SNR: 14.585043907165527\n",
      "Epoch [05/25], Step [500/1803], Loss: 0.007749684154987335, SNR: 13.498210906982422\n",
      "Epoch [05/25], Step [600/1803], Loss: 0.007522015832364559, SNR: 14.196281433105469\n",
      "Epoch [05/25], Step [700/1803], Loss: 0.008291597478091717, SNR: 13.112151145935059\n",
      "Epoch [05/25], Step [800/1803], Loss: 0.008817000314593315, SNR: 14.304301261901855\n",
      "Epoch [05/25], Step [900/1803], Loss: 0.009285373613238335, SNR: 14.164773941040039\n",
      "Epoch [05/25], Step [1000/1803], Loss: 0.009414519183337688, SNR: 13.090853691101074\n",
      "Epoch [05/25], Step [1100/1803], Loss: 0.009398950263857841, SNR: 13.140321731567383\n",
      "Epoch [05/25], Step [1200/1803], Loss: 0.010734893381595612, SNR: 11.751314163208008\n",
      "Epoch [05/25], Step [1300/1803], Loss: 0.007310614921152592, SNR: 13.474435806274414\n",
      "Epoch [05/25], Step [1400/1803], Loss: 0.010449115186929703, SNR: 13.147805213928223\n",
      "Epoch [05/25], Step [1500/1803], Loss: 0.00863930955529213, SNR: 14.234235763549805\n",
      "Epoch [05/25], Step [1600/1803], Loss: 0.008953871205449104, SNR: 12.581116676330566\n",
      "Epoch [05/25], Step [1700/1803], Loss: 0.00928557850420475, SNR: 12.856256484985352\n",
      "Epoch [05/25], Step [1800/1803], Loss: 0.008200673386454582, SNR: 13.576080322265625\n",
      ".:. Training metrics = Loss: 0.009209242236757767, SNR: 12.83884656453679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:. Validation metrics = Loss: 0.008371790282820401, SNR: 13.350174196117676\n",
      "Epoch [06/25], Step [100/1803], Loss: 0.009224780835211277, SNR: 12.15718936920166\n",
      "Epoch [06/25], Step [200/1803], Loss: 0.012171165086328983, SNR: 11.868850708007812\n",
      "Epoch [06/25], Step [300/1803], Loss: 0.007633144035935402, SNR: 13.677124977111816\n",
      "Epoch [06/25], Step [400/1803], Loss: 0.0076002017594873905, SNR: 13.16380500793457\n",
      "Epoch [06/25], Step [500/1803], Loss: 0.006863073445856571, SNR: 13.583941459655762\n",
      "Epoch [06/25], Step [600/1803], Loss: 0.012539981864392757, SNR: 11.240049362182617\n",
      "Epoch [06/25], Step [700/1803], Loss: 0.009719420224428177, SNR: 12.21314811706543\n",
      "Epoch [06/25], Step [800/1803], Loss: 0.008010799996554852, SNR: 14.272464752197266\n",
      "Epoch [06/25], Step [900/1803], Loss: 0.011484164744615555, SNR: 12.89985466003418\n",
      "Epoch [06/25], Step [1000/1803], Loss: 0.00862180907279253, SNR: 13.251618385314941\n",
      "Epoch [06/25], Step [1100/1803], Loss: 0.006604962050914764, SNR: 13.54355239868164\n",
      "Epoch [06/25], Step [1200/1803], Loss: 0.008339827880263329, SNR: 13.483264923095703\n",
      "Epoch [06/25], Step [1300/1803], Loss: 0.008615387603640556, SNR: 12.592728614807129\n",
      "Epoch [06/25], Step [1400/1803], Loss: 0.007031462620943785, SNR: 12.755516052246094\n",
      "Epoch [06/25], Step [1500/1803], Loss: 0.010743224993348122, SNR: 12.607769966125488\n",
      "Epoch [06/25], Step [1600/1803], Loss: 0.008350917138159275, SNR: 13.574257850646973\n",
      "Epoch [06/25], Step [1700/1803], Loss: 0.008257035166025162, SNR: 13.103492736816406\n",
      "Epoch [06/25], Step [1800/1803], Loss: 0.008576865307986736, SNR: 13.222953796386719\n",
      ".:. Training metrics = Loss: 0.008831536153713048, SNR: 13.150718934303093\n",
      ".:. Validation metrics = Loss: 0.008000014929647201, SNR: 13.476977126871395\n",
      "Epoch [07/25], Step [100/1803], Loss: 0.009321963414549828, SNR: 13.04263687133789\n",
      "Epoch [07/25], Step [200/1803], Loss: 0.010287635959684849, SNR: 13.206768035888672\n",
      "Epoch [07/25], Step [300/1803], Loss: 0.007931162603199482, SNR: 13.917832374572754\n",
      "Epoch [07/25], Step [400/1803], Loss: 0.008706001564860344, SNR: 13.773807525634766\n",
      "Epoch [07/25], Step [500/1803], Loss: 0.008880466222763062, SNR: 13.060810089111328\n",
      "Epoch [07/25], Step [600/1803], Loss: 0.0073477476835250854, SNR: 13.758207321166992\n",
      "Epoch [07/25], Step [700/1803], Loss: 0.010466861538589, SNR: 12.727688789367676\n",
      "Epoch [07/25], Step [800/1803], Loss: 0.01180196087807417, SNR: 12.304160118103027\n",
      "Epoch [07/25], Step [900/1803], Loss: 0.008579347282648087, SNR: 13.162437438964844\n",
      "Epoch [07/25], Step [1000/1803], Loss: 0.008567584678530693, SNR: 12.463973045349121\n",
      "Epoch [07/25], Step [1100/1803], Loss: 0.009464222937822342, SNR: 13.063302040100098\n",
      "Epoch [07/25], Step [1200/1803], Loss: 0.008114997297525406, SNR: 13.255833625793457\n",
      "Epoch [07/25], Step [1300/1803], Loss: 0.007398658432066441, SNR: 13.150035858154297\n",
      "Epoch [07/25], Step [1400/1803], Loss: 0.009735037572681904, SNR: 13.49587345123291\n",
      "Epoch [07/25], Step [1500/1803], Loss: 0.008554957807064056, SNR: 13.668999671936035\n",
      "Epoch [07/25], Step [1600/1803], Loss: 0.0082854013890028, SNR: 13.78078842163086\n",
      "Epoch [07/25], Step [1700/1803], Loss: 0.011871472001075745, SNR: 11.317031860351562\n",
      "Epoch [07/25], Step [1800/1803], Loss: 0.007342745549976826, SNR: 14.04109001159668\n",
      ".:. Training metrics = Loss: 0.008577074495311891, SNR: 13.377224023003425\n",
      ".:. Validation metrics = Loss: 0.007768475634327439, SNR: 13.851406558989469\n",
      "Epoch [08/25], Step [100/1803], Loss: 0.008260659873485565, SNR: 13.807941436767578\n",
      "Epoch [08/25], Step [200/1803], Loss: 0.006466298829764128, SNR: 13.6404447555542\n",
      "Epoch [08/25], Step [300/1803], Loss: 0.0072083016857504845, SNR: 14.054756164550781\n",
      "Epoch [08/25], Step [400/1803], Loss: 0.006937331520020962, SNR: 14.160076141357422\n",
      "Epoch [08/25], Step [500/1803], Loss: 0.006461828947067261, SNR: 13.640541076660156\n",
      "Epoch [08/25], Step [600/1803], Loss: 0.00725975725799799, SNR: 12.843924522399902\n",
      "Epoch [08/25], Step [700/1803], Loss: 0.007164347916841507, SNR: 14.76661491394043\n",
      "Epoch [08/25], Step [800/1803], Loss: 0.008411170914769173, SNR: 13.539846420288086\n",
      "Epoch [08/25], Step [900/1803], Loss: 0.007868502289056778, SNR: 12.58332347869873\n",
      "Epoch [08/25], Step [1000/1803], Loss: 0.006943578831851482, SNR: 14.07944107055664\n",
      "Epoch [08/25], Step [1100/1803], Loss: 0.008723746053874493, SNR: 14.319768905639648\n",
      "Epoch [08/25], Step [1200/1803], Loss: 0.008206158876419067, SNR: 13.085006713867188\n",
      "Epoch [08/25], Step [1300/1803], Loss: 0.01000475324690342, SNR: 13.58940315246582\n",
      "Epoch [08/25], Step [1400/1803], Loss: 0.008145240135490894, SNR: 13.48565673828125\n",
      "Epoch [08/25], Step [1500/1803], Loss: 0.008782856166362762, SNR: 14.477239608764648\n",
      "Epoch [08/25], Step [1600/1803], Loss: 0.010758365504443645, SNR: 12.706888198852539\n",
      "Epoch [08/25], Step [1700/1803], Loss: 0.008643527515232563, SNR: 12.955491065979004\n",
      "Epoch [08/25], Step [1800/1803], Loss: 0.008555554784834385, SNR: 13.949525833129883\n",
      ".:. Training metrics = Loss: 0.008359755293511911, SNR: 13.571527075125154\n",
      ".:. Validation metrics = Loss: 0.007617631823926005, SNR: 13.871604598851722\n",
      "Epoch [09/25], Step [100/1803], Loss: 0.007900068536400795, SNR: 13.310362815856934\n",
      "Epoch [09/25], Step [200/1803], Loss: 0.007293172180652618, SNR: 13.943960189819336\n",
      "Epoch [09/25], Step [300/1803], Loss: 0.012062727473676205, SNR: 13.031631469726562\n",
      "Epoch [09/25], Step [400/1803], Loss: 0.006273001432418823, SNR: 13.751849174499512\n",
      "Epoch [09/25], Step [500/1803], Loss: 0.008708690293133259, SNR: 13.327607154846191\n",
      "Epoch [09/25], Step [600/1803], Loss: 0.0081262718886137, SNR: 12.690203666687012\n",
      "Epoch [09/25], Step [700/1803], Loss: 0.009343564510345459, SNR: 13.80354118347168\n",
      "Epoch [09/25], Step [800/1803], Loss: 0.007949799299240112, SNR: 13.482803344726562\n",
      "Epoch [09/25], Step [900/1803], Loss: 0.007372776046395302, SNR: 15.03515338897705\n",
      "Epoch [09/25], Step [1000/1803], Loss: 0.011229593306779861, SNR: 12.80531120300293\n",
      "Epoch [09/25], Step [1100/1803], Loss: 0.00817315373569727, SNR: 13.028437614440918\n",
      "Epoch [09/25], Step [1200/1803], Loss: 0.008983445353806019, SNR: 12.977925300598145\n",
      "Epoch [09/25], Step [1300/1803], Loss: 0.0071283020079135895, SNR: 13.63052749633789\n",
      "Epoch [09/25], Step [1400/1803], Loss: 0.011334199458360672, SNR: 13.277379035949707\n",
      "Epoch [09/25], Step [1500/1803], Loss: 0.006541123613715172, SNR: 15.275676727294922\n",
      "Epoch [09/25], Step [1600/1803], Loss: 0.006754305679351091, SNR: 13.904059410095215\n",
      "Epoch [09/25], Step [1700/1803], Loss: 0.008098222315311432, SNR: 13.262596130371094\n",
      "Epoch [09/25], Step [1800/1803], Loss: 0.006631060503423214, SNR: 14.641282081604004\n",
      ".:. Training metrics = Loss: 0.008207004032699037, SNR: 13.722611656110923\n",
      ".:. Validation metrics = Loss: 0.007441161351396164, SNR: 14.187691798761263\n",
      "Epoch [10/25], Step [100/1803], Loss: 0.006604629103094339, SNR: 13.23729133605957\n",
      "Epoch [10/25], Step [200/1803], Loss: 0.008510448038578033, SNR: 14.634645462036133\n",
      "Epoch [10/25], Step [300/1803], Loss: 0.006869303062558174, SNR: 14.560608863830566\n",
      "Epoch [10/25], Step [400/1803], Loss: 0.013699316419661045, SNR: 12.57693862915039\n",
      "Epoch [10/25], Step [500/1803], Loss: 0.008476793766021729, SNR: 12.808759689331055\n",
      "Epoch [10/25], Step [600/1803], Loss: 0.008454583585262299, SNR: 13.520578384399414\n",
      "Epoch [10/25], Step [700/1803], Loss: 0.006091560237109661, SNR: 15.247936248779297\n",
      "Epoch [10/25], Step [800/1803], Loss: 0.007132085971534252, SNR: 14.6317777633667\n",
      "Epoch [10/25], Step [900/1803], Loss: 0.007772768847644329, SNR: 14.093790054321289\n",
      "Epoch [10/25], Step [1000/1803], Loss: 0.0058189439587295055, SNR: 14.437095642089844\n",
      "Epoch [10/25], Step [1100/1803], Loss: 0.00823582150042057, SNR: 13.679195404052734\n",
      "Epoch [10/25], Step [1200/1803], Loss: 0.00822516344487667, SNR: 13.909913063049316\n",
      "Epoch [10/25], Step [1300/1803], Loss: 0.010355625301599503, SNR: 13.844430923461914\n",
      "Epoch [10/25], Step [1400/1803], Loss: 0.007129349745810032, SNR: 15.420037269592285\n",
      "Epoch [10/25], Step [1500/1803], Loss: 0.00648113526403904, SNR: 15.046208381652832\n",
      "Epoch [10/25], Step [1600/1803], Loss: 0.0077619245275855064, SNR: 13.453643798828125\n",
      "Epoch [10/25], Step [1700/1803], Loss: 0.007582828402519226, SNR: 14.096407890319824\n",
      "Epoch [10/25], Step [1800/1803], Loss: 0.009174825623631477, SNR: 13.335657119750977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:. Training metrics = Loss: 0.008063677168270113, SNR: 13.862511455890784\n",
      ".:. Validation metrics = Loss: 0.007424662694141872, SNR: 14.075312879532616\n",
      "Epoch [11/25], Step [100/1803], Loss: 0.007255478762090206, SNR: 13.703855514526367\n",
      "Epoch [11/25], Step [200/1803], Loss: 0.007444534916430712, SNR: 14.320298194885254\n",
      "Epoch [11/25], Step [300/1803], Loss: 0.0077450755052268505, SNR: 13.525017738342285\n",
      "Epoch [11/25], Step [400/1803], Loss: 0.007131774909794331, SNR: 14.3926420211792\n",
      "Epoch [11/25], Step [500/1803], Loss: 0.008541376329958439, SNR: 13.28829574584961\n",
      "Epoch [11/25], Step [600/1803], Loss: 0.0077815307304263115, SNR: 13.812055587768555\n",
      "Epoch [11/25], Step [700/1803], Loss: 0.008790146559476852, SNR: 13.666913986206055\n",
      "Epoch [11/25], Step [800/1803], Loss: 0.008046318776905537, SNR: 13.962971687316895\n",
      "Epoch [11/25], Step [900/1803], Loss: 0.007004409097135067, SNR: 13.739261627197266\n",
      "Epoch [11/25], Step [1000/1803], Loss: 0.009479578584432602, SNR: 13.467211723327637\n",
      "Epoch [11/25], Step [1100/1803], Loss: 0.010425176471471786, SNR: 12.959885597229004\n",
      "Epoch [11/25], Step [1200/1803], Loss: 0.008115548640489578, SNR: 12.936615943908691\n",
      "Epoch [11/25], Step [1300/1803], Loss: 0.007993667386472225, SNR: 13.806407928466797\n",
      "Epoch [11/25], Step [1400/1803], Loss: 0.006260495632886887, SNR: 14.19382095336914\n",
      "Epoch [11/25], Step [1500/1803], Loss: 0.00653167674317956, SNR: 14.055588722229004\n",
      "Epoch [11/25], Step [1600/1803], Loss: 0.00681737344712019, SNR: 14.479772567749023\n",
      "Epoch [11/25], Step [1700/1803], Loss: 0.008147899061441422, SNR: 12.906177520751953\n",
      "Epoch [11/25], Step [1800/1803], Loss: 0.007110564038157463, SNR: 13.676446914672852\n",
      ".:. Training metrics = Loss: 0.007950528926858423, SNR: 13.979512842804604\n",
      ".:. Validation metrics = Loss: 0.007378045104235151, SNR: 14.206628357282677\n",
      "Epoch [12/25], Step [100/1803], Loss: 0.007153174839913845, SNR: 14.781990051269531\n",
      "Epoch [12/25], Step [200/1803], Loss: 0.009703325107693672, SNR: 13.065093994140625\n",
      "Epoch [12/25], Step [300/1803], Loss: 0.007159722037613392, SNR: 15.27236557006836\n",
      "Epoch [12/25], Step [400/1803], Loss: 0.01256640162318945, SNR: 12.726806640625\n",
      "Epoch [12/25], Step [500/1803], Loss: 0.008817341178655624, SNR: 13.225847244262695\n",
      "Epoch [12/25], Step [600/1803], Loss: 0.0068579986691474915, SNR: 14.873781204223633\n",
      "Epoch [12/25], Step [700/1803], Loss: 0.00767760444432497, SNR: 13.245859146118164\n",
      "Epoch [12/25], Step [800/1803], Loss: 0.009660315699875355, SNR: 13.937259674072266\n",
      "Epoch [12/25], Step [900/1803], Loss: 0.0074401721358299255, SNR: 13.686721801757812\n",
      "Epoch [12/25], Step [1000/1803], Loss: 0.005489627830684185, SNR: 15.661999702453613\n",
      "Epoch [12/25], Step [1100/1803], Loss: 0.010728452354669571, SNR: 13.047666549682617\n",
      "Epoch [12/25], Step [1200/1803], Loss: 0.008062235079705715, SNR: 13.586405754089355\n",
      "Epoch [12/25], Step [1300/1803], Loss: 0.0077073597349226475, SNR: 14.022613525390625\n",
      "Epoch [12/25], Step [1400/1803], Loss: 0.007915100082755089, SNR: 14.327080726623535\n",
      "Epoch [12/25], Step [1500/1803], Loss: 0.007796442601829767, SNR: 13.621482849121094\n",
      "Epoch [12/25], Step [1600/1803], Loss: 0.008493823930621147, SNR: 14.48275375366211\n",
      "Epoch [12/25], Step [1700/1803], Loss: 0.006283599883317947, SNR: 14.71245002746582\n",
      "Epoch [12/25], Step [1800/1803], Loss: 0.009103920310735703, SNR: 13.950155258178711\n",
      ".:. Training metrics = Loss: 0.007839073318885519, SNR: 14.09657215867882\n",
      ".:. Validation metrics = Loss: 0.007344169112986963, SNR: 14.260175518307285\n",
      "Epoch [13/25], Step [100/1803], Loss: 0.00878128968179226, SNR: 13.086040496826172\n",
      "Epoch [13/25], Step [200/1803], Loss: 0.012518011033535004, SNR: 13.24295425415039\n",
      "Epoch [13/25], Step [300/1803], Loss: 0.0069852564483881, SNR: 15.31045913696289\n",
      "Epoch [13/25], Step [400/1803], Loss: 0.008878331631422043, SNR: 13.495031356811523\n",
      "Epoch [13/25], Step [500/1803], Loss: 0.008172156289219856, SNR: 14.759418487548828\n",
      "Epoch [13/25], Step [600/1803], Loss: 0.006760316900908947, SNR: 15.535807609558105\n",
      "Epoch [13/25], Step [700/1803], Loss: 0.008233102038502693, SNR: 14.759397506713867\n",
      "Epoch [13/25], Step [800/1803], Loss: 0.006843741983175278, SNR: 14.107601165771484\n",
      "Epoch [13/25], Step [900/1803], Loss: 0.006399823352694511, SNR: 14.80720043182373\n",
      "Epoch [13/25], Step [1000/1803], Loss: 0.0067373113706707954, SNR: 14.924792289733887\n",
      "Epoch [13/25], Step [1100/1803], Loss: 0.007724880240857601, SNR: 14.236488342285156\n",
      "Epoch [13/25], Step [1200/1803], Loss: 0.010023118928074837, SNR: 13.968755722045898\n",
      "Epoch [13/25], Step [1300/1803], Loss: 0.009000049903988838, SNR: 13.329431533813477\n",
      "Epoch [13/25], Step [1400/1803], Loss: 0.008528489619493484, SNR: 14.359953880310059\n",
      "Epoch [13/25], Step [1500/1803], Loss: 0.009929828345775604, SNR: 13.627399444580078\n",
      "Epoch [13/25], Step [1600/1803], Loss: 0.00896223820745945, SNR: 14.232159614562988\n",
      "Epoch [13/25], Step [1700/1803], Loss: 0.007077231537550688, SNR: 13.47441291809082\n",
      "Epoch [13/25], Step [1800/1803], Loss: 0.006503860931843519, SNR: 14.711427688598633\n",
      ".:. Training metrics = Loss: 0.007766295737739052, SNR: 14.181290972062927\n",
      ".:. Validation metrics = Loss: 0.007313453589404222, SNR: 14.324818353115708\n",
      "Epoch [14/25], Step [100/1803], Loss: 0.008498644456267357, SNR: 13.422672271728516\n",
      "Epoch [14/25], Step [200/1803], Loss: 0.006307438015937805, SNR: 14.27060317993164\n",
      "Epoch [14/25], Step [300/1803], Loss: 0.009527027606964111, SNR: 14.429216384887695\n",
      "Epoch [14/25], Step [400/1803], Loss: 0.007254206109791994, SNR: 14.553960800170898\n",
      "Epoch [14/25], Step [500/1803], Loss: 0.008287747390568256, SNR: 14.094893455505371\n",
      "Epoch [14/25], Step [600/1803], Loss: 0.006964918226003647, SNR: 15.068304061889648\n",
      "Epoch [14/25], Step [700/1803], Loss: 0.00689421221613884, SNR: 14.376595497131348\n",
      "Epoch [14/25], Step [800/1803], Loss: 0.00791163370013237, SNR: 13.771476745605469\n",
      "Epoch [14/25], Step [900/1803], Loss: 0.006501218769699335, SNR: 15.719670295715332\n",
      "Epoch [14/25], Step [1000/1803], Loss: 0.006978485733270645, SNR: 14.2053861618042\n",
      "Epoch [14/25], Step [1100/1803], Loss: 0.007571743801236153, SNR: 14.317204475402832\n",
      "Epoch [14/25], Step [1200/1803], Loss: 0.007342691998928785, SNR: 15.255363464355469\n",
      "Epoch [14/25], Step [1300/1803], Loss: 0.00865620095282793, SNR: 14.544804573059082\n",
      "Epoch [14/25], Step [1400/1803], Loss: 0.006975072436034679, SNR: 15.10460090637207\n",
      "Epoch [14/25], Step [1500/1803], Loss: 0.007176381070166826, SNR: 14.546669006347656\n",
      "Epoch [14/25], Step [1600/1803], Loss: 0.00660603865981102, SNR: 14.675212860107422\n",
      "Epoch [14/25], Step [1700/1803], Loss: 0.006033881567418575, SNR: 14.558401107788086\n",
      "Epoch [14/25], Step [1800/1803], Loss: 0.00722222775220871, SNR: 13.55021858215332\n",
      ".:. Training metrics = Loss: 0.007684675907395994, SNR: 14.275836850697441\n",
      ".:. Validation metrics = Loss: 0.007146174819434061, SNR: 14.479041345218477\n",
      "Epoch [15/25], Step [100/1803], Loss: 0.005985287018120289, SNR: 15.661731719970703\n",
      "Epoch [15/25], Step [200/1803], Loss: 0.006928467191755772, SNR: 14.581539154052734\n",
      "Epoch [15/25], Step [300/1803], Loss: 0.006135639268904924, SNR: 14.561759948730469\n",
      "Epoch [15/25], Step [400/1803], Loss: 0.007300829514861107, SNR: 14.190401077270508\n",
      "Epoch [15/25], Step [500/1803], Loss: 0.006976527161896229, SNR: 14.255271911621094\n",
      "Epoch [15/25], Step [600/1803], Loss: 0.007719106040894985, SNR: 14.222956657409668\n",
      "Epoch [15/25], Step [700/1803], Loss: 0.006373835727572441, SNR: 14.50174617767334\n",
      "Epoch [15/25], Step [800/1803], Loss: 0.010887736454606056, SNR: 13.916900634765625\n",
      "Epoch [15/25], Step [900/1803], Loss: 0.006596848834306002, SNR: 14.5675048828125\n",
      "Epoch [15/25], Step [1000/1803], Loss: 0.008249662816524506, SNR: 14.426923751831055\n",
      "Epoch [15/25], Step [1100/1803], Loss: 0.008135532960295677, SNR: 14.080365180969238\n",
      "Epoch [15/25], Step [1200/1803], Loss: 0.007226281799376011, SNR: 15.014904022216797\n",
      "Epoch [15/25], Step [1300/1803], Loss: 0.009898371063172817, SNR: 14.060627937316895\n",
      "Epoch [15/25], Step [1400/1803], Loss: 0.006895145401358604, SNR: 14.650291442871094\n",
      "Epoch [15/25], Step [1500/1803], Loss: 0.006261896807700396, SNR: 14.532693862915039\n",
      "Epoch [15/25], Step [1600/1803], Loss: 0.009052842855453491, SNR: 12.979924201965332\n",
      "Epoch [15/25], Step [1700/1803], Loss: 0.006827197037637234, SNR: 15.194562911987305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Step [1800/1803], Loss: 0.006645298562943935, SNR: 14.492193222045898\n",
      ".:. Training metrics = Loss: 0.0076171674987117735, SNR: 14.353958064505576\n",
      ".:. Validation metrics = Loss: 0.007073291915960765, SNR: 14.647758429405457\n",
      "Epoch [16/25], Step [100/1803], Loss: 0.007100443355739117, SNR: 14.550176620483398\n",
      "Epoch [16/25], Step [200/1803], Loss: 0.009477062150835991, SNR: 13.616886138916016\n",
      "Epoch [16/25], Step [300/1803], Loss: 0.008549200370907784, SNR: 14.241193771362305\n",
      "Epoch [16/25], Step [400/1803], Loss: 0.008612385019659996, SNR: 15.144351959228516\n",
      "Epoch [16/25], Step [500/1803], Loss: 0.006178450305014849, SNR: 14.192558288574219\n",
      "Epoch [16/25], Step [600/1803], Loss: 0.006536804139614105, SNR: 14.490084648132324\n",
      "Epoch [16/25], Step [700/1803], Loss: 0.007985995151102543, SNR: 14.81401252746582\n",
      "Epoch [16/25], Step [800/1803], Loss: 0.006818071007728577, SNR: 15.161272048950195\n",
      "Epoch [16/25], Step [900/1803], Loss: 0.009024582803249359, SNR: 13.976608276367188\n",
      "Epoch [16/25], Step [1000/1803], Loss: 0.0075745051726698875, SNR: 14.378287315368652\n",
      "Epoch [16/25], Step [1100/1803], Loss: 0.006530488841235638, SNR: 13.392725944519043\n",
      "Epoch [16/25], Step [1200/1803], Loss: 0.006958097219467163, SNR: 14.103377342224121\n",
      "Epoch [16/25], Step [1300/1803], Loss: 0.006771744228899479, SNR: 15.760364532470703\n",
      "Epoch [16/25], Step [1400/1803], Loss: 0.006678569130599499, SNR: 14.410212516784668\n",
      "Epoch [16/25], Step [1500/1803], Loss: 0.007896646857261658, SNR: 14.808608055114746\n",
      "Epoch [16/25], Step [1600/1803], Loss: 0.009634945541620255, SNR: 13.984851837158203\n",
      "Epoch [16/25], Step [1700/1803], Loss: 0.007317504845559597, SNR: 14.849143028259277\n",
      "Epoch [16/25], Step [1800/1803], Loss: 0.00674604345113039, SNR: 15.22219467163086\n",
      ".:. Training metrics = Loss: 0.007540740009657298, SNR: 14.439196029959913\n",
      ".:. Validation metrics = Loss: 0.006985846969957422, SNR: 14.739445868448996\n",
      "Epoch [17/25], Step [100/1803], Loss: 0.011075122281908989, SNR: 12.813894271850586\n",
      "Epoch [17/25], Step [200/1803], Loss: 0.00777873769402504, SNR: 14.125066757202148\n",
      "Epoch [17/25], Step [300/1803], Loss: 0.00652646366506815, SNR: 15.496678352355957\n",
      "Epoch [17/25], Step [400/1803], Loss: 0.007438340224325657, SNR: 14.531915664672852\n",
      "Epoch [17/25], Step [500/1803], Loss: 0.006288830656558275, SNR: 15.235124588012695\n",
      "Epoch [17/25], Step [600/1803], Loss: 0.0081165237352252, SNR: 13.643241882324219\n",
      "Epoch [17/25], Step [700/1803], Loss: 0.008565635420382023, SNR: 14.04500675201416\n",
      "Epoch [17/25], Step [800/1803], Loss: 0.007007499225437641, SNR: 15.646719932556152\n",
      "Epoch [17/25], Step [900/1803], Loss: 0.006310291588306427, SNR: 15.457596778869629\n",
      "Epoch [17/25], Step [1000/1803], Loss: 0.0059945425018668175, SNR: 14.6857271194458\n",
      "Epoch [17/25], Step [1100/1803], Loss: 0.007125344127416611, SNR: 14.523797035217285\n",
      "Epoch [17/25], Step [1200/1803], Loss: 0.006141205318272114, SNR: 16.198246002197266\n",
      "Epoch [17/25], Step [1300/1803], Loss: 0.006902588531374931, SNR: 15.139896392822266\n",
      "Epoch [17/25], Step [1400/1803], Loss: 0.009422194212675095, SNR: 14.135248184204102\n",
      "Epoch [17/25], Step [1500/1803], Loss: 0.0067719463258981705, SNR: 14.294554710388184\n",
      "Epoch [17/25], Step [1600/1803], Loss: 0.006707317195832729, SNR: 15.486029624938965\n",
      "Epoch [17/25], Step [1700/1803], Loss: 0.006635374389588833, SNR: 14.695770263671875\n",
      "Epoch [17/25], Step [1800/1803], Loss: 0.0065497104078531265, SNR: 14.901250839233398\n",
      ".:. Training metrics = Loss: 0.007493565770139251, SNR: 14.498804833878342\n",
      ".:. Validation metrics = Loss: 0.006990258001368438, SNR: 14.695019332040273\n",
      "Epoch [18/25], Step [100/1803], Loss: 0.006015638820827007, SNR: 14.491659164428711\n",
      "Epoch [18/25], Step [200/1803], Loss: 0.008456189185380936, SNR: 14.981649398803711\n",
      "Epoch [18/25], Step [300/1803], Loss: 0.006829041056334972, SNR: 14.943418502807617\n",
      "Epoch [18/25], Step [400/1803], Loss: 0.006962180603295565, SNR: 14.298467636108398\n",
      "Epoch [18/25], Step [500/1803], Loss: 0.006530918646603823, SNR: 15.013742446899414\n",
      "Epoch [18/25], Step [600/1803], Loss: 0.007238910533487797, SNR: 14.794668197631836\n",
      "Epoch [18/25], Step [700/1803], Loss: 0.006922638975083828, SNR: 14.710844039916992\n",
      "Epoch [18/25], Step [800/1803], Loss: 0.006491953507065773, SNR: 14.883428573608398\n",
      "Epoch [18/25], Step [900/1803], Loss: 0.008886368945240974, SNR: 13.69247817993164\n",
      "Epoch [18/25], Step [1000/1803], Loss: 0.008386848494410515, SNR: 14.639305114746094\n",
      "Epoch [18/25], Step [1100/1803], Loss: 0.005982701666653156, SNR: 14.948587417602539\n",
      "Epoch [18/25], Step [1200/1803], Loss: 0.00692882901057601, SNR: 13.975516319274902\n",
      "Epoch [18/25], Step [1300/1803], Loss: 0.007345295511186123, SNR: 13.919221878051758\n",
      "Epoch [18/25], Step [1400/1803], Loss: 0.007427331060171127, SNR: 13.972092628479004\n",
      "Epoch [18/25], Step [1500/1803], Loss: 0.0083853118121624, SNR: 12.644746780395508\n",
      "Epoch [18/25], Step [1600/1803], Loss: 0.006122995633631945, SNR: 14.548645973205566\n",
      "Epoch [18/25], Step [1700/1803], Loss: 0.007584217935800552, SNR: 13.660345077514648\n",
      "Epoch [18/25], Step [1800/1803], Loss: 0.006577023304998875, SNR: 14.775705337524414\n",
      ".:. Training metrics = Loss: 0.007433913869632083, SNR: 14.566757634259893\n",
      ".:. Validation metrics = Loss: 0.007054813594513747, SNR: 14.642946091444838\n",
      "Epoch [19/25], Step [100/1803], Loss: 0.00665075471624732, SNR: 14.927452087402344\n",
      "Epoch [19/25], Step [200/1803], Loss: 0.007201538886874914, SNR: 14.95699691772461\n",
      "Epoch [19/25], Step [300/1803], Loss: 0.009171013720333576, SNR: 14.460159301757812\n",
      "Epoch [19/25], Step [400/1803], Loss: 0.007196605671197176, SNR: 14.129693984985352\n",
      "Epoch [19/25], Step [500/1803], Loss: 0.008933854289352894, SNR: 14.621827125549316\n",
      "Epoch [19/25], Step [600/1803], Loss: 0.007979771122336388, SNR: 13.686040878295898\n",
      "Epoch [19/25], Step [700/1803], Loss: 0.005777127109467983, SNR: 14.695075988769531\n",
      "Epoch [19/25], Step [800/1803], Loss: 0.005177156068384647, SNR: 16.770572662353516\n",
      "Epoch [19/25], Step [900/1803], Loss: 0.006325962953269482, SNR: 15.157434463500977\n",
      "Epoch [19/25], Step [1000/1803], Loss: 0.007218589540570974, SNR: 13.660530090332031\n",
      "Epoch [19/25], Step [1100/1803], Loss: 0.007342914119362831, SNR: 14.904518127441406\n",
      "Epoch [19/25], Step [1200/1803], Loss: 0.008215431123971939, SNR: 14.445394515991211\n",
      "Epoch [19/25], Step [1300/1803], Loss: 0.008288908749818802, SNR: 13.36662483215332\n",
      "Epoch [19/25], Step [1400/1803], Loss: 0.005252820905297995, SNR: 16.42247200012207\n",
      "Epoch [19/25], Step [1500/1803], Loss: 0.009478693827986717, SNR: 12.396389961242676\n",
      "Epoch [19/25], Step [1600/1803], Loss: 0.007133567240089178, SNR: 14.688569068908691\n",
      "Epoch [19/25], Step [1700/1803], Loss: 0.0075103058479726315, SNR: 13.61905288696289\n",
      "Epoch [19/25], Step [1800/1803], Loss: 0.007842417806386948, SNR: 14.93859577178955\n",
      ".:. Training metrics = Loss: 0.007386242486480957, SNR: 14.62773993167489\n",
      ".:. Validation metrics = Loss: 0.006939679898540357, SNR: 14.786397087230345\n",
      "Epoch [20/25], Step [100/1803], Loss: 0.0062238192185759544, SNR: 15.245288848876953\n",
      "Epoch [20/25], Step [200/1803], Loss: 0.008199533447623253, SNR: 13.600845336914062\n",
      "Epoch [20/25], Step [300/1803], Loss: 0.006143870763480663, SNR: 15.704627990722656\n",
      "Epoch [20/25], Step [400/1803], Loss: 0.006378069519996643, SNR: 15.55916690826416\n",
      "Epoch [20/25], Step [500/1803], Loss: 0.00740294111892581, SNR: 15.289263725280762\n",
      "Epoch [20/25], Step [600/1803], Loss: 0.011012526229023933, SNR: 15.185342788696289\n",
      "Epoch [20/25], Step [700/1803], Loss: 0.006816709879785776, SNR: 14.261812210083008\n",
      "Epoch [20/25], Step [800/1803], Loss: 0.008931290358304977, SNR: 13.801023483276367\n",
      "Epoch [20/25], Step [900/1803], Loss: 0.00566972978413105, SNR: 15.276729583740234\n",
      "Epoch [20/25], Step [1000/1803], Loss: 0.006211770698428154, SNR: 16.731857299804688\n",
      "Epoch [20/25], Step [1100/1803], Loss: 0.007910586893558502, SNR: 15.347429275512695\n",
      "Epoch [20/25], Step [1200/1803], Loss: 0.00762728089466691, SNR: 15.20930290222168\n",
      "Epoch [20/25], Step [1300/1803], Loss: 0.008280890062451363, SNR: 14.370321273803711\n",
      "Epoch [20/25], Step [1400/1803], Loss: 0.007080703042447567, SNR: 14.45272445678711\n",
      "Epoch [20/25], Step [1500/1803], Loss: 0.007172713987529278, SNR: 14.789973258972168\n",
      "Epoch [20/25], Step [1600/1803], Loss: 0.005791517440229654, SNR: 15.116329193115234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Step [1700/1803], Loss: 0.00654595298692584, SNR: 15.005887985229492\n",
      "Epoch [20/25], Step [1800/1803], Loss: 0.00725255161523819, SNR: 16.151918411254883\n",
      ".:. Training metrics = Loss: 0.007339780676939187, SNR: 14.683017405546291\n",
      ".:. Validation metrics = Loss: 0.0068998650323301046, SNR: 14.915724217339944\n",
      "Epoch [21/25], Step [100/1803], Loss: 0.007073031738400459, SNR: 14.040371894836426\n",
      "Epoch [21/25], Step [200/1803], Loss: 0.007418198045343161, SNR: 14.728482246398926\n",
      "Epoch [21/25], Step [300/1803], Loss: 0.009418309666216373, SNR: 13.526447296142578\n",
      "Epoch [21/25], Step [400/1803], Loss: 0.008951650001108646, SNR: 15.065353393554688\n",
      "Epoch [21/25], Step [500/1803], Loss: 0.006549696438014507, SNR: 14.781513214111328\n",
      "Epoch [21/25], Step [600/1803], Loss: 0.007419083267450333, SNR: 14.15644359588623\n",
      "Epoch [21/25], Step [700/1803], Loss: 0.007271800190210342, SNR: 15.082571029663086\n",
      "Epoch [21/25], Step [800/1803], Loss: 0.00723081873729825, SNR: 14.593706130981445\n",
      "Epoch [21/25], Step [900/1803], Loss: 0.007695632055401802, SNR: 14.5757417678833\n",
      "Epoch [21/25], Step [1000/1803], Loss: 0.005525018088519573, SNR: 15.144618034362793\n",
      "Epoch [21/25], Step [1100/1803], Loss: 0.006632315926253796, SNR: 14.393686294555664\n",
      "Epoch [21/25], Step [1200/1803], Loss: 0.005749265663325787, SNR: 16.143095016479492\n",
      "Epoch [21/25], Step [1300/1803], Loss: 0.009027428925037384, SNR: 14.448352813720703\n",
      "Epoch [21/25], Step [1400/1803], Loss: 0.006269409321248531, SNR: 17.159448623657227\n",
      "Epoch [21/25], Step [1500/1803], Loss: 0.006641239393502474, SNR: 13.577762603759766\n",
      "Epoch [21/25], Step [1600/1803], Loss: 0.006385845132172108, SNR: 14.879315376281738\n",
      "Epoch [21/25], Step [1700/1803], Loss: 0.0066862874664366245, SNR: 13.961299896240234\n",
      "Epoch [21/25], Step [1800/1803], Loss: 0.006064011715352535, SNR: 14.19614028930664\n",
      ".:. Training metrics = Loss: 0.007296813114291215, SNR: 14.738770132475866\n",
      ".:. Validation metrics = Loss: 0.006815774300616235, SNR: 14.958091812769403\n",
      "Epoch [22/25], Step [100/1803], Loss: 0.009984294883906841, SNR: 12.996192932128906\n",
      "Epoch [22/25], Step [200/1803], Loss: 0.00740868179127574, SNR: 14.436670303344727\n",
      "Epoch [22/25], Step [300/1803], Loss: 0.006225133314728737, SNR: 15.213338851928711\n",
      "Epoch [22/25], Step [400/1803], Loss: 0.00538295041769743, SNR: 15.649568557739258\n",
      "Epoch [22/25], Step [500/1803], Loss: 0.0055894325487315655, SNR: 16.13678741455078\n",
      "Epoch [22/25], Step [600/1803], Loss: 0.005531751550734043, SNR: 16.08559226989746\n",
      "Epoch [22/25], Step [700/1803], Loss: 0.007424641400575638, SNR: 14.462645530700684\n",
      "Epoch [22/25], Step [800/1803], Loss: 0.006528192199766636, SNR: 14.888696670532227\n",
      "Epoch [22/25], Step [900/1803], Loss: 0.006722607649862766, SNR: 14.591922760009766\n",
      "Epoch [22/25], Step [1000/1803], Loss: 0.0073297834023833275, SNR: 14.281097412109375\n",
      "Epoch [22/25], Step [1100/1803], Loss: 0.006593894213438034, SNR: 15.39107894897461\n",
      "Epoch [22/25], Step [1200/1803], Loss: 0.009129105135798454, SNR: 14.661909103393555\n",
      "Epoch [22/25], Step [1300/1803], Loss: 0.010192574001848698, SNR: 13.452104568481445\n",
      "Epoch [22/25], Step [1400/1803], Loss: 0.007307407911866903, SNR: 14.815411567687988\n",
      "Epoch [22/25], Step [1500/1803], Loss: 0.0070311641320586205, SNR: 14.24563217163086\n",
      "Epoch [22/25], Step [1600/1803], Loss: 0.006666506174951792, SNR: 14.602890014648438\n",
      "Epoch [22/25], Step [1700/1803], Loss: 0.005781461019068956, SNR: 15.06734561920166\n",
      "Epoch [22/25], Step [1800/1803], Loss: 0.009007102809846401, SNR: 14.700857162475586\n",
      ".:. Training metrics = Loss: 0.007259073832734245, SNR: 14.783561687627552\n",
      ".:. Validation metrics = Loss: 0.006917984924517834, SNR: 14.880177420681981\n",
      "Epoch [23/25], Step [100/1803], Loss: 0.007875293493270874, SNR: 16.05799102783203\n",
      "Epoch [23/25], Step [200/1803], Loss: 0.009078621864318848, SNR: 13.69940185546875\n",
      "Epoch [23/25], Step [300/1803], Loss: 0.007781441789120436, SNR: 14.9524507522583\n",
      "Epoch [23/25], Step [400/1803], Loss: 0.0054544853046536446, SNR: 15.953683853149414\n",
      "Epoch [23/25], Step [500/1803], Loss: 0.007845738902688026, SNR: 14.185647964477539\n",
      "Epoch [23/25], Step [600/1803], Loss: 0.006926028057932854, SNR: 15.369071960449219\n",
      "Epoch [23/25], Step [700/1803], Loss: 0.007579260040074587, SNR: 14.519923210144043\n",
      "Epoch [23/25], Step [800/1803], Loss: 0.009125517681241035, SNR: 14.229105949401855\n",
      "Epoch [23/25], Step [900/1803], Loss: 0.006228945218026638, SNR: 16.042247772216797\n",
      "Epoch [23/25], Step [1000/1803], Loss: 0.005389026831835508, SNR: 15.341683387756348\n",
      "Epoch [23/25], Step [1100/1803], Loss: 0.005866179242730141, SNR: 15.41041088104248\n",
      "Epoch [23/25], Step [1200/1803], Loss: 0.005980790592730045, SNR: 15.65189266204834\n",
      "Epoch [23/25], Step [1300/1803], Loss: 0.008160186931490898, SNR: 14.676107406616211\n",
      "Epoch [23/25], Step [1400/1803], Loss: 0.0066693443804979324, SNR: 14.844718933105469\n",
      "Epoch [23/25], Step [1500/1803], Loss: 0.006571468431502581, SNR: 14.066513061523438\n",
      "Epoch [23/25], Step [1600/1803], Loss: 0.006181908771395683, SNR: 16.17641258239746\n",
      "Epoch [23/25], Step [1700/1803], Loss: 0.006621464155614376, SNR: 15.43749713897705\n",
      "Epoch [23/25], Step [1800/1803], Loss: 0.0068252114579081535, SNR: 14.545902252197266\n",
      ".:. Training metrics = Loss: 0.007224890363066065, SNR: 14.831069816195967\n",
      ".:. Validation metrics = Loss: 0.006813305936540932, SNR: 14.988823327208536\n",
      "Epoch [24/25], Step [100/1803], Loss: 0.0089500080794096, SNR: 13.870122909545898\n",
      "Epoch [24/25], Step [200/1803], Loss: 0.006305396091192961, SNR: 14.26942253112793\n",
      "Epoch [24/25], Step [300/1803], Loss: 0.0062841856852173805, SNR: 14.978958129882812\n",
      "Epoch [24/25], Step [400/1803], Loss: 0.007150985766202211, SNR: 14.217300415039062\n",
      "Epoch [24/25], Step [500/1803], Loss: 0.0073809269815683365, SNR: 14.019110679626465\n",
      "Epoch [24/25], Step [600/1803], Loss: 0.006300388835370541, SNR: 15.517196655273438\n",
      "Epoch [24/25], Step [700/1803], Loss: 0.008364315144717693, SNR: 14.543577194213867\n",
      "Epoch [24/25], Step [800/1803], Loss: 0.005284977611154318, SNR: 16.784940719604492\n",
      "Epoch [24/25], Step [900/1803], Loss: 0.007105558644980192, SNR: 15.150480270385742\n",
      "Epoch [24/25], Step [1000/1803], Loss: 0.007460561580955982, SNR: 14.061800956726074\n",
      "Epoch [24/25], Step [1100/1803], Loss: 0.006236896850168705, SNR: 15.617504119873047\n",
      "Epoch [24/25], Step [1200/1803], Loss: 0.005985019728541374, SNR: 16.403701782226562\n",
      "Epoch [24/25], Step [1300/1803], Loss: 0.0060301292687654495, SNR: 14.388882637023926\n",
      "Epoch [24/25], Step [1400/1803], Loss: 0.006786321755498648, SNR: 15.016340255737305\n",
      "Epoch [24/25], Step [1500/1803], Loss: 0.00802651047706604, SNR: 14.603506088256836\n",
      "Epoch [24/25], Step [1600/1803], Loss: 0.006213350221514702, SNR: 15.059616088867188\n",
      "Epoch [24/25], Step [1700/1803], Loss: 0.00619278009980917, SNR: 15.63443660736084\n",
      "Epoch [24/25], Step [1800/1803], Loss: 0.006640180014073849, SNR: 15.404736518859863\n",
      ".:. Training metrics = Loss: 0.007181716784252927, SNR: 14.879530017718787\n",
      ".:. Validation metrics = Loss: 0.00680659501893405, SNR: 14.963920174310902\n",
      "Epoch [25/25], Step [100/1803], Loss: 0.006262841634452343, SNR: 14.899635314941406\n",
      "Epoch [25/25], Step [200/1803], Loss: 0.0073653883300721645, SNR: 14.504504203796387\n",
      "Epoch [25/25], Step [300/1803], Loss: 0.007071883417665958, SNR: 15.274909973144531\n",
      "Epoch [25/25], Step [400/1803], Loss: 0.006264647468924522, SNR: 15.261358261108398\n",
      "Epoch [25/25], Step [500/1803], Loss: 0.005628135055303574, SNR: 15.974605560302734\n",
      "Epoch [25/25], Step [600/1803], Loss: 0.005686893593519926, SNR: 15.573567390441895\n",
      "Epoch [25/25], Step [700/1803], Loss: 0.009830476716160774, SNR: 14.763638496398926\n",
      "Epoch [25/25], Step [800/1803], Loss: 0.0060278065502643585, SNR: 14.23351001739502\n",
      "Epoch [25/25], Step [900/1803], Loss: 0.005988083779811859, SNR: 16.250911712646484\n",
      "Epoch [25/25], Step [1000/1803], Loss: 0.007003512699157, SNR: 14.6926908493042\n",
      "Epoch [25/25], Step [1100/1803], Loss: 0.006753790657967329, SNR: 14.670886993408203\n",
      "Epoch [25/25], Step [1200/1803], Loss: 0.007410959340631962, SNR: 15.673139572143555\n",
      "Epoch [25/25], Step [1300/1803], Loss: 0.007805810775607824, SNR: 13.538166999816895\n",
      "Epoch [25/25], Step [1400/1803], Loss: 0.00637787114828825, SNR: 14.320972442626953\n",
      "Epoch [25/25], Step [1500/1803], Loss: 0.008285564370453358, SNR: 14.133462905883789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Step [1600/1803], Loss: 0.006380870938301086, SNR: 14.720996856689453\n",
      "Epoch [25/25], Step [1700/1803], Loss: 0.006205449812114239, SNR: 15.471891403198242\n",
      "Epoch [25/25], Step [1800/1803], Loss: 0.006124178878962994, SNR: 15.853748321533203\n",
      ".:. Training metrics = Loss: 0.0071372523416338655, SNR: 14.93141395580488\n",
      ".:. Validation metrics = Loss: 0.0068875416424603285, SNR: 14.810803748602213\n"
     ]
    }
   ],
   "source": [
    "# Train the model over epochs\n",
    "steps = len(ls_generator)\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    # training and val metrics for all data\n",
    "    loss, metric = 0.0, 0.0\n",
    "    val_loss, val_metric = 0.0, 0.0\n",
    "\n",
    "    # ======================== Training ============================= #\n",
    "    for i, (local_batch, local_labels) in enumerate(ls_generator):\n",
    "        # Transfer to Device\n",
    "        local_batch = local_batch.to(device)\n",
    "        local_labels = local_labels.to(device)\n",
    "\n",
    "        # Set gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass, backward pass, optimize\n",
    "        outputs = model(local_batch)\n",
    "        loss_batch = m_loss(outputs, local_labels)\n",
    "        batch_metric = m_snr(outputs, local_labels)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute metrics to all batch\n",
    "        loss += loss_batch.item() * len(local_batch)\n",
    "        metric += batch_metric.item() * len(local_batch)\n",
    "\n",
    "        # Print the loss every \"verbose\" batches\n",
    "        if (i + 1) % config.verbose == 0:\n",
    "            _display_metrics(epoch, i, steps,\n",
    "                loss_batch.item(), batch_metric.item())\n",
    "\n",
    "    # Compute the statistics of the last epoch and save to history\n",
    "    history['loss'].append(loss / len(lsg))\n",
    "    history['SNR'].append(metric / len(lsg))\n",
    "\n",
    "    # Checkpoint the model\n",
    "    torch.save(model.state_dict(), config.checkpoint_path)\n",
    "    \n",
    "    # Print Validation statistics\n",
    "    print(\".:. Training metrics =\", end=\" \")\n",
    "    print(\"Loss: {}, SNR: {}\".format(loss / len(lsg), metric / len(lsg)))\n",
    "    \n",
    "    # ======================= Validation ============================ #\n",
    "    with torch.no_grad():\n",
    "        for local_batch, local_labels in ls_val_generator:\n",
    "            # Transfer to device\n",
    "            local_batch = local_batch.to(device)\n",
    "            local_labels = local_labels.to(device)\n",
    "\n",
    "            # Predict, get loss and metric\n",
    "            outputs = model(local_batch)\n",
    "            val_loss += m_loss(outputs, local_labels).item() \\\n",
    "                * len(local_batch)\n",
    "\n",
    "            val_metric += m_snr(outputs, local_labels).item() \\\n",
    "                * len(local_batch)\n",
    "\n",
    "        val_loss /= len(lsg_val)\n",
    "        val_metric /= len(lsg_val)\n",
    "                \n",
    "    # Print Validation statistics\n",
    "    print(\".:. Validation metrics =\", end=\" \")\n",
    "    print(\"Loss: {}, SNR: {}\".format(val_loss, val_metric))\n",
    "\n",
    "    # Compute the metrics and loss of last batch and save to history\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_SNR'].append(val_metric)\n",
    "    lr_scheduler.step(val_loss)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "history['elapsed_time'] = elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the last model\n",
    "torch.save(model.state_dict(), config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot network history\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['val_loss'], label='val')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Traning history')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot network history\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(history['SNR'], label='train')\n",
    "plt.plot(history['val_SNR'], label='val')\n",
    "plt.ylabel('SNR')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Traning history')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history to a JSON file\n",
    "with open(config.history_path, 'w') as fp:\n",
    "    json.dump(history, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.load(\"../data/processed/noisy/test/x_test.pt\")\n",
    "y_test = torch.load(\"../data/processed/noisy/test/y_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3874, 1, 65536])\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_params = {\n",
    "    'batch_size': config.batch_size,\n",
    "    'shuffle': False,\n",
    "    'num_workers': config.num_workers\n",
    "}\n",
    "\n",
    "lsg_test = LibriSpeechGenerator(config, X_test, y_test)\n",
    "ls_test_generator = data.DataLoader(lsg_test, **_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3874, 1, 65536])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR (Test): 10.058753967285156\n"
     ]
    }
   ],
   "source": [
    "# Print validation metric before trainer\n",
    "print(\"SNR (Test): {}\".format(m_snr(lsg_test.X, lsg_test.y).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_metric = 0.0, 0.0\n",
    "with torch.no_grad():\n",
    "    for local_batch, local_labels in ls_test_generator:\n",
    "        # Transfer to device\n",
    "        local_batch = local_batch.to(device)\n",
    "        local_labels = local_labels.to(device)\n",
    "\n",
    "        # Predict, get loss and metric\n",
    "        outputs = model(local_batch)\n",
    "        test_loss += m_loss(outputs, local_labels).item() \\\n",
    "            * len(local_batch)\n",
    "\n",
    "        test_metric += m_snr(outputs, local_labels).item() \\\n",
    "            * len(local_batch)\n",
    "        \n",
    "        writer(local_batch, local_labels,\n",
    "               outputs, config.sr, config.writer_path)\n",
    "\n",
    "    test_loss /= len(lsg_test)\n",
    "    test_metric /= len(lsg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_history = {\n",
    "    'SNR_ini': m_snr(lsg_test.X, lsg_test.y).item(),\n",
    "    'SNR': test_metric, \n",
    "    'loss': test_loss\n",
    "}\n",
    "\n",
    "with open(os.path.join(config.writer_path, 'test_history.json') , 'w') as fp:\n",
    "    json.dump(test_history, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sewunet",
   "language": "python",
   "name": "sewunet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
