{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import ConfigObject\n",
    "from utils import reserve_pop\n",
    "from utils import id_generator\n",
    "from utils import writer\n",
    "from utils import LibriSpeechGenerator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from parts import VSConvBlock\n",
    "from parts import DownSamplingBlock\n",
    "from parts import UpSamplingBlock\n",
    "from parts import OutBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonConfig = {\n",
    "    \"test_platform\": False,\n",
    "    \"ds_prop\": 0.25,\n",
    "    \"sr\": 16000,\n",
    "    \"n_samples\": 65536,\n",
    "    \n",
    "    \"n_channels\": 1,\n",
    "    \"n_classes\": 1,\n",
    "    \"depth\": 5,\n",
    "    \"fsize\": 24,\n",
    "    \"moffset\": 8,\n",
    "    \n",
    "    \"batch_size\": 48,\n",
    "    \"epochs\": 100,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 8,\n",
    "    \"verbose\": 100,\n",
    "\n",
    "    \"checkpoint_path\": \"../models/checkpoint.pt\",\n",
    "    \"model_path\": \"../models/last_model.pt\",\n",
    "\n",
    "    \"save_last_batch\": True,\n",
    "    \"writer_path\": \"../logs/\",\n",
    "    \"history_path\": \"../logs/history.json\"\n",
    "}\n",
    "\n",
    "config = ConfigObject(**jsonConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "_params = {\n",
    "    'batch_size': config.batch_size,\n",
    "    'shuffle': config.shuffle,\n",
    "    'num_workers': config.num_workers\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load(\"../data/processed/aewi/train/train.pt\")\n",
    "X_val = torch.load(\"../data/processed/aewi/val/val.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generators\n",
    "lsg = LibriSpeechGenerator(config, X_train, mode=\"ae\")\n",
    "lsg_val = LibriSpeechGenerator(config, X_val, mode=\"ae\")\n",
    "\n",
    "ls_generator = data.DataLoader(lsg, **_params)\n",
    "ls_val_generator = data.DataLoader(lsg_val, **_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEWUNet(nn.Module):\n",
    "    def __init__(self, config, fd=15, fu=5):\n",
    "        \"\"\"Speech Enhancenment using Wave-U-Net\"\"\"\n",
    "        super(SEWUNet, self).__init__()\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.n_channels = config.n_channels\n",
    "        self.n_classes = config.n_classes\n",
    "        self.depth = config.depth\n",
    "        self.fsize = config.fsize\n",
    "        self.moffset = config.moffset\n",
    "        self.fd = fd\n",
    "        self.fu = fu\n",
    "\n",
    "        # Generate the list of in, out channels for the encoder\n",
    "        self.enc_filters = [self.n_channels]\n",
    "        self.enc_filters += [self.fsize * i + self.moffset\n",
    "                             for i in range(1, self.depth + 1)]\n",
    "        self.n_encoder = zip(self.enc_filters, self.enc_filters[1:])\n",
    "\n",
    "        # Bottleneck block sizes\n",
    "        mid_in = self.fsize * self.depth + self.moffset\n",
    "        mid_out = self.fsize * (self.depth + 1) + self.moffset\n",
    "\n",
    "        # Generate the list of in, out channels for the decoder\n",
    "        self.out_dec = reserve_pop(self.enc_filters)\n",
    "        self.in_dec = [mid_out + self.enc_filters[-1]]\n",
    "        self.in_dec += [self.out_dec[i] + self.out_dec[i + 1]\n",
    "                        for i in range(self.depth - 1)]\n",
    "        self.n_decoder = zip(self.in_dec, self.out_dec)\n",
    "\n",
    "        # Architecture and parameters\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "\n",
    "        # Build the encoder part of the U-net architecture\n",
    "        for i, (in_ch, out_ch) in enumerate(self.n_encoder):\n",
    "            self.encoder.append(DownSamplingBlock(\n",
    "                in_ch=in_ch,\n",
    "                out_ch=out_ch,\n",
    "                kernel_size=self.fd,\n",
    "                padding=self.fd // 2,\n",
    "                activation=nn.LeakyReLU(0.1))\n",
    "            )\n",
    "\n",
    "        # Bottleneck block for the U-net\n",
    "        self.mid_block = VSConvBlock(\n",
    "            in_ch=mid_in,\n",
    "            out_ch=mid_out,\n",
    "            kernel_size=self.fd,\n",
    "            padding=self.fd // 2,\n",
    "            activation=nn.LeakyReLU(0.1))\n",
    "\n",
    "        # Build the decoder part of the U-net architecture\n",
    "        for in_ch, out_ch in self.n_decoder:\n",
    "            self.decoder.append(UpSamplingBlock(\n",
    "                in_ch=in_ch,\n",
    "                out_ch=out_ch,\n",
    "                kernel_size=self.fu,\n",
    "                padding=self.fu // 2,\n",
    "                activation=nn.LeakyReLU(0.1),\n",
    "                mode=\"linear\")\n",
    "            )\n",
    "\n",
    "        # Output block\n",
    "        out_ch = self.out_dec[-1] + 1\n",
    "        self.out_block = OutBlock(\n",
    "            in_ch=out_ch,\n",
    "            out_ch=self.n_classes,\n",
    "            activation=nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\"\"\"\n",
    "        enc = []\n",
    "        net_in = copy.copy(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            x, xi = self.encoder[i](x)\n",
    "            enc.append(xi)\n",
    "\n",
    "        x = self.mid_block(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            x = self.decoder[i](x, enc.pop())\n",
    "\n",
    "        x = self.out_block(x, net_in)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SEWUNet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "history = {'loss': [], 'SNR': [], 'val_loss': [], 'val_SNR': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomMetric():\n",
    "    \"\"\"Calculate the SNR of X and Y\"\"\"\n",
    "    def SNR(X, Y):\n",
    "        n = X.shape[2]\n",
    "        return torch.mean(10 * torch.log10(\n",
    "            (torch.norm(Y, dim=2)**2 / n) /\n",
    "            (torch.norm(X - Y, dim=2)**2 / n)\n",
    "        ))\n",
    "    return SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optimizer\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-6,\n",
    "    betas=(0.9, 0.999))\n",
    "\n",
    "# lr_scheduler = torch.optim.lr_scheduler(optimizer)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "# Loss and metric\n",
    "m_loss = nn.L1Loss()\n",
    "m_snr = CustomMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1139372"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of trainable parameters in the model\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display trainning metrics\n",
    "def _display_metrics(epoch, it, steps, loss, metric):\n",
    "    print(\"Epoch [{:02d}/{:02d}]\".format(\n",
    "        epoch + 1, config.epochs), end=\", \")\n",
    "\n",
    "    print(\"Step [{:03d}/{:03d}]\".format(\n",
    "        it + 1, steps), end=\", \")\n",
    "\n",
    "    print(\"Loss: {}, SNR: {}\".format(\n",
    "        loss, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [01/100], Step [100/602], Loss: 0.05871373414993286, SNR: -3.8860230445861816\n",
      "Epoch [01/100], Step [200/602], Loss: 0.024353602901101112, SNR: 1.4941496849060059\n",
      "Epoch [01/100], Step [300/602], Loss: 0.019357120618224144, SNR: 3.414375066757202\n",
      "Epoch [01/100], Step [400/602], Loss: 0.01653040386736393, SNR: 3.8690755367279053\n",
      "Epoch [01/100], Step [500/602], Loss: 0.013603641651570797, SNR: 6.049432754516602\n",
      "Epoch [01/100], Step [600/602], Loss: 0.013891865499317646, SNR: 6.460853099822998\n",
      ".:. Training metrics = Loss: 0.029538707824573875, SNR: 1.775557097458275\n",
      ".:. Validation metrics = Loss: 0.01493075532706181, SNR: 6.01450013511117\n",
      "Epoch [02/100], Step [100/602], Loss: 0.012636459432542324, SNR: 6.197272300720215\n",
      "Epoch [02/100], Step [200/602], Loss: 0.012585346587002277, SNR: 7.237674713134766\n",
      "Epoch [02/100], Step [300/602], Loss: 0.011551455594599247, SNR: 7.767800331115723\n",
      "Epoch [02/100], Step [400/602], Loss: 0.012242640368640423, SNR: 7.906096935272217\n",
      "Epoch [02/100], Step [500/602], Loss: 0.009640658274292946, SNR: 9.324185371398926\n",
      "Epoch [02/100], Step [600/602], Loss: 0.007754138205200434, SNR: 11.392389297485352\n",
      ".:. Training metrics = Loss: 0.011288037204589665, SNR: 7.899104489894424\n",
      ".:. Validation metrics = Loss: 0.009121851495402133, SNR: 9.141320046430184\n",
      "Epoch [03/100], Step [100/602], Loss: 0.008469851687550545, SNR: 9.823421478271484\n",
      "Epoch [03/100], Step [200/602], Loss: 0.007730807643383741, SNR: 10.911380767822266\n",
      "Epoch [03/100], Step [300/602], Loss: 0.005796215962618589, SNR: 12.925025939941406\n",
      "Epoch [03/100], Step [400/602], Loss: 0.008479556068778038, SNR: 11.506270408630371\n",
      "Epoch [03/100], Step [500/602], Loss: 0.0065663703717291355, SNR: 12.78732681274414\n",
      "Epoch [03/100], Step [600/602], Loss: 0.0065294490195810795, SNR: 13.084624290466309\n",
      ".:. Training metrics = Loss: 0.007466132155321731, SNR: 11.004608789176308\n",
      ".:. Validation metrics = Loss: 0.006973023614865808, SNR: 11.42771406865188\n",
      "Epoch [04/100], Step [100/602], Loss: 0.00609249621629715, SNR: 11.35654354095459\n",
      "Epoch [04/100], Step [200/602], Loss: 0.004925076384097338, SNR: 14.134010314941406\n",
      "Epoch [04/100], Step [300/602], Loss: 0.006163138896226883, SNR: 12.791339874267578\n",
      "Epoch [04/100], Step [400/602], Loss: 0.0059754434041678905, SNR: 13.238882064819336\n",
      "Epoch [04/100], Step [500/602], Loss: 0.0058441124856472015, SNR: 12.911882400512695\n",
      "Epoch [04/100], Step [600/602], Loss: 0.005725498776882887, SNR: 13.180606842041016\n",
      ".:. Training metrics = Loss: 0.005712826421316957, SNR: 13.029528755127435\n",
      ".:. Validation metrics = Loss: 0.0052157050160681765, SNR: 13.287899685204394\n",
      "Epoch [05/100], Step [100/602], Loss: 0.0044098529033362865, SNR: 15.091376304626465\n",
      "Epoch [05/100], Step [200/602], Loss: 0.004585464019328356, SNR: 14.408012390136719\n",
      "Epoch [05/100], Step [300/602], Loss: 0.004541828762739897, SNR: 14.75699234008789\n",
      "Epoch [05/100], Step [400/602], Loss: 0.004857833497226238, SNR: 14.158892631530762\n",
      "Epoch [05/100], Step [500/602], Loss: 0.005896344315260649, SNR: 13.663619995117188\n",
      "Epoch [05/100], Step [600/602], Loss: 0.004483592230826616, SNR: 15.132619857788086\n",
      ".:. Training metrics = Loss: 0.00490928271738446, SNR: 14.451499656362847\n",
      ".:. Validation metrics = Loss: 0.004782552455704334, SNR: 14.634386549902812\n",
      "Epoch [06/100], Step [100/602], Loss: 0.004185102414339781, SNR: 16.781768798828125\n",
      "Epoch [06/100], Step [200/602], Loss: 0.0041383905336260796, SNR: 16.59809112548828\n",
      "Epoch [06/100], Step [300/602], Loss: 0.004786436911672354, SNR: 15.251680374145508\n",
      "Epoch [06/100], Step [400/602], Loss: 0.00416156742721796, SNR: 15.568441390991211\n",
      "Epoch [06/100], Step [500/602], Loss: 0.0034474253188818693, SNR: 17.636028289794922\n",
      "Epoch [06/100], Step [600/602], Loss: 0.00405860273167491, SNR: 16.334985733032227\n",
      ".:. Training metrics = Loss: 0.004206846176460695, SNR: 15.789066896493797\n",
      ".:. Validation metrics = Loss: 0.004139906754301676, SNR: 16.14631241705122\n",
      "Epoch [07/100], Step [100/602], Loss: 0.003550030989572406, SNR: 16.22718048095703\n",
      "Epoch [07/100], Step [200/602], Loss: 0.0028682055417448282, SNR: 17.33572006225586\n",
      "Epoch [07/100], Step [300/602], Loss: 0.003333189757540822, SNR: 17.059118270874023\n",
      "Epoch [07/100], Step [400/602], Loss: 0.0033711781725287437, SNR: 17.39067840576172\n",
      "Epoch [07/100], Step [500/602], Loss: 0.003336179768666625, SNR: 16.176328659057617\n",
      "Epoch [07/100], Step [600/602], Loss: 0.0030656466260552406, SNR: 17.915403366088867\n",
      ".:. Training metrics = Loss: 0.0035139356917478198, SNR: 17.179907264037837\n",
      ".:. Validation metrics = Loss: 0.003447827505645355, SNR: 17.643810704749807\n",
      "Epoch [08/100], Step [100/602], Loss: 0.0028659438248723745, SNR: 18.479827880859375\n",
      "Epoch [08/100], Step [200/602], Loss: 0.0024923933669924736, SNR: 18.554046630859375\n",
      "Epoch [08/100], Step [300/602], Loss: 0.00240269280038774, SNR: 18.413820266723633\n",
      "Epoch [08/100], Step [400/602], Loss: 0.0029494876507669687, SNR: 18.898395538330078\n",
      "Epoch [08/100], Step [500/602], Loss: 0.002871677279472351, SNR: 19.21994400024414\n",
      "Epoch [08/100], Step [600/602], Loss: 0.0025447800289839506, SNR: 19.565250396728516\n",
      ".:. Training metrics = Loss: 0.0029973945458104684, SNR: 18.520634747665394\n",
      ".:. Validation metrics = Loss: 0.002903402686372973, SNR: 19.191632370318935\n",
      "Epoch [09/100], Step [100/602], Loss: 0.0025874117854982615, SNR: 19.729562759399414\n",
      "Epoch [09/100], Step [200/602], Loss: 0.002529451157897711, SNR: 19.765974044799805\n",
      "Epoch [09/100], Step [300/602], Loss: 0.002344368025660515, SNR: 20.06952667236328\n",
      "Epoch [09/100], Step [400/602], Loss: 0.001924215815961361, SNR: 20.96788215637207\n",
      "Epoch [09/100], Step [500/602], Loss: 0.002448845421895385, SNR: 19.578651428222656\n",
      "Epoch [09/100], Step [600/602], Loss: 0.0019743749871850014, SNR: 20.8559627532959\n",
      ".:. Training metrics = Loss: 0.0025643130118284973, SNR: 19.859065036775664\n",
      ".:. Validation metrics = Loss: 0.002124771454681657, SNR: 20.878209221883626\n",
      "Epoch [10/100], Step [100/602], Loss: 0.0018753070617094636, SNR: 22.02338409423828\n",
      "Epoch [10/100], Step [200/602], Loss: 0.0019161225063726306, SNR: 20.70987319946289\n",
      "Epoch [10/100], Step [300/602], Loss: 0.0017671548994258046, SNR: 21.974647521972656\n",
      "Epoch [10/100], Step [400/602], Loss: 0.0015712134772911668, SNR: 22.66497039794922\n",
      "Epoch [10/100], Step [500/602], Loss: 0.0016406252980232239, SNR: 21.439252853393555\n",
      "Epoch [10/100], Step [600/602], Loss: 0.0015062970342114568, SNR: 23.283267974853516\n",
      ".:. Training metrics = Loss: 0.0018569938772150226, SNR: 21.551005783863747\n",
      ".:. Validation metrics = Loss: 0.0015301950511515876, SNR: 22.63804010072868\n",
      "Epoch [11/100], Step [100/602], Loss: 0.002239987486973405, SNR: 21.868667602539062\n",
      "Epoch [11/100], Step [200/602], Loss: 0.0018344047712162137, SNR: 22.05347442626953\n",
      "Epoch [11/100], Step [300/602], Loss: 0.0020143366418778896, SNR: 21.76785659790039\n",
      "Epoch [11/100], Step [400/602], Loss: 0.00180023571010679, SNR: 22.263214111328125\n",
      "Epoch [11/100], Step [500/602], Loss: 0.0019525435054674745, SNR: 22.275671005249023\n",
      "Epoch [11/100], Step [600/602], Loss: 0.0017552198842167854, SNR: 22.450788497924805\n",
      ".:. Training metrics = Loss: 0.0019237455186950122, SNR: 22.333029827823534\n",
      ".:. Validation metrics = Loss: 0.0018185405293922989, SNR: 23.24542237833039\n",
      "Epoch [12/100], Step [100/602], Loss: 0.001345612108707428, SNR: 23.733776092529297\n",
      "Epoch [12/100], Step [200/602], Loss: 0.0013529894640669227, SNR: 23.022993087768555\n",
      "Epoch [12/100], Step [300/602], Loss: 0.0018955250270664692, SNR: 21.453168869018555\n",
      "Epoch [12/100], Step [400/602], Loss: 0.0013348651118576527, SNR: 26.28525161743164\n",
      "Epoch [12/100], Step [500/602], Loss: 0.001586563535965979, SNR: 22.611034393310547\n",
      "Epoch [12/100], Step [600/602], Loss: 0.001590611762367189, SNR: 23.65059471130371\n",
      ".:. Training metrics = Loss: 0.0016584721861832232, SNR: 23.36224974782092\n",
      ".:. Validation metrics = Loss: 0.001751571952414369, SNR: 23.709408161867525\n",
      "Epoch [13/100], Step [100/602], Loss: 0.0013682966819033027, SNR: 24.336139678955078\n",
      "Epoch [13/100], Step [200/602], Loss: 0.0014442045940086246, SNR: 23.855846405029297\n",
      "Epoch [13/100], Step [300/602], Loss: 0.001372847706079483, SNR: 25.282474517822266\n",
      "Epoch [13/100], Step [400/602], Loss: 0.001501103863120079, SNR: 25.59075164794922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Step [500/602], Loss: 0.0015135295689105988, SNR: 23.991836547851562\n",
      "Epoch [13/100], Step [600/602], Loss: 0.0011949427425861359, SNR: 25.44036865234375\n",
      ".:. Training metrics = Loss: 0.0014500057038088381, SNR: 24.255576886771454\n",
      ".:. Validation metrics = Loss: 0.0012550104346964774, SNR: 25.0597384606814\n",
      "Epoch [14/100], Step [100/602], Loss: 0.0013770029181614518, SNR: 23.783132553100586\n",
      "Epoch [14/100], Step [200/602], Loss: 0.0013231203192844987, SNR: 24.422658920288086\n",
      "Epoch [14/100], Step [300/602], Loss: 0.0011771477293223143, SNR: 24.22305679321289\n",
      "Epoch [14/100], Step [400/602], Loss: 0.001398757565766573, SNR: 23.10690689086914\n",
      "Epoch [14/100], Step [500/602], Loss: 0.0013998759677633643, SNR: 24.922714233398438\n",
      "Epoch [14/100], Step [600/602], Loss: 0.0009784706635400653, SNR: 26.24969482421875\n",
      ".:. Training metrics = Loss: 0.0013562838713454919, SNR: 24.731353959867672\n",
      ".:. Validation metrics = Loss: 0.0010148194792758106, SNR: 25.811238298349974\n",
      "Epoch [15/100], Step [100/602], Loss: 0.001151955104433, SNR: 25.44232177734375\n",
      "Epoch [15/100], Step [200/602], Loss: 0.0010817486327141523, SNR: 25.36929702758789\n",
      "Epoch [15/100], Step [300/602], Loss: 0.0013087629340589046, SNR: 24.369468688964844\n",
      "Epoch [15/100], Step [400/602], Loss: 0.0011249525705352426, SNR: 24.17439842224121\n",
      "Epoch [15/100], Step [500/602], Loss: 0.0011735128937289119, SNR: 25.32699966430664\n",
      "Epoch [15/100], Step [600/602], Loss: 0.00101480761077255, SNR: 26.74196434020996\n",
      ".:. Training metrics = Loss: 0.0012914619413438024, SNR: 25.086431329371724\n",
      ".:. Validation metrics = Loss: 0.0011112740576243677, SNR: 25.91530394888203\n",
      "Epoch [16/100], Step [100/602], Loss: 0.0012449858477339149, SNR: 25.330358505249023\n",
      "Epoch [16/100], Step [200/602], Loss: 0.0008654920384287834, SNR: 26.741729736328125\n",
      "Epoch [16/100], Step [300/602], Loss: 0.0012960321037098765, SNR: 24.346446990966797\n",
      "Epoch [16/100], Step [400/602], Loss: 0.0012365307193249464, SNR: 25.40658950805664\n",
      "Epoch [16/100], Step [500/602], Loss: 0.0012264965334907174, SNR: 24.549301147460938\n",
      "Epoch [16/100], Step [600/602], Loss: 0.001277647796086967, SNR: 24.923458099365234\n",
      ".:. Training metrics = Loss: 0.0012408646342235772, SNR: 25.401220807334074\n",
      ".:. Validation metrics = Loss: 0.0012063862691249396, SNR: 26.024619839756102\n",
      "Epoch [17/100], Step [100/602], Loss: 0.0011391114676371217, SNR: 26.272418975830078\n",
      "Epoch [17/100], Step [200/602], Loss: 0.0008463560952804983, SNR: 26.417295455932617\n",
      "Epoch [17/100], Step [300/602], Loss: 0.0006970035028643906, SNR: 27.383689880371094\n",
      "Epoch [17/100], Step [400/602], Loss: 0.0009207674884237349, SNR: 25.673254013061523\n",
      "Epoch [17/100], Step [500/602], Loss: 0.0009072574903257191, SNR: 26.814849853515625\n",
      "Epoch [17/100], Step [600/602], Loss: 0.0007892907597124577, SNR: 26.073387145996094\n",
      ".:. Training metrics = Loss: 0.000996056316004354, SNR: 26.250831845884772\n",
      ".:. Validation metrics = Loss: 0.0008703140914737885, SNR: 26.982204059730044\n",
      "Epoch [18/100], Step [100/602], Loss: 0.000873300654347986, SNR: 27.564266204833984\n",
      "Epoch [18/100], Step [200/602], Loss: 0.00101841997820884, SNR: 25.96361541748047\n",
      "Epoch [18/100], Step [300/602], Loss: 0.0010966898407787085, SNR: 25.029857635498047\n",
      "Epoch [18/100], Step [400/602], Loss: 0.0008670281968079507, SNR: 26.779766082763672\n",
      "Epoch [18/100], Step [500/602], Loss: 0.0008940809057094157, SNR: 26.802959442138672\n",
      "Epoch [18/100], Step [600/602], Loss: 0.0010049444390460849, SNR: 25.182384490966797\n",
      ".:. Training metrics = Loss: 0.0009086863411621703, SNR: 26.741837474323372\n",
      ".:. Validation metrics = Loss: 0.0008100167871101295, SNR: 27.418951164539322\n",
      "Epoch [19/100], Step [100/602], Loss: 0.000826109666377306, SNR: 27.249217987060547\n",
      "Epoch [19/100], Step [200/602], Loss: 0.0008004764094948769, SNR: 26.924041748046875\n",
      "Epoch [19/100], Step [300/602], Loss: 0.0007193826022557914, SNR: 27.17835235595703\n",
      "Epoch [19/100], Step [400/602], Loss: 0.001577812246978283, SNR: 25.748329162597656\n",
      "Epoch [19/100], Step [500/602], Loss: 0.0006908455980010331, SNR: 27.706985473632812\n",
      "Epoch [19/100], Step [600/602], Loss: 0.0009637388284318149, SNR: 26.089588165283203\n",
      ".:. Training metrics = Loss: 0.0008829345138925504, SNR: 27.07072297897024\n",
      ".:. Validation metrics = Loss: 0.0007642277766976527, SNR: 27.830251019627948\n",
      "Epoch [20/100], Step [100/602], Loss: 0.0011061523109674454, SNR: 25.68124008178711\n",
      "Epoch [20/100], Step [200/602], Loss: 0.0010914310114458203, SNR: 28.005109786987305\n",
      "Epoch [20/100], Step [300/602], Loss: 0.0014291711850091815, SNR: 25.690855026245117\n",
      "Epoch [20/100], Step [400/602], Loss: 0.0010931125143542886, SNR: 26.555891036987305\n",
      "Epoch [20/100], Step [500/602], Loss: 0.0009280983940698206, SNR: 26.968612670898438\n",
      "Epoch [20/100], Step [600/602], Loss: 0.001050065620802343, SNR: 27.29195213317871\n",
      ".:. Training metrics = Loss: 0.0010706458752284115, SNR: 26.73706064074514\n",
      ".:. Validation metrics = Loss: 0.001008040328228403, SNR: 27.391422116307236\n",
      "Epoch [21/100], Step [100/602], Loss: 0.0007113325409591198, SNR: 26.74024772644043\n",
      "Epoch [21/100], Step [200/602], Loss: 0.0008324192021973431, SNR: 26.71167755126953\n",
      "Epoch [21/100], Step [300/602], Loss: 0.0006776256486773491, SNR: 28.818214416503906\n",
      "Epoch [21/100], Step [400/602], Loss: 0.0008171394583769143, SNR: 27.05270767211914\n",
      "Epoch [21/100], Step [500/602], Loss: 0.0007812520489096642, SNR: 27.174131393432617\n",
      "Epoch [21/100], Step [600/602], Loss: 0.0005950393970124424, SNR: 30.65932846069336\n",
      ".:. Training metrics = Loss: 0.0008021189608203396, SNR: 27.78062154769699\n",
      ".:. Validation metrics = Loss: 0.0006495864854244648, SNR: 28.588724155553166\n",
      "Epoch [22/100], Step [100/602], Loss: 0.0010844970820471644, SNR: 26.223127365112305\n",
      "Epoch [22/100], Step [200/602], Loss: 0.0008281636983156204, SNR: 28.211240768432617\n",
      "Epoch [22/100], Step [300/602], Loss: 0.0009433072409592569, SNR: 26.586132049560547\n",
      "Epoch [22/100], Step [400/602], Loss: 0.0009682102245278656, SNR: 27.4250545501709\n",
      "Epoch [22/100], Step [500/602], Loss: 0.0008086733869276941, SNR: 28.128652572631836\n",
      "Epoch [22/100], Step [600/602], Loss: 0.0007793125696480274, SNR: 27.074630737304688\n",
      ".:. Training metrics = Loss: 0.0009786973035922997, SNR: 27.343101252841194\n",
      ".:. Validation metrics = Loss: 0.0006696278693575963, SNR: 28.80809678825095\n",
      "Epoch [23/100], Step [100/602], Loss: 0.0005845706327818334, SNR: 29.236478805541992\n",
      "Epoch [23/100], Step [200/602], Loss: 0.0007099180947989225, SNR: 27.720603942871094\n",
      "Epoch [23/100], Step [300/602], Loss: 0.0008737454190850258, SNR: 28.250057220458984\n",
      "Epoch [23/100], Step [400/602], Loss: 0.0008678326266817749, SNR: 27.716453552246094\n",
      "Epoch [23/100], Step [500/602], Loss: 0.001045744284056127, SNR: 26.855817794799805\n",
      "Epoch [23/100], Step [600/602], Loss: 0.0008717410382814705, SNR: 28.07393455505371\n",
      ".:. Training metrics = Loss: 0.0008491939471565442, SNR: 27.97676416802389\n",
      ".:. Validation metrics = Loss: 0.0007964955147321841, SNR: 28.569361679830642\n",
      "Epoch [24/100], Step [100/602], Loss: 0.0007772236131131649, SNR: 30.300662994384766\n",
      "Epoch [24/100], Step [200/602], Loss: 0.0008775306050665677, SNR: 27.582733154296875\n",
      "Epoch [24/100], Step [300/602], Loss: 0.0008259302121587098, SNR: 27.776784896850586\n",
      "Epoch [24/100], Step [400/602], Loss: 0.0008383216918446124, SNR: 29.233184814453125\n",
      "Epoch [24/100], Step [500/602], Loss: 0.0006866299663670361, SNR: 28.616483688354492\n",
      "Epoch [24/100], Step [600/602], Loss: 0.000898093159776181, SNR: 27.415157318115234\n",
      ".:. Training metrics = Loss: 0.0009176140052431167, SNR: 27.883990174178063\n",
      ".:. Validation metrics = Loss: 0.0009760507885504141, SNR: 27.880554459984005\n",
      "Epoch [25/100], Step [100/602], Loss: 0.0012510557426139712, SNR: 26.065834045410156\n",
      "Epoch [25/100], Step [200/602], Loss: 0.0007951133302412927, SNR: 29.295385360717773\n",
      "Epoch [25/100], Step [300/602], Loss: 0.0007149267476052046, SNR: 29.628955841064453\n",
      "Epoch [25/100], Step [400/602], Loss: 0.0010997477220371366, SNR: 27.815200805664062\n",
      "Epoch [25/100], Step [500/602], Loss: 0.0006683689425699413, SNR: 29.582862854003906\n",
      "Epoch [25/100], Step [600/602], Loss: 0.0008714667637832463, SNR: 26.990341186523438\n",
      ".:. Training metrics = Loss: 0.0008734531201073869, SNR: 28.170118567708318\n",
      ".:. Validation metrics = Loss: 0.001013724807871691, SNR: 28.21786071057061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Step [100/602], Loss: 0.0007342477329075336, SNR: 28.12886619567871\n",
      "Epoch [26/100], Step [200/602], Loss: 0.0007155972998589277, SNR: 28.37030029296875\n",
      "Epoch [26/100], Step [300/602], Loss: 0.0008381966035813093, SNR: 27.646183013916016\n",
      "Epoch [26/100], Step [400/602], Loss: 0.0006693550967611372, SNR: 29.454526901245117\n",
      "Epoch [26/100], Step [500/602], Loss: 0.000617196608800441, SNR: 30.773635864257812\n",
      "Epoch [26/100], Step [600/602], Loss: 0.0007179484236985445, SNR: 28.67856216430664\n",
      ".:. Training metrics = Loss: 0.000844334061818052, SNR: 28.403391988431213\n",
      ".:. Validation metrics = Loss: 0.0008219404928026402, SNR: 28.991390529254264\n",
      "Epoch [27/100], Step [100/602], Loss: 0.0006832375074736774, SNR: 28.850521087646484\n",
      "Epoch [27/100], Step [200/602], Loss: 0.000880557345226407, SNR: 28.053001403808594\n",
      "Epoch [27/100], Step [300/602], Loss: 0.0007796382997184992, SNR: 30.471755981445312\n",
      "Epoch [27/100], Step [400/602], Loss: 0.0008754036389291286, SNR: 27.905380249023438\n",
      "Epoch [27/100], Step [500/602], Loss: 0.0007314514368772507, SNR: 30.611539840698242\n",
      "Epoch [27/100], Step [600/602], Loss: 0.0006715375930070877, SNR: 28.348140716552734\n",
      ".:. Training metrics = Loss: 0.0008211844440843053, SNR: 28.596689362205822\n",
      ".:. Validation metrics = Loss: 0.000785822914652942, SNR: 29.2465643370951\n",
      "Epoch [28/100], Step [100/602], Loss: 0.0004801149480044842, SNR: 30.212141036987305\n",
      "Epoch [28/100], Step [200/602], Loss: 0.00045017083175480366, SNR: 29.99953842163086\n",
      "Epoch [28/100], Step [300/602], Loss: 0.0005861378740519285, SNR: 27.988037109375\n",
      "Epoch [28/100], Step [400/602], Loss: 0.0006394193624146283, SNR: 29.8439998626709\n",
      "Epoch [28/100], Step [500/602], Loss: 0.0006011822842992842, SNR: 30.762802124023438\n",
      "Epoch [28/100], Step [600/602], Loss: 0.0004852106503676623, SNR: 29.19453239440918\n",
      ".:. Training metrics = Loss: 0.0005457926082607321, SNR: 29.6526488963642\n",
      ".:. Validation metrics = Loss: 0.0004811157871784832, SNR: 30.203601707424248\n",
      "Epoch [29/100], Step [100/602], Loss: 0.0006754926289431751, SNR: 28.006187438964844\n",
      "Epoch [29/100], Step [200/602], Loss: 0.000489642727188766, SNR: 30.708541870117188\n",
      "Epoch [29/100], Step [300/602], Loss: 0.0005773543380200863, SNR: 27.67618179321289\n",
      "Epoch [29/100], Step [400/602], Loss: 0.0004566678253468126, SNR: 30.06465721130371\n",
      "Epoch [29/100], Step [500/602], Loss: 0.0007653117645531893, SNR: 27.86322784423828\n",
      "Epoch [29/100], Step [600/602], Loss: 0.0004827476805076003, SNR: 29.45488739013672\n",
      ".:. Training metrics = Loss: 0.0005382858231156597, SNR: 29.70398023686855\n",
      ".:. Validation metrics = Loss: 0.0004795486836675747, SNR: 30.234184408881944\n",
      "Epoch [30/100], Step [100/602], Loss: 0.000505288306158036, SNR: 31.7437744140625\n",
      "Epoch [30/100], Step [200/602], Loss: 0.0006330407923087478, SNR: 29.757736206054688\n",
      "Epoch [30/100], Step [300/602], Loss: 0.0004991660243831575, SNR: 29.913429260253906\n",
      "Epoch [30/100], Step [400/602], Loss: 0.0005635405541397631, SNR: 28.472148895263672\n",
      "Epoch [30/100], Step [500/602], Loss: 0.0005427633877843618, SNR: 27.860403060913086\n",
      "Epoch [30/100], Step [600/602], Loss: 0.000584933441132307, SNR: 30.990219116210938\n",
      ".:. Training metrics = Loss: 0.0005366210522003537, SNR: 29.742333558958183\n",
      ".:. Validation metrics = Loss: 0.00047111178857281704, SNR: 30.300216857210632\n",
      "Epoch [31/100], Step [100/602], Loss: 0.0004574781924020499, SNR: 30.55813217163086\n",
      "Epoch [31/100], Step [200/602], Loss: 0.000494385021738708, SNR: 29.44301414489746\n",
      "Epoch [31/100], Step [300/602], Loss: 0.0004783577751368284, SNR: 30.603248596191406\n",
      "Epoch [31/100], Step [400/602], Loss: 0.0003934854466933757, SNR: 31.270078659057617\n",
      "Epoch [31/100], Step [500/602], Loss: 0.0004064279783051461, SNR: 32.02171325683594\n",
      "Epoch [31/100], Step [600/602], Loss: 0.0005670042592100799, SNR: 27.403335571289062\n",
      ".:. Training metrics = Loss: 0.0005341554003536735, SNR: 29.786420166573027\n",
      ".:. Validation metrics = Loss: 0.00047234208428612837, SNR: 30.333996459718076\n",
      "Epoch [32/100], Step [100/602], Loss: 0.000539311848115176, SNR: 28.913480758666992\n",
      "Epoch [32/100], Step [200/602], Loss: 0.0007165949791669846, SNR: 27.360591888427734\n",
      "Epoch [32/100], Step [300/602], Loss: 0.0005243720952421427, SNR: 29.94769287109375\n",
      "Epoch [32/100], Step [400/602], Loss: 0.000609007605817169, SNR: 28.205421447753906\n",
      "Epoch [32/100], Step [500/602], Loss: 0.0006073605618439615, SNR: 29.6744441986084\n",
      "Epoch [32/100], Step [600/602], Loss: 0.00045077575487084687, SNR: 29.983741760253906\n",
      ".:. Training metrics = Loss: 0.0005306577710836981, SNR: 29.837301875798538\n",
      ".:. Validation metrics = Loss: 0.0004632137238578609, SNR: 30.392839117028117\n",
      "Epoch [33/100], Step [100/602], Loss: 0.0007388701778836548, SNR: 29.182920455932617\n",
      "Epoch [33/100], Step [200/602], Loss: 0.00046933884732425213, SNR: 29.057729721069336\n",
      "Epoch [33/100], Step [300/602], Loss: 0.0004918862250633538, SNR: 31.2314453125\n",
      "Epoch [33/100], Step [400/602], Loss: 0.0006507787038572133, SNR: 28.699506759643555\n",
      "Epoch [33/100], Step [500/602], Loss: 0.0008742996142245829, SNR: 28.822227478027344\n",
      "Epoch [33/100], Step [600/602], Loss: 0.0005079690017737448, SNR: 28.28464126586914\n",
      ".:. Training metrics = Loss: 0.0005265348735476372, SNR: 29.89139455657061\n",
      ".:. Validation metrics = Loss: 0.0004652493924471111, SNR: 30.444846029622816\n",
      "Epoch [34/100], Step [100/602], Loss: 0.0003601621137931943, SNR: 30.392494201660156\n",
      "Epoch [34/100], Step [200/602], Loss: 0.0005202976753935218, SNR: 30.73585319519043\n",
      "Epoch [34/100], Step [300/602], Loss: 0.0005756844184361398, SNR: 27.448230743408203\n",
      "Epoch [34/100], Step [400/602], Loss: 0.00046404285239987075, SNR: 30.256206512451172\n",
      "Epoch [34/100], Step [500/602], Loss: 0.0004533998726401478, SNR: 30.36288070678711\n",
      "Epoch [34/100], Step [600/602], Loss: 0.000644745712634176, SNR: 29.23481559753418\n",
      ".:. Training metrics = Loss: 0.0005221910720264577, SNR: 29.949125137873814\n",
      ".:. Validation metrics = Loss: 0.0004615337363598328, SNR: 30.497461127222937\n",
      "Epoch [35/100], Step [100/602], Loss: 0.0004376184951979667, SNR: 29.742652893066406\n",
      "Epoch [35/100], Step [200/602], Loss: 0.00038011171272955835, SNR: 30.905927658081055\n",
      "Epoch [35/100], Step [300/602], Loss: 0.0006015450926497579, SNR: 29.866741180419922\n",
      "Epoch [35/100], Step [400/602], Loss: 0.0006631628493778408, SNR: 28.517066955566406\n",
      "Epoch [35/100], Step [500/602], Loss: 0.0006660118233412504, SNR: 28.269508361816406\n",
      "Epoch [35/100], Step [600/602], Loss: 0.000461023737443611, SNR: 29.91246795654297\n",
      ".:. Training metrics = Loss: 0.0005178215015402554, SNR: 30.005222860309928\n",
      ".:. Validation metrics = Loss: 0.00045550077959341864, SNR: 30.56925194773637\n",
      "Epoch [36/100], Step [100/602], Loss: 0.0010337888961657882, SNR: 28.080371856689453\n",
      "Epoch [36/100], Step [200/602], Loss: 0.00033304825774393976, SNR: 31.718860626220703\n",
      "Epoch [36/100], Step [300/602], Loss: 0.00047131525934673846, SNR: 29.209888458251953\n",
      "Epoch [36/100], Step [400/602], Loss: 0.0006445437902584672, SNR: 29.113460540771484\n",
      "Epoch [36/100], Step [500/602], Loss: 0.00039987926720641553, SNR: 30.233848571777344\n",
      "Epoch [36/100], Step [600/602], Loss: 0.00041033129673451185, SNR: 31.04480743408203\n",
      ".:. Training metrics = Loss: 0.0005135580130595146, SNR: 30.061465593531768\n",
      ".:. Validation metrics = Loss: 0.0004577602823299104, SNR: 30.60443905936895\n",
      "Epoch [37/100], Step [100/602], Loss: 0.0004739586729556322, SNR: 29.952016830444336\n",
      "Epoch [37/100], Step [200/602], Loss: 0.0008679866441525519, SNR: 30.163471221923828\n",
      "Epoch [37/100], Step [300/602], Loss: 0.0004966663545928895, SNR: 30.021202087402344\n",
      "Epoch [37/100], Step [400/602], Loss: 0.00045834959018975496, SNR: 31.296283721923828\n",
      "Epoch [37/100], Step [500/602], Loss: 0.0004799442831426859, SNR: 27.919788360595703\n",
      "Epoch [37/100], Step [600/602], Loss: 0.000607342750299722, SNR: 27.38869285583496\n",
      ".:. Training metrics = Loss: 0.0005095313625605466, SNR: 30.11629367695232\n",
      ".:. Validation metrics = Loss: 0.0004526379555086562, SNR: 30.65915218026861\n",
      "Epoch [38/100], Step [100/602], Loss: 0.0003866362094413489, SNR: 32.613426208496094\n",
      "Epoch [38/100], Step [200/602], Loss: 0.0004780879244208336, SNR: 30.35650634765625\n",
      "Epoch [38/100], Step [300/602], Loss: 0.00039032401400618255, SNR: 31.89821434020996\n",
      "Epoch [38/100], Step [400/602], Loss: 0.0006518771406263113, SNR: 29.154109954833984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Step [500/602], Loss: 0.0006436420371755958, SNR: 30.542320251464844\n",
      "Epoch [38/100], Step [600/602], Loss: 0.00046320189721882343, SNR: 31.014263153076172\n",
      ".:. Training metrics = Loss: 0.0005057106132747744, SNR: 30.16782287739387\n",
      ".:. Validation metrics = Loss: 0.0004425292714898528, SNR: 30.71660794084404\n",
      "Epoch [39/100], Step [100/602], Loss: 0.0004076382901985198, SNR: 30.39790153503418\n",
      "Epoch [39/100], Step [200/602], Loss: 0.00046717023360542953, SNR: 30.845420837402344\n",
      "Epoch [39/100], Step [300/602], Loss: 0.000647170701995492, SNR: 28.732685089111328\n",
      "Epoch [39/100], Step [400/602], Loss: 0.000664122577290982, SNR: 29.078527450561523\n",
      "Epoch [39/100], Step [500/602], Loss: 0.0005347509286366403, SNR: 29.659408569335938\n",
      "Epoch [39/100], Step [600/602], Loss: 0.0003875697439070791, SNR: 30.995681762695312\n",
      ".:. Training metrics = Loss: 0.0005020379569979897, SNR: 30.21974879134504\n",
      ".:. Validation metrics = Loss: 0.00043903173633447337, SNR: 30.778243219134044\n",
      "Epoch [40/100], Step [100/602], Loss: 0.0004437502066139132, SNR: 30.140050888061523\n",
      "Epoch [40/100], Step [200/602], Loss: 0.0004951671580784023, SNR: 31.35426139831543\n",
      "Epoch [40/100], Step [300/602], Loss: 0.00033514469396322966, SNR: 31.703838348388672\n",
      "Epoch [40/100], Step [400/602], Loss: 0.0004077024932485074, SNR: 32.35340118408203\n",
      "Epoch [40/100], Step [500/602], Loss: 0.0004148216685280204, SNR: 31.27023696899414\n",
      "Epoch [40/100], Step [600/602], Loss: 0.0004457293835002929, SNR: 31.022541046142578\n",
      ".:. Training metrics = Loss: 0.0004986043695504673, SNR: 30.269446582045212\n",
      ".:. Validation metrics = Loss: 0.0004325487113537422, SNR: 30.828792423605837\n",
      "Epoch [41/100], Step [100/602], Loss: 0.00044715593685396016, SNR: 29.847736358642578\n",
      "Epoch [41/100], Step [200/602], Loss: 0.00051745685050264, SNR: 31.02520751953125\n",
      "Epoch [41/100], Step [300/602], Loss: 0.00046126439701765776, SNR: 30.38876724243164\n",
      "Epoch [41/100], Step [400/602], Loss: 0.0006058893050067127, SNR: 28.16425895690918\n",
      "Epoch [41/100], Step [500/602], Loss: 0.0005472722114063799, SNR: 27.733440399169922\n",
      "Epoch [41/100], Step [600/602], Loss: 0.0005991426878608763, SNR: 28.531509399414062\n",
      ".:. Training metrics = Loss: 0.0004953061787028259, SNR: 30.316877800947385\n",
      ".:. Validation metrics = Loss: 0.00043685946500333873, SNR: 30.877598599177155\n",
      "Epoch [42/100], Step [100/602], Loss: 0.00043333086068741977, SNR: 31.351173400878906\n",
      "Epoch [42/100], Step [200/602], Loss: 0.0005421075620688498, SNR: 29.035802841186523\n",
      "Epoch [42/100], Step [300/602], Loss: 0.00042299472261220217, SNR: 30.333593368530273\n",
      "Epoch [42/100], Step [400/602], Loss: 0.00035601211129687726, SNR: 29.961156845092773\n",
      "Epoch [42/100], Step [500/602], Loss: 0.0005037422524765134, SNR: 29.913496017456055\n",
      "Epoch [42/100], Step [600/602], Loss: 0.0005322654615156353, SNR: 29.096904754638672\n",
      ".:. Training metrics = Loss: 0.0004922258105381968, SNR: 30.36113606775769\n",
      ".:. Validation metrics = Loss: 0.00043408539401757016, SNR: 30.91592750424772\n",
      "Epoch [43/100], Step [100/602], Loss: 0.0004350721137598157, SNR: 30.348526000976562\n",
      "Epoch [43/100], Step [200/602], Loss: 0.0003779150720220059, SNR: 30.688541412353516\n",
      "Epoch [43/100], Step [300/602], Loss: 0.0004438686592038721, SNR: 31.071317672729492\n",
      "Epoch [43/100], Step [400/602], Loss: 0.0005657479632645845, SNR: 29.89746856689453\n",
      "Epoch [43/100], Step [500/602], Loss: 0.0004259573470335454, SNR: 29.71695327758789\n",
      "Epoch [43/100], Step [600/602], Loss: 0.0004248470941092819, SNR: 29.551353454589844\n",
      ".:. Training metrics = Loss: 0.0004892722925412891, SNR: 30.405027875734014\n",
      ".:. Validation metrics = Loss: 0.0004294471281857515, SNR: 30.95591528862289\n",
      "Epoch [44/100], Step [100/602], Loss: 0.00038324648630805314, SNR: 31.773178100585938\n",
      "Epoch [44/100], Step [200/602], Loss: 0.0006718012155033648, SNR: 28.895877838134766\n",
      "Epoch [44/100], Step [300/602], Loss: 0.00035868320264853537, SNR: 29.917150497436523\n",
      "Epoch [44/100], Step [400/602], Loss: 0.000594985787756741, SNR: 29.76776123046875\n",
      "Epoch [44/100], Step [500/602], Loss: 0.0003470027295406908, SNR: 30.914304733276367\n",
      "Epoch [44/100], Step [600/602], Loss: 0.0003754873760044575, SNR: 32.75688934326172\n",
      ".:. Training metrics = Loss: 0.00048648740458816394, SNR: 30.446878722374002\n",
      ".:. Validation metrics = Loss: 0.0004231224863691408, SNR: 31.004342629883244\n",
      "Epoch [45/100], Step [100/602], Loss: 0.0004468465631362051, SNR: 30.671993255615234\n",
      "Epoch [45/100], Step [200/602], Loss: 0.00048192564281634986, SNR: 31.743803024291992\n",
      "Epoch [45/100], Step [300/602], Loss: 0.0009109832462854683, SNR: 30.276411056518555\n",
      "Epoch [45/100], Step [400/602], Loss: 0.0004188849125057459, SNR: 30.370891571044922\n",
      "Epoch [45/100], Step [500/602], Loss: 0.0004148530715610832, SNR: 31.99811553955078\n",
      "Epoch [45/100], Step [600/602], Loss: 0.0003147060051560402, SNR: 31.974533081054688\n",
      ".:. Training metrics = Loss: 0.0004837859999514018, SNR: 30.487730119189774\n",
      ".:. Validation metrics = Loss: 0.00042360860844505206, SNR: 31.040487502451867\n",
      "Epoch [46/100], Step [100/602], Loss: 0.0003256197087466717, SNR: 31.956592559814453\n",
      "Epoch [46/100], Step [200/602], Loss: 0.000322341569699347, SNR: 32.9073600769043\n",
      "Epoch [46/100], Step [300/602], Loss: 0.0007750976947136223, SNR: 29.158790588378906\n",
      "Epoch [46/100], Step [400/602], Loss: 0.0004897862090729177, SNR: 28.94764518737793\n",
      "Epoch [46/100], Step [500/602], Loss: 0.0004569369775708765, SNR: 30.417341232299805\n",
      "Epoch [46/100], Step [600/602], Loss: 0.0003906248603016138, SNR: 30.79463768005371\n",
      ".:. Training metrics = Loss: 0.00048124901302858884, SNR: 30.52580987937371\n",
      ".:. Validation metrics = Loss: 0.00040994750573774294, SNR: 31.081959912929708\n",
      "Epoch [47/100], Step [100/602], Loss: 0.00048289462574757636, SNR: 29.86315155029297\n",
      "Epoch [47/100], Step [200/602], Loss: 0.0005753797595389187, SNR: 29.091495513916016\n",
      "Epoch [47/100], Step [300/602], Loss: 0.0005025787395425141, SNR: 29.651649475097656\n",
      "Epoch [47/100], Step [400/602], Loss: 0.0006029729847796261, SNR: 32.553165435791016\n",
      "Epoch [47/100], Step [500/602], Loss: 0.0005602245219051838, SNR: 30.316783905029297\n",
      "Epoch [47/100], Step [600/602], Loss: 0.0004493257438298315, SNR: 33.43874740600586\n",
      ".:. Training metrics = Loss: 0.00047884990299747453, SNR: 30.564009929510625\n",
      ".:. Validation metrics = Loss: 0.0004131836736210336, SNR: 31.121912208840467\n",
      "Epoch [48/100], Step [100/602], Loss: 0.0005793451564386487, SNR: 28.89204978942871\n",
      "Epoch [48/100], Step [200/602], Loss: 0.0003991989651694894, SNR: 30.689802169799805\n",
      "Epoch [48/100], Step [300/602], Loss: 0.0005521837738342583, SNR: 29.71804428100586\n",
      "Epoch [48/100], Step [400/602], Loss: 0.00043185733375139534, SNR: 30.972883224487305\n",
      "Epoch [48/100], Step [500/602], Loss: 0.0005360118229873478, SNR: 28.31725311279297\n",
      "Epoch [48/100], Step [600/602], Loss: 0.00033101029112003744, SNR: 32.172447204589844\n",
      ".:. Training metrics = Loss: 0.0004764429974630577, SNR: 30.600975492882842\n",
      ".:. Validation metrics = Loss: 0.0004087442431476389, SNR: 31.173500261344387\n",
      "Epoch [49/100], Step [100/602], Loss: 0.00040304590947926044, SNR: 29.971052169799805\n",
      "Epoch [49/100], Step [200/602], Loss: 0.00039006207953207195, SNR: 31.657684326171875\n",
      "Epoch [49/100], Step [300/602], Loss: 0.0005072210333310068, SNR: 30.421356201171875\n",
      "Epoch [49/100], Step [400/602], Loss: 0.0006261834059841931, SNR: 29.26915740966797\n",
      "Epoch [49/100], Step [500/602], Loss: 0.0003112002450507134, SNR: 32.71445083618164\n",
      "Epoch [49/100], Step [600/602], Loss: 0.0004114076728001237, SNR: 32.291160583496094\n",
      ".:. Training metrics = Loss: 0.00047416852377135443, SNR: 30.637185047260584\n",
      ".:. Validation metrics = Loss: 0.00041953782469067517, SNR: 31.18080548444843\n",
      "Epoch [50/100], Step [100/602], Loss: 0.0005724361981265247, SNR: 29.766250610351562\n",
      "Epoch [50/100], Step [200/602], Loss: 0.00037137349136173725, SNR: 30.285903930664062\n",
      "Epoch [50/100], Step [300/602], Loss: 0.0005369063001126051, SNR: 29.517253875732422\n",
      "Epoch [50/100], Step [400/602], Loss: 0.00035542596015147865, SNR: 32.38661193847656\n",
      "Epoch [50/100], Step [500/602], Loss: 0.0004711213114205748, SNR: 31.620460510253906\n",
      "Epoch [50/100], Step [600/602], Loss: 0.00043202409869991243, SNR: 31.76691436767578\n",
      ".:. Training metrics = Loss: 0.00047191695135558487, SNR: 30.672738034237742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:. Validation metrics = Loss: 0.00041382507673362286, SNR: 31.20742813212063\n",
      "Epoch [51/100], Step [100/602], Loss: 0.0005423363763839006, SNR: 28.563512802124023\n",
      "Epoch [51/100], Step [200/602], Loss: 0.0005325688980519772, SNR: 29.413631439208984\n",
      "Epoch [51/100], Step [300/602], Loss: 0.00029884898685850203, SNR: 33.64718246459961\n",
      "Epoch [51/100], Step [400/602], Loss: 0.0004426841624081135, SNR: 29.55805015563965\n",
      "Epoch [51/100], Step [500/602], Loss: 0.000352707487763837, SNR: 30.38687515258789\n",
      "Epoch [51/100], Step [600/602], Loss: 0.0003966515650972724, SNR: 31.039052963256836\n",
      ".:. Training metrics = Loss: 0.00046975727809683913, SNR: 30.706717608983368\n",
      ".:. Validation metrics = Loss: 0.00041478089966377063, SNR: 31.244313849411665\n",
      "Epoch [52/100], Step [100/602], Loss: 0.0004567427095025778, SNR: 30.52103042602539\n",
      "Epoch [52/100], Step [200/602], Loss: 0.00045939264236949384, SNR: 30.39308738708496\n",
      "Epoch [52/100], Step [300/602], Loss: 0.0003767912567127496, SNR: 32.136924743652344\n",
      "Epoch [52/100], Step [400/602], Loss: 0.000422716693719849, SNR: 30.503280639648438\n",
      "Epoch [52/100], Step [500/602], Loss: 0.0005138008273206651, SNR: 29.205062866210938\n",
      "Epoch [52/100], Step [600/602], Loss: 0.0003501061873976141, SNR: 32.840179443359375\n",
      ".:. Training metrics = Loss: 0.00046764087334840246, SNR: 30.741323725774713\n",
      ".:. Validation metrics = Loss: 0.00040602355190866844, SNR: 31.304305822958575\n",
      "Epoch [53/100], Step [100/602], Loss: 0.00036576492129825056, SNR: 33.29766845703125\n",
      "Epoch [53/100], Step [200/602], Loss: 0.0003877874987665564, SNR: 31.63861656188965\n",
      "Epoch [53/100], Step [300/602], Loss: 0.0005242656916379929, SNR: 30.24539566040039\n",
      "Epoch [53/100], Step [400/602], Loss: 0.0005789448623545468, SNR: 30.591022491455078\n",
      "Epoch [53/100], Step [500/602], Loss: 0.0004778551810886711, SNR: 30.513233184814453\n",
      "Epoch [53/100], Step [600/602], Loss: 0.00038676359690725803, SNR: 31.29866600036621\n",
      ".:. Training metrics = Loss: 0.00046567207709518645, SNR: 30.773876142853844\n",
      ".:. Validation metrics = Loss: 0.00039626893321766235, SNR: 31.35181249214539\n",
      "Epoch [54/100], Step [100/602], Loss: 0.0005382493254728615, SNR: 31.863422393798828\n",
      "Epoch [54/100], Step [200/602], Loss: 0.0003427068004384637, SNR: 31.1192626953125\n",
      "Epoch [54/100], Step [300/602], Loss: 0.0005498743266798556, SNR: 31.13390350341797\n",
      "Epoch [54/100], Step [400/602], Loss: 0.00046883078175596893, SNR: 30.44447898864746\n",
      "Epoch [54/100], Step [500/602], Loss: 0.0003891585802193731, SNR: 32.32884979248047\n",
      "Epoch [54/100], Step [600/602], Loss: 0.00039523374289274216, SNR: 31.016727447509766\n",
      ".:. Training metrics = Loss: 0.00046366534841956895, SNR: 30.80612890602947\n",
      ".:. Validation metrics = Loss: 0.00040055483121417563, SNR: 31.356825597755538\n",
      "Epoch [55/100], Step [100/602], Loss: 0.0004558236978482455, SNR: 27.710147857666016\n",
      "Epoch [55/100], Step [200/602], Loss: 0.0004198167007416487, SNR: 31.15082550048828\n",
      "Epoch [55/100], Step [300/602], Loss: 0.00045387691352516413, SNR: 29.640655517578125\n",
      "Epoch [55/100], Step [400/602], Loss: 0.0003413451777305454, SNR: 32.79621887207031\n",
      "Epoch [55/100], Step [500/602], Loss: 0.0004527089186012745, SNR: 30.125577926635742\n",
      "Epoch [55/100], Step [600/602], Loss: 0.0004010953416582197, SNR: 31.29926300048828\n",
      ".:. Training metrics = Loss: 0.0004616882422011768, SNR: 30.838669740459192\n",
      ".:. Validation metrics = Loss: 0.00040708965257217763, SNR: 31.383299459001513\n",
      "Epoch [56/100], Step [100/602], Loss: 0.0004895885358564556, SNR: 31.580841064453125\n",
      "Epoch [56/100], Step [200/602], Loss: 0.00041191637865267694, SNR: 33.19903564453125\n",
      "Epoch [56/100], Step [300/602], Loss: 0.0007626575534231961, SNR: 30.652873992919922\n",
      "Epoch [56/100], Step [400/602], Loss: 0.00040058427839539945, SNR: 29.977439880371094\n",
      "Epoch [56/100], Step [500/602], Loss: 0.00034545446396805346, SNR: 31.807445526123047\n",
      "Epoch [56/100], Step [600/602], Loss: 0.00048444897402077913, SNR: 29.41676139831543\n",
      ".:. Training metrics = Loss: 0.00045977423353204866, SNR: 30.869913503185234\n",
      ".:. Validation metrics = Loss: 0.00038698881378932244, SNR: 31.453470283293463\n",
      "Epoch [57/100], Step [100/602], Loss: 0.0003665562253445387, SNR: 32.11835861206055\n",
      "Epoch [57/100], Step [200/602], Loss: 0.00045998315908946097, SNR: 29.631694793701172\n",
      "Epoch [57/100], Step [300/602], Loss: 0.0003968186501879245, SNR: 30.280109405517578\n",
      "Epoch [57/100], Step [400/602], Loss: 0.00039677531458437443, SNR: 33.92793655395508\n",
      "Epoch [57/100], Step [500/602], Loss: 0.0004175433423370123, SNR: 30.55685043334961\n",
      "Epoch [57/100], Step [600/602], Loss: 0.00040658630314283073, SNR: 32.047996520996094\n",
      ".:. Training metrics = Loss: 0.00045795777499671166, SNR: 30.9013359411062\n",
      ".:. Validation metrics = Loss: 0.0003980692861530255, SNR: 31.442916768405766\n",
      "Epoch [58/100], Step [100/602], Loss: 0.0004322278837207705, SNR: 30.446292877197266\n",
      "Epoch [58/100], Step [200/602], Loss: 0.0003870802465826273, SNR: 30.363004684448242\n",
      "Epoch [58/100], Step [300/602], Loss: 0.0005626149941235781, SNR: 29.506473541259766\n",
      "Epoch [58/100], Step [400/602], Loss: 0.00034634096664376557, SNR: 32.71808624267578\n",
      "Epoch [58/100], Step [500/602], Loss: 0.0004367680521681905, SNR: 30.17702293395996\n",
      "Epoch [58/100], Step [600/602], Loss: 0.0004614395147655159, SNR: 31.56380271911621\n",
      ".:. Training metrics = Loss: 0.00045614412404444194, SNR: 30.93115021078251\n",
      ".:. Validation metrics = Loss: 0.00039156889187087426, SNR: 31.47927871442558\n",
      "Epoch [59/100], Step [100/602], Loss: 0.0005779327475465834, SNR: 32.35065841674805\n",
      "Epoch [59/100], Step [200/602], Loss: 0.00037588682607747614, SNR: 31.800262451171875\n",
      "Epoch [59/100], Step [300/602], Loss: 0.0004907840630039573, SNR: 28.94686508178711\n",
      "Epoch [59/100], Step [400/602], Loss: 0.00041163095738738775, SNR: 29.254608154296875\n",
      "Epoch [59/100], Step [500/602], Loss: 0.0003394399245735258, SNR: 32.495697021484375\n",
      "Epoch [59/100], Step [600/602], Loss: 0.00044708719360642135, SNR: 30.30451202392578\n",
      ".:. Training metrics = Loss: 0.00045435854263666756, SNR: 30.961401598121256\n",
      ".:. Validation metrics = Loss: 0.000394198076216786, SNR: 31.52085944808692\n",
      "Epoch [60/100], Step [100/602], Loss: 0.000502740906085819, SNR: 29.73684310913086\n",
      "Epoch [60/100], Step [200/602], Loss: 0.0004943541716784239, SNR: 30.47683334350586\n",
      "Epoch [60/100], Step [300/602], Loss: 0.0005346878315322101, SNR: 30.343786239624023\n",
      "Epoch [60/100], Step [400/602], Loss: 0.0007019671611487865, SNR: 28.903900146484375\n",
      "Epoch [60/100], Step [500/602], Loss: 0.0004129604494664818, SNR: 32.159812927246094\n",
      "Epoch [60/100], Step [600/602], Loss: 0.00041638038237579167, SNR: 30.803367614746094\n",
      ".:. Training metrics = Loss: 0.00045263166274003955, SNR: 30.99058614844603\n",
      ".:. Validation metrics = Loss: 0.00038780874590494714, SNR: 31.544469056267623\n",
      "Epoch [61/100], Step [100/602], Loss: 0.0005892810295335948, SNR: 28.181774139404297\n",
      "Epoch [61/100], Step [200/602], Loss: 0.0004379225429147482, SNR: 31.539379119873047\n",
      "Epoch [61/100], Step [300/602], Loss: 0.00030450624763034284, SNR: 32.39009475708008\n",
      "Epoch [61/100], Step [400/602], Loss: 0.00030238638282753527, SNR: 33.685367584228516\n",
      "Epoch [61/100], Step [500/602], Loss: 0.00048088308540172875, SNR: 30.684293746948242\n",
      "Epoch [61/100], Step [600/602], Loss: 0.0004441124328877777, SNR: 31.858375549316406\n",
      ".:. Training metrics = Loss: 0.00045095218344602954, SNR: 31.01890951926153\n",
      ".:. Validation metrics = Loss: 0.0003902710184172772, SNR: 31.569430765757318\n",
      "Epoch [62/100], Step [100/602], Loss: 0.00043518550228327513, SNR: 30.159414291381836\n",
      "Epoch [62/100], Step [200/602], Loss: 0.00044631402124650776, SNR: 29.91567611694336\n",
      "Epoch [62/100], Step [300/602], Loss: 0.00041448455885984004, SNR: 31.18653678894043\n",
      "Epoch [62/100], Step [400/602], Loss: 0.0004554449988063425, SNR: 29.60943603515625\n",
      "Epoch [62/100], Step [500/602], Loss: 0.0005293001304380596, SNR: 32.6828727722168\n",
      "Epoch [62/100], Step [600/602], Loss: 0.00034999882336705923, SNR: 32.03374481201172\n",
      ".:. Training metrics = Loss: 0.0004493251249268353, SNR: 31.046890049564425\n",
      ".:. Validation metrics = Loss: 0.0003825731247448373, SNR: 31.616856483809237\n",
      "Epoch [63/100], Step [100/602], Loss: 0.0003459684958215803, SNR: 30.41866683959961\n",
      "Epoch [63/100], Step [200/602], Loss: 0.0003976875450462103, SNR: 32.020591735839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Step [300/602], Loss: 0.0004089334106538445, SNR: 32.199527740478516\n",
      "Epoch [63/100], Step [400/602], Loss: 0.0003985173534601927, SNR: 32.164573669433594\n",
      "Epoch [63/100], Step [500/602], Loss: 0.00042929232586175203, SNR: 31.45321273803711\n",
      "Epoch [63/100], Step [600/602], Loss: 0.00033015396911650896, SNR: 33.14774703979492\n",
      ".:. Training metrics = Loss: 0.00044764863118067644, SNR: 31.07540944548648\n",
      ".:. Validation metrics = Loss: 0.00038949272786114437, SNR: 31.633675126247123\n",
      "Epoch [64/100], Step [100/602], Loss: 0.00030743409297429025, SNR: 32.32069778442383\n",
      "Epoch [64/100], Step [200/602], Loss: 0.0003273625625297427, SNR: 32.01468276977539\n",
      "Epoch [64/100], Step [300/602], Loss: 0.00045694049913436174, SNR: 31.466022491455078\n",
      "Epoch [64/100], Step [400/602], Loss: 0.00035825115628540516, SNR: 31.246910095214844\n",
      "Epoch [64/100], Step [500/602], Loss: 0.00033750187139958143, SNR: 32.0083122253418\n",
      "Epoch [64/100], Step [600/602], Loss: 0.0005621942109428346, SNR: 29.968236923217773\n",
      ".:. Training metrics = Loss: 0.0004461011185421786, SNR: 31.102743120840987\n",
      ".:. Validation metrics = Loss: 0.00038192605594471565, SNR: 31.671254022188567\n",
      "Epoch [65/100], Step [100/602], Loss: 0.000364922103472054, SNR: 31.525897979736328\n",
      "Epoch [65/100], Step [200/602], Loss: 0.0004619326500687748, SNR: 30.507381439208984\n",
      "Epoch [65/100], Step [300/602], Loss: 0.0005029647145420313, SNR: 30.827804565429688\n",
      "Epoch [65/100], Step [400/602], Loss: 0.0005635042325593531, SNR: 30.935178756713867\n",
      "Epoch [65/100], Step [500/602], Loss: 0.0002639854501467198, SNR: 33.43403625488281\n",
      "Epoch [65/100], Step [600/602], Loss: 0.000640440615825355, SNR: 30.12397003173828\n",
      ".:. Training metrics = Loss: 0.0004445457297583675, SNR: 31.129525286335014\n",
      ".:. Validation metrics = Loss: 0.00038755686535322495, SNR: 31.683678188124183\n",
      "Epoch [66/100], Step [100/602], Loss: 0.0004408311506267637, SNR: 29.418546676635742\n",
      "Epoch [66/100], Step [200/602], Loss: 0.0003590112610254437, SNR: 31.768413543701172\n",
      "Epoch [66/100], Step [300/602], Loss: 0.00030112164677120745, SNR: 33.12559127807617\n",
      "Epoch [66/100], Step [400/602], Loss: 0.0003717080981004983, SNR: 31.660125732421875\n",
      "Epoch [66/100], Step [500/602], Loss: 0.00037605888792313635, SNR: 30.83950424194336\n",
      "Epoch [66/100], Step [600/602], Loss: 0.0003968964156229049, SNR: 29.519161224365234\n",
      ".:. Training metrics = Loss: 0.000443026717579191, SNR: 31.155915621615808\n",
      ".:. Validation metrics = Loss: 0.00038208922819144985, SNR: 31.722383028211244\n",
      "Epoch [67/100], Step [100/602], Loss: 0.0003949714300688356, SNR: 31.487035751342773\n",
      "Epoch [67/100], Step [200/602], Loss: 0.0003641522489488125, SNR: 31.87708282470703\n",
      "Epoch [67/100], Step [300/602], Loss: 0.0003842634614557028, SNR: 31.743383407592773\n",
      "Epoch [67/100], Step [400/602], Loss: 0.0005339307244867086, SNR: 29.0306396484375\n",
      "Epoch [67/100], Step [500/602], Loss: 0.00040844237082637846, SNR: 31.583988189697266\n",
      "Epoch [67/100], Step [600/602], Loss: 0.0006375705124810338, SNR: 30.680400848388672\n",
      ".:. Training metrics = Loss: 0.00044153343248711375, SNR: 31.18338294570146\n",
      ".:. Validation metrics = Loss: 0.00037705725479582553, SNR: 31.746689042044796\n",
      "Epoch [68/100], Step [100/602], Loss: 0.0002987283223774284, SNR: 34.024600982666016\n",
      "Epoch [68/100], Step [200/602], Loss: 0.0004072991432622075, SNR: 31.162132263183594\n",
      "Epoch [68/100], Step [300/602], Loss: 0.000543845584616065, SNR: 28.122907638549805\n",
      "Epoch [68/100], Step [400/602], Loss: 0.000343259860528633, SNR: 31.96320152282715\n",
      "Epoch [68/100], Step [500/602], Loss: 0.000469067512312904, SNR: 31.556228637695312\n",
      "Epoch [68/100], Step [600/602], Loss: 0.0006108275265432894, SNR: 31.44118881225586\n",
      ".:. Training metrics = Loss: 0.00044009649526237696, SNR: 31.208850175608127\n",
      ".:. Validation metrics = Loss: 0.0003730546643647667, SNR: 31.78028130430767\n",
      "Epoch [69/100], Step [100/602], Loss: 0.0003948469238821417, SNR: 31.923480987548828\n",
      "Epoch [69/100], Step [200/602], Loss: 0.0007151358295232058, SNR: 29.936262130737305\n",
      "Epoch [69/100], Step [300/602], Loss: 0.00039526019827462733, SNR: 29.757625579833984\n",
      "Epoch [69/100], Step [400/602], Loss: 0.0005240713362582028, SNR: 30.616592407226562\n",
      "Epoch [69/100], Step [500/602], Loss: 0.0008903472335077822, SNR: 29.50037384033203\n",
      "Epoch [69/100], Step [600/602], Loss: 0.0006184115190990269, SNR: 30.993925094604492\n",
      ".:. Training metrics = Loss: 0.0004386033725659011, SNR: 31.23415785721963\n",
      ".:. Validation metrics = Loss: 0.0003744359730920622, SNR: 31.80407253821161\n",
      "Epoch [70/100], Step [100/602], Loss: 0.0003504808701109141, SNR: 31.500484466552734\n",
      "Epoch [70/100], Step [200/602], Loss: 0.0002974830858875066, SNR: 33.43845748901367\n",
      "Epoch [70/100], Step [300/602], Loss: 0.0002795965410768986, SNR: 32.717262268066406\n",
      "Epoch [70/100], Step [400/602], Loss: 0.0005119327688589692, SNR: 30.893524169921875\n",
      "Epoch [70/100], Step [500/602], Loss: 0.0003231085720472038, SNR: 32.372196197509766\n",
      "Epoch [70/100], Step [600/602], Loss: 0.0004061832732986659, SNR: 31.92336654663086\n",
      ".:. Training metrics = Loss: 0.00043727041273509693, SNR: 31.25935706719449\n",
      ".:. Validation metrics = Loss: 0.00037018906338816406, SNR: 31.830743346761125\n",
      "Epoch [71/100], Step [100/602], Loss: 0.000622886698693037, SNR: 31.348472595214844\n",
      "Epoch [71/100], Step [200/602], Loss: 0.00028090711566619575, SNR: 33.965248107910156\n",
      "Epoch [71/100], Step [300/602], Loss: 0.0003852070076391101, SNR: 31.57272720336914\n",
      "Epoch [71/100], Step [400/602], Loss: 0.0003342841228004545, SNR: 32.75035095214844\n",
      "Epoch [71/100], Step [500/602], Loss: 0.000323745101923123, SNR: 31.89777183532715\n",
      "Epoch [71/100], Step [600/602], Loss: 0.000374533497961238, SNR: 32.13152313232422\n",
      ".:. Training metrics = Loss: 0.00043584141564415605, SNR: 31.2830799702891\n",
      ".:. Validation metrics = Loss: 0.0003753989426952328, SNR: 31.849773781135152\n",
      "Epoch [72/100], Step [100/602], Loss: 0.0003367106837686151, SNR: 31.237247467041016\n",
      "Epoch [72/100], Step [200/602], Loss: 0.00037324734148569405, SNR: 31.18899154663086\n",
      "Epoch [72/100], Step [300/602], Loss: 0.0003764594439417124, SNR: 31.22100067138672\n",
      "Epoch [72/100], Step [400/602], Loss: 0.00040453733527101576, SNR: 31.673078536987305\n",
      "Epoch [72/100], Step [500/602], Loss: 0.00032540515530854464, SNR: 31.650882720947266\n",
      "Epoch [72/100], Step [600/602], Loss: 0.0003960774920415133, SNR: 32.91981887817383\n",
      ".:. Training metrics = Loss: 0.0004345452384523812, SNR: 31.30804027230414\n",
      ".:. Validation metrics = Loss: 0.00037209222059825, SNR: 31.87829846768878\n",
      "Epoch [73/100], Step [100/602], Loss: 0.0004104826657567173, SNR: 32.00534439086914\n",
      "Epoch [73/100], Step [200/602], Loss: 0.00046755094081163406, SNR: 30.69588851928711\n",
      "Epoch [73/100], Step [300/602], Loss: 0.00042255179141648114, SNR: 28.76910400390625\n",
      "Epoch [73/100], Step [400/602], Loss: 0.00035439900238998234, SNR: 33.46342086791992\n",
      "Epoch [73/100], Step [500/602], Loss: 0.00041531867464073, SNR: 29.684659957885742\n",
      "Epoch [73/100], Step [600/602], Loss: 0.0003203334636054933, SNR: 32.575401306152344\n",
      ".:. Training metrics = Loss: 0.0004331159339227899, SNR: 31.331239913177836\n",
      ".:. Validation metrics = Loss: 0.00039087550797295233, SNR: 31.83572453574216\n",
      "Epoch [74/100], Step [100/602], Loss: 0.0007733532693237066, SNR: 29.313236236572266\n",
      "Epoch [74/100], Step [200/602], Loss: 0.00046933055273257196, SNR: 30.74165916442871\n",
      "Epoch [74/100], Step [300/602], Loss: 0.0004586039576679468, SNR: 29.78893280029297\n",
      "Epoch [74/100], Step [400/602], Loss: 0.0005274875438772142, SNR: 29.02703094482422\n",
      "Epoch [74/100], Step [500/602], Loss: 0.00027936333208344877, SNR: 30.973318099975586\n",
      "Epoch [74/100], Step [600/602], Loss: 0.00036230895784683526, SNR: 31.371109008789062\n",
      ".:. Training metrics = Loss: 0.00043167819404239024, SNR: 31.35556338934313\n",
      ".:. Validation metrics = Loss: 0.00036582521902673595, SNR: 31.935902970321422\n",
      "Epoch [75/100], Step [100/602], Loss: 0.00038214042433537543, SNR: 31.84608268737793\n",
      "Epoch [75/100], Step [200/602], Loss: 0.0003775059012696147, SNR: 30.360916137695312\n",
      "Epoch [75/100], Step [300/602], Loss: 0.0003833052178379148, SNR: 31.365692138671875\n",
      "Epoch [75/100], Step [400/602], Loss: 0.0004209019534755498, SNR: 30.773975372314453\n",
      "Epoch [75/100], Step [500/602], Loss: 0.0004262652073521167, SNR: 30.88225555419922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Step [600/602], Loss: 0.00033924367744475603, SNR: 31.31066131591797\n",
      ".:. Training metrics = Loss: 0.0004306647229160391, SNR: 31.37840992520307\n",
      ".:. Validation metrics = Loss: 0.0003659644661709241, SNR: 31.93434018028819\n",
      "Epoch [76/100], Step [100/602], Loss: 0.000626911933068186, SNR: 29.030914306640625\n",
      "Epoch [76/100], Step [200/602], Loss: 0.0003477738646324724, SNR: 31.133583068847656\n",
      "Epoch [76/100], Step [300/602], Loss: 0.0003505090717226267, SNR: 31.536787033081055\n",
      "Epoch [76/100], Step [400/602], Loss: 0.00038164504803717136, SNR: 30.75423240661621\n",
      "Epoch [76/100], Step [500/602], Loss: 0.00046719680540263653, SNR: 31.86189842224121\n",
      "Epoch [76/100], Step [600/602], Loss: 0.0003029713116120547, SNR: 31.924312591552734\n",
      ".:. Training metrics = Loss: 0.00042931074854608343, SNR: 31.401743925378398\n",
      ".:. Validation metrics = Loss: 0.0003624098441510209, SNR: 31.974940053882477\n",
      "Epoch [77/100], Step [100/602], Loss: 0.0003702666435856372, SNR: 31.669279098510742\n",
      "Epoch [77/100], Step [200/602], Loss: 0.0004487861879169941, SNR: 30.134077072143555\n",
      "Epoch [77/100], Step [300/602], Loss: 0.00038780082832090557, SNR: 30.59625816345215\n",
      "Epoch [77/100], Step [400/602], Loss: 0.0005521497805602849, SNR: 29.36587142944336\n",
      "Epoch [77/100], Step [500/602], Loss: 0.0005758092156611383, SNR: 31.96596336364746\n",
      "Epoch [77/100], Step [600/602], Loss: 0.00034759228583425283, SNR: 31.98505210876465\n",
      ".:. Training metrics = Loss: 0.0004280596319758727, SNR: 31.42486465775904\n",
      ".:. Validation metrics = Loss: 0.0003584772698948503, SNR: 31.99367166061723\n",
      "Epoch [78/100], Step [100/602], Loss: 0.000571810407564044, SNR: 34.97700500488281\n",
      "Epoch [78/100], Step [200/602], Loss: 0.00033612045808695257, SNR: 33.135101318359375\n",
      "Epoch [78/100], Step [300/602], Loss: 0.001052799285389483, SNR: 31.928531646728516\n",
      "Epoch [78/100], Step [400/602], Loss: 0.0009144468349404633, SNR: 34.05686950683594\n",
      "Epoch [78/100], Step [500/602], Loss: 0.000515662191901356, SNR: 29.552947998046875\n",
      "Epoch [78/100], Step [600/602], Loss: 0.00037418489228002727, SNR: 33.101295471191406\n",
      ".:. Training metrics = Loss: 0.0004267349378629003, SNR: 31.447472114511427\n",
      ".:. Validation metrics = Loss: 0.00037419754488426856, SNR: 31.99220217342945\n",
      "Epoch [79/100], Step [100/602], Loss: 0.0003911661624442786, SNR: 30.94540786743164\n",
      "Epoch [79/100], Step [200/602], Loss: 0.00035682437010109425, SNR: 33.25433349609375\n",
      "Epoch [79/100], Step [300/602], Loss: 0.000345081090927124, SNR: 31.51576805114746\n",
      "Epoch [79/100], Step [400/602], Loss: 0.00043391273356974125, SNR: 30.77011489868164\n",
      "Epoch [79/100], Step [500/602], Loss: 0.0004609550815075636, SNR: 32.230140686035156\n",
      "Epoch [79/100], Step [600/602], Loss: 0.00037856597919017076, SNR: 31.66836929321289\n",
      ".:. Training metrics = Loss: 0.00042552584437531896, SNR: 31.471170451394592\n",
      ".:. Validation metrics = Loss: 0.0003611643542269547, SNR: 32.03490693817948\n",
      "Epoch [80/100], Step [100/602], Loss: 0.00041436843457631767, SNR: 30.145687103271484\n",
      "Epoch [80/100], Step [200/602], Loss: 0.0005001651006750762, SNR: 30.92933464050293\n",
      "Epoch [80/100], Step [300/602], Loss: 0.000425714417360723, SNR: 29.838850021362305\n",
      "Epoch [80/100], Step [400/602], Loss: 0.00046959970495663583, SNR: 30.331859588623047\n",
      "Epoch [80/100], Step [500/602], Loss: 0.0002904440916609019, SNR: 32.74788284301758\n",
      "Epoch [80/100], Step [600/602], Loss: 0.00029002956580370665, SNR: 35.28248596191406\n",
      ".:. Training metrics = Loss: 0.0004243334921255747, SNR: 31.49365021977289\n",
      ".:. Validation metrics = Loss: 0.000360667889799441, SNR: 32.062425404012714\n",
      "Epoch [81/100], Step [100/602], Loss: 0.00033784762490540743, SNR: 30.616313934326172\n",
      "Epoch [81/100], Step [200/602], Loss: 0.0003561285266187042, SNR: 30.899763107299805\n",
      "Epoch [81/100], Step [300/602], Loss: 0.0003739588719327003, SNR: 31.74779510498047\n",
      "Epoch [81/100], Step [400/602], Loss: 0.0003972735721617937, SNR: 31.841880798339844\n",
      "Epoch [81/100], Step [500/602], Loss: 0.00033135467674583197, SNR: 32.70146942138672\n",
      "Epoch [81/100], Step [600/602], Loss: 0.000365852756658569, SNR: 32.09347915649414\n",
      ".:. Training metrics = Loss: 0.0004232006054853347, SNR: 31.51558694114628\n",
      ".:. Validation metrics = Loss: 0.0003663838050676475, SNR: 32.068299199720414\n",
      "Epoch [82/100], Step [100/602], Loss: 0.00042982841841876507, SNR: 29.885242462158203\n",
      "Epoch [82/100], Step [200/602], Loss: 0.00039969824138097465, SNR: 31.44249725341797\n",
      "Epoch [82/100], Step [300/602], Loss: 0.00035022024530917406, SNR: 31.769378662109375\n",
      "Epoch [82/100], Step [400/602], Loss: 0.00035560442483983934, SNR: 30.47481918334961\n",
      "Epoch [82/100], Step [500/602], Loss: 0.0003158879990223795, SNR: 32.36423873901367\n",
      "Epoch [82/100], Step [600/602], Loss: 0.0004558986984193325, SNR: 29.322120666503906\n",
      ".:. Training metrics = Loss: 0.0004220075419060187, SNR: 31.537026099959053\n",
      ".:. Validation metrics = Loss: 0.00035624027137951567, SNR: 32.09534397781698\n",
      "Epoch [83/100], Step [100/602], Loss: 0.00044930781587027013, SNR: 31.311603546142578\n",
      "Epoch [83/100], Step [200/602], Loss: 0.0003341429110150784, SNR: 33.5269660949707\n",
      "Epoch [83/100], Step [300/602], Loss: 0.0004831939295399934, SNR: 31.94184684753418\n",
      "Epoch [83/100], Step [400/602], Loss: 0.000636632030364126, SNR: 31.622859954833984\n",
      "Epoch [83/100], Step [500/602], Loss: 0.0004714226524811238, SNR: 30.761394500732422\n",
      "Epoch [83/100], Step [600/602], Loss: 0.0005610876251012087, SNR: 31.62041473388672\n",
      ".:. Training metrics = Loss: 0.00042085795745420957, SNR: 31.55888832876828\n",
      ".:. Validation metrics = Loss: 0.0003483530289819166, SNR: 32.15004413025085\n",
      "Epoch [84/100], Step [100/602], Loss: 0.00037554974551312625, SNR: 29.118391036987305\n",
      "Epoch [84/100], Step [200/602], Loss: 0.0003337161906529218, SNR: 32.15711212158203\n",
      "Epoch [84/100], Step [300/602], Loss: 0.00031242825207300484, SNR: 32.79926300048828\n",
      "Epoch [84/100], Step [400/602], Loss: 0.0003862122248392552, SNR: 30.821861267089844\n",
      "Epoch [84/100], Step [500/602], Loss: 0.00036734240711666644, SNR: 30.910106658935547\n",
      "Epoch [84/100], Step [600/602], Loss: 0.0005161022418178618, SNR: 28.475337982177734\n",
      ".:. Training metrics = Loss: 0.0004197057534922336, SNR: 31.58048971514146\n",
      ".:. Validation metrics = Loss: 0.00036147116504580063, SNR: 32.142580028456614\n",
      "Epoch [85/100], Step [100/602], Loss: 0.00036161576281301677, SNR: 30.348094940185547\n",
      "Epoch [85/100], Step [200/602], Loss: 0.00035908434074372053, SNR: 31.627002716064453\n",
      "Epoch [85/100], Step [300/602], Loss: 0.0003303303092252463, SNR: 33.36319351196289\n",
      "Epoch [85/100], Step [400/602], Loss: 0.000524901959579438, SNR: 29.322303771972656\n",
      "Epoch [85/100], Step [500/602], Loss: 0.000294013530947268, SNR: 33.09795379638672\n",
      "Epoch [85/100], Step [600/602], Loss: 0.00036008664756082, SNR: 32.641883850097656\n",
      ".:. Training metrics = Loss: 0.00041853488942572765, SNR: 31.602563131199723\n",
      ".:. Validation metrics = Loss: 0.00035282543901250313, SNR: 32.1803880561016\n",
      "Epoch [86/100], Step [100/602], Loss: 0.0002981919969897717, SNR: 33.47613525390625\n",
      "Epoch [86/100], Step [200/602], Loss: 0.00040165369864553213, SNR: 30.034582138061523\n",
      "Epoch [86/100], Step [300/602], Loss: 0.0002935357333626598, SNR: 32.17622375488281\n",
      "Epoch [86/100], Step [400/602], Loss: 0.00035770281101576984, SNR: 31.768478393554688\n",
      "Epoch [86/100], Step [500/602], Loss: 0.00027766713174059987, SNR: 32.57067108154297\n",
      "Epoch [86/100], Step [600/602], Loss: 0.00037804487510584295, SNR: 32.45452880859375\n",
      ".:. Training metrics = Loss: 0.0004174336079859237, SNR: 31.623861026958927\n",
      ".:. Validation metrics = Loss: 0.00034948720939610337, SNR: 32.2011390938238\n",
      "Epoch [87/100], Step [100/602], Loss: 0.000406916398787871, SNR: 30.937088012695312\n",
      "Epoch [87/100], Step [200/602], Loss: 0.0004343042674008757, SNR: 31.512149810791016\n",
      "Epoch [87/100], Step [300/602], Loss: 0.0003151987912133336, SNR: 33.814353942871094\n",
      "Epoch [87/100], Step [400/602], Loss: 0.00033203113707713783, SNR: 32.69686508178711\n",
      "Epoch [87/100], Step [500/602], Loss: 0.00037197055644355714, SNR: 31.95722198486328\n",
      "Epoch [87/100], Step [600/602], Loss: 0.0003876355476677418, SNR: 31.506980895996094\n",
      ".:. Training metrics = Loss: 0.00041634242598280035, SNR: 31.64483935452952\n",
      ".:. Validation metrics = Loss: 0.00034706579397012264, SNR: 32.221765329036366\n",
      "Epoch [88/100], Step [100/602], Loss: 0.00034978435724042356, SNR: 32.00825881958008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Step [200/602], Loss: 0.0005004799459129572, SNR: 32.65711975097656\n",
      "Epoch [88/100], Step [300/602], Loss: 0.0008630871307104826, SNR: 30.517911911010742\n",
      "Epoch [88/100], Step [400/602], Loss: 0.00046603704686276615, SNR: 31.982769012451172\n",
      "Epoch [88/100], Step [500/602], Loss: 0.0003338593814987689, SNR: 31.577579498291016\n",
      "Epoch [88/100], Step [600/602], Loss: 0.00028686129371635616, SNR: 32.91240692138672\n",
      ".:. Training metrics = Loss: 0.0004151903868221595, SNR: 31.665467437018563\n",
      ".:. Validation metrics = Loss: 0.00035455570744964763, SNR: 32.24018011143736\n",
      "Epoch [89/100], Step [100/602], Loss: 0.00036480967537499964, SNR: 31.804906845092773\n",
      "Epoch [89/100], Step [200/602], Loss: 0.0003680386289488524, SNR: 32.67555618286133\n",
      "Epoch [89/100], Step [300/602], Loss: 0.0002780030481517315, SNR: 33.745635986328125\n",
      "Epoch [89/100], Step [400/602], Loss: 0.00041829681140370667, SNR: 30.064693450927734\n",
      "Epoch [89/100], Step [500/602], Loss: 0.0003479606530163437, SNR: 32.333290100097656\n",
      "Epoch [89/100], Step [600/602], Loss: 0.00035031125298701227, SNR: 33.52379608154297\n",
      ".:. Training metrics = Loss: 0.00041421945438517837, SNR: 31.68566791617849\n",
      ".:. Validation metrics = Loss: 0.00035009055051644987, SNR: 32.26627124868888\n",
      "Epoch [90/100], Step [100/602], Loss: 0.0004461209464352578, SNR: 29.605588912963867\n",
      "Epoch [90/100], Step [200/602], Loss: 0.00033952834201045334, SNR: 30.771833419799805\n",
      "Epoch [90/100], Step [300/602], Loss: 0.0002872498007491231, SNR: 32.06154251098633\n",
      "Epoch [90/100], Step [400/602], Loss: 0.0002656200958881527, SNR: 33.342411041259766\n",
      "Epoch [90/100], Step [500/602], Loss: 0.0006033580866642296, SNR: 30.285186767578125\n",
      "Epoch [90/100], Step [600/602], Loss: 0.0005944306030869484, SNR: 31.1329345703125\n",
      ".:. Training metrics = Loss: 0.00041310436715762247, SNR: 31.70631693534387\n",
      ".:. Validation metrics = Loss: 0.0003524532777535609, SNR: 32.26965817651397\n",
      "Epoch [91/100], Step [100/602], Loss: 0.0007629756000824273, SNR: 30.42339324951172\n",
      "Epoch [91/100], Step [200/602], Loss: 0.0004001573834102601, SNR: 31.793094635009766\n",
      "Epoch [91/100], Step [300/602], Loss: 0.0003624561068136245, SNR: 30.44436264038086\n",
      "Epoch [91/100], Step [400/602], Loss: 0.0003619557246565819, SNR: 30.878067016601562\n",
      "Epoch [91/100], Step [500/602], Loss: 0.00036540222936309874, SNR: 33.03606033325195\n",
      "Epoch [91/100], Step [600/602], Loss: 0.0004245908639859408, SNR: 31.07622528076172\n",
      ".:. Training metrics = Loss: 0.00041210970000271375, SNR: 31.72551462673684\n",
      ".:. Validation metrics = Loss: 0.00034190426316879917, SNR: 32.31488889513365\n",
      "Epoch [92/100], Step [100/602], Loss: 0.0005225229542702436, SNR: 31.63674545288086\n",
      "Epoch [92/100], Step [200/602], Loss: 0.0003939974121749401, SNR: 30.70118522644043\n",
      "Epoch [92/100], Step [300/602], Loss: 0.000633718678727746, SNR: 30.090171813964844\n",
      "Epoch [92/100], Step [400/602], Loss: 0.00032046515843831003, SNR: 32.916805267333984\n",
      "Epoch [92/100], Step [500/602], Loss: 0.0003085665812250227, SNR: 33.816009521484375\n",
      "Epoch [92/100], Step [600/602], Loss: 0.00032782056950964034, SNR: 31.58236312866211\n",
      ".:. Training metrics = Loss: 0.00041110863154840546, SNR: 31.74592126045046\n",
      ".:. Validation metrics = Loss: 0.0003489657703148491, SNR: 32.31369824825282\n",
      "Epoch [93/100], Step [100/602], Loss: 0.0007475835154764354, SNR: 34.599674224853516\n",
      "Epoch [93/100], Step [200/602], Loss: 0.00041182758286595345, SNR: 30.664127349853516\n",
      "Epoch [93/100], Step [300/602], Loss: 0.00040906015783548355, SNR: 31.334753036499023\n",
      "Epoch [93/100], Step [400/602], Loss: 0.00043300085235387087, SNR: 33.609928131103516\n",
      "Epoch [93/100], Step [500/602], Loss: 0.00037017822614870965, SNR: 32.303916931152344\n",
      "Epoch [93/100], Step [600/602], Loss: 0.00040356069803237915, SNR: 31.543846130371094\n",
      ".:. Training metrics = Loss: 0.00041008712167032275, SNR: 31.76484250303439\n",
      ".:. Validation metrics = Loss: 0.00033827960604523427, SNR: 32.35160823277658\n",
      "Epoch [94/100], Step [100/602], Loss: 0.00042667679372243583, SNR: 31.257457733154297\n",
      "Epoch [94/100], Step [200/602], Loss: 0.00040724233258515596, SNR: 31.8262939453125\n",
      "Epoch [94/100], Step [300/602], Loss: 0.00036843676934950054, SNR: 29.174360275268555\n",
      "Epoch [94/100], Step [400/602], Loss: 0.00039264780934900045, SNR: 31.682655334472656\n",
      "Epoch [94/100], Step [500/602], Loss: 0.0003478220896795392, SNR: 31.72030258178711\n",
      "Epoch [94/100], Step [600/602], Loss: 0.0003917361900676042, SNR: 32.175662994384766\n",
      ".:. Training metrics = Loss: 0.00040912931592936263, SNR: 31.783939333543437\n",
      ".:. Validation metrics = Loss: 0.0003521454210497083, SNR: 32.34243324600487\n",
      "Epoch [95/100], Step [100/602], Loss: 0.0004355252895038575, SNR: 28.367116928100586\n",
      "Epoch [95/100], Step [200/602], Loss: 0.00034062404301948845, SNR: 32.875247955322266\n",
      "Epoch [95/100], Step [300/602], Loss: 0.0003556514566298574, SNR: 30.636327743530273\n",
      "Epoch [95/100], Step [400/602], Loss: 0.0003634147869888693, SNR: 31.740943908691406\n",
      "Epoch [95/100], Step [500/602], Loss: 0.00029287984943948686, SNR: 32.67283630371094\n",
      "Epoch [95/100], Step [600/602], Loss: 0.00037934412830509245, SNR: 31.302656173706055\n",
      ".:. Training metrics = Loss: 0.0004082029140849068, SNR: 31.803012634511095\n",
      ".:. Validation metrics = Loss: 0.00033675634660962686, SNR: 32.394122687412306\n",
      "Epoch [96/100], Step [100/602], Loss: 0.0003732969344127923, SNR: 30.66621971130371\n",
      "Epoch [96/100], Step [200/602], Loss: 0.00041875659371726215, SNR: 30.641530990600586\n",
      "Epoch [96/100], Step [300/602], Loss: 0.0007922386866994202, SNR: 30.064390182495117\n",
      "Epoch [96/100], Step [400/602], Loss: 0.00041711388621479273, SNR: 31.827831268310547\n",
      "Epoch [96/100], Step [500/602], Loss: 0.0004986498970538378, SNR: 29.70342254638672\n",
      "Epoch [96/100], Step [600/602], Loss: 0.0004610598261933774, SNR: 32.0344352722168\n",
      ".:. Training metrics = Loss: 0.00040724186966347993, SNR: 31.822115624619865\n",
      ".:. Validation metrics = Loss: 0.00034007941576716334, SNR: 32.40667869703832\n",
      "Epoch [97/100], Step [100/602], Loss: 0.00038020612555556, SNR: 31.643400192260742\n",
      "Epoch [97/100], Step [200/602], Loss: 0.0003414869133848697, SNR: 33.139469146728516\n",
      "Epoch [97/100], Step [300/602], Loss: 0.00032668598578311503, SNR: 31.902816772460938\n",
      "Epoch [97/100], Step [400/602], Loss: 0.0003786006709560752, SNR: 31.763471603393555\n",
      "Epoch [97/100], Step [500/602], Loss: 0.0003060422313865274, SNR: 32.796207427978516\n",
      "Epoch [97/100], Step [600/602], Loss: 0.00046365134767256677, SNR: 29.245895385742188\n",
      ".:. Training metrics = Loss: 0.000406252042989102, SNR: 31.839791421100625\n",
      ".:. Validation metrics = Loss: 0.00034424549759729987, SNR: 32.41002432898816\n",
      "Epoch [98/100], Step [100/602], Loss: 0.0003507293004076928, SNR: 33.196800231933594\n",
      "Epoch [98/100], Step [200/602], Loss: 0.0004389955138321966, SNR: 33.98215866088867\n",
      "Epoch [98/100], Step [300/602], Loss: 0.00045282012433744967, SNR: 30.995052337646484\n",
      "Epoch [98/100], Step [400/602], Loss: 0.00031532792490907013, SNR: 31.042644500732422\n",
      "Epoch [98/100], Step [500/602], Loss: 0.0008286277879960835, SNR: 31.35879898071289\n",
      "Epoch [98/100], Step [600/602], Loss: 0.00036984842154197395, SNR: 32.881324768066406\n",
      ".:. Training metrics = Loss: 0.00040534744130363775, SNR: 31.858234942824954\n",
      ".:. Validation metrics = Loss: 0.0003363377897828321, SNR: 32.42940594410186\n",
      "Epoch [99/100], Step [100/602], Loss: 0.0006802291609346867, SNR: 33.89736557006836\n",
      "Epoch [99/100], Step [200/602], Loss: 0.0003402014554012567, SNR: 33.23517608642578\n",
      "Epoch [99/100], Step [300/602], Loss: 0.00032477176864631474, SNR: 31.936071395874023\n",
      "Epoch [99/100], Step [400/602], Loss: 0.00026626602630130947, SNR: 33.89857864379883\n",
      "Epoch [99/100], Step [500/602], Loss: 0.00038132714689709246, SNR: 33.74382019042969\n",
      "Epoch [99/100], Step [600/602], Loss: 0.00037019382580183446, SNR: 31.605703353881836\n",
      ".:. Training metrics = Loss: 0.0004044442606311295, SNR: 31.876434175979657\n",
      ".:. Validation metrics = Loss: 0.0003444473448478308, SNR: 32.4402022293645\n",
      "Epoch [100/100], Step [100/602], Loss: 0.00041664132731966674, SNR: 31.70362663269043\n",
      "Epoch [100/100], Step [200/602], Loss: 0.0004612691991496831, SNR: 31.31053924560547\n",
      "Epoch [100/100], Step [300/602], Loss: 0.0003953254781663418, SNR: 30.059385299682617\n",
      "Epoch [100/100], Step [400/602], Loss: 0.00041202432475984097, SNR: 29.48568344116211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Step [500/602], Loss: 0.0006597147439606488, SNR: 30.180410385131836\n",
      "Epoch [100/100], Step [600/602], Loss: 0.000351812836015597, SNR: 32.38691329956055\n",
      ".:. Training metrics = Loss: 0.0004034875532211003, SNR: 31.89495943525786\n",
      ".:. Validation metrics = Loss: 0.00034114208742853295, SNR: 32.454291452535756\n"
     ]
    }
   ],
   "source": [
    "# Train the model over epochs\n",
    "steps = len(ls_generator)\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    # training and val metrics for all data\n",
    "    loss, metric = 0.0, 0.0\n",
    "    val_loss, val_metric = 0.0, 0.0\n",
    "\n",
    "    # ======================== Training ============================= #\n",
    "    for i, (local_batch, local_labels) in enumerate(ls_generator):\n",
    "        # Transfer to Device\n",
    "        local_batch = local_batch.to(device)\n",
    "        local_labels = local_labels.to(device)\n",
    "\n",
    "        # Set gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass, backward pass, optimize\n",
    "        outputs = model(local_batch)\n",
    "        loss_batch = m_loss(outputs, local_labels)\n",
    "        batch_metric = m_snr(outputs, local_labels)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute metrics to all batch\n",
    "        loss += loss_batch.item() * len(local_batch)\n",
    "        metric += batch_metric.item() * len(local_batch)\n",
    "\n",
    "        # Print the loss every \"verbose\" batches\n",
    "        if (i + 1) % config.verbose == 0:\n",
    "            _display_metrics(epoch, i, steps,\n",
    "                loss_batch.item(), batch_metric.item())\n",
    "\n",
    "    # Compute the statistics of the last epoch and save to history\n",
    "    history['loss'].append(loss / len(lsg))\n",
    "    history['SNR'].append(metric / len(lsg))\n",
    "\n",
    "    # Print Validation statistics\n",
    "    print(\".:. Training metrics =\", end=\" \")\n",
    "    print(\"Loss: {}, SNR: {}\".format(loss / len(lsg), metric / len(lsg)))\n",
    "    \n",
    "    # ======================= Validation ============================ #\n",
    "    with torch.no_grad():\n",
    "        for local_batch, local_labels in ls_val_generator:\n",
    "            # Transfer to device\n",
    "            local_batch = local_batch.to(device)\n",
    "            local_labels = local_labels.to(device)\n",
    "\n",
    "            # Predict, get loss and metric\n",
    "            outputs = model(local_batch)\n",
    "            val_loss += m_loss(outputs, local_labels).item() \\\n",
    "                * len(local_batch)\n",
    "\n",
    "            val_metric += m_snr(outputs, local_labels).item() \\\n",
    "                * len(local_batch)\n",
    "\n",
    "        val_loss /= len(lsg_val)\n",
    "        val_metric /= len(lsg_val)\n",
    "                \n",
    "    # Print Validation statistics\n",
    "    print(\".:. Validation metrics =\", end=\" \")\n",
    "    print(\"Loss: {}, SNR: {}\".format(val_loss, val_metric))\n",
    "\n",
    "    # Compute the metrics and loss of last batch and save to history\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_SNR'].append(val_metric)\n",
    "    lr_scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the last model\n",
    "torch.save(model.state_dict(), config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss_batch\n",
    "}, config.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot network history\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['val_loss'], label='val')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Traning history')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot network history\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history['SNR'], label='train')\n",
    "plt.plot(history['val_SNR'], label='val')\n",
    "plt.ylabel('SNR')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Traning history')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history to a JSON file\n",
    "with open(config.history_path, 'w') as fp:\n",
    "    json.dump(history, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for local_batch, local_labels in ls_val_generator:\n",
    "        # Transfer to device\n",
    "        local_batch = local_batch.to(device)\n",
    "        local_labels = local_labels.to(device)\n",
    "\n",
    "        # Predict, get loss and metric\n",
    "        outputs = model(local_batch)\n",
    "        writer(local_batch, local_labels,\n",
    "               outputs, config.sr, config.writer_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
